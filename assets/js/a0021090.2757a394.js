"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[5406],{6445:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"core-concepts/nodes/index","title":"Nodes (Source, Transform, Sink, and Specialized)","description":"Explore the fundamental building blocks of any NPipeline \u2013 Source, Transform, Sink, and specialized nodes for complex data processing patterns.","source":"@site/docs/core-concepts/nodes/index.md","sourceDirName":"core-concepts/nodes","slug":"/core-concepts/nodes/","permalink":"/docs/core-concepts/nodes/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Nodes (Source, Transform, Sink, and Specialized)","description":"Explore the fundamental building blocks of any NPipeline \u2013 Source, Transform, Sink, and specialized nodes for complex data processing patterns.","sidebar_position":4},"sidebar":"docsSidebar","previous":{"title":"Data Pipes (IDataPipe)","permalink":"/docs/core-concepts/data-pipes"},"next":{"title":"Source Nodes","permalink":"/docs/core-concepts/nodes/source-nodes"}}');var r=i(4848),o=i(8453);const t={title:"Nodes (Source, Transform, Sink, and Specialized)",description:"Explore the fundamental building blocks of any NPipeline \u2013 Source, Transform, Sink, and specialized nodes for complex data processing patterns.",sidebar_position:4},a="Nodes: Source, Transform, Sink, and Specialized",c={},d=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"The Node Hierarchy",id:"the-node-hierarchy",level:2},{value:"Core Node Types",id:"core-node-types",level:2},{value:"ISourceNode&lt;TOut&gt;",id:"isourcenodetout",level:3},{value:"Definition",id:"definition",level:4},{value:"Key Design Pattern: Synchronous Pipe Creation + Asynchronous Iteration",id:"key-design-pattern-synchronous-pipe-creation--asynchronous-iteration",level:4},{value:"Example",id:"example",level:4},{value:"ITransformNode&lt;TIn, TOut&gt;",id:"itransformnodetin-tout",level:3},{value:"Definition",id:"definition-1",level:4},{value:"Example",id:"example-1",level:4},{value:"ISinkNode&lt;TIn&gt;",id:"isinknodetin",level:3},{value:"Definition",id:"definition-2",level:4},{value:"Example",id:"example-2",level:4},{value:"Specialized Node Types",id:"specialized-node-types",level:2},{value:"Topics in this Section",id:"topics-in-this-section",level:3},{value:"Core Node Types",id:"core-node-types-1",level:4},{value:"Specialized Node Types",id:"specialized-node-types-1",level:4},{value:"Choosing the Right Node Type",id:"choosing-the-right-node-type",level:2},{value:"Node Connectivity",id:"node-connectivity",level:2},{value:"See Also",id:"see-also",level:2},{value:"Next Steps",id:"next-steps",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"nodes-source-transform-sink-and-specialized",children:"Nodes: Source, Transform, Sink, and Specialized"})}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(n.p,{children:"Before understanding nodes, you should be familiar with:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/core-concepts",children:"Core Concepts Overview"})," - Basic NPipeline concepts and terminology"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/core-concepts/pipeline-context",children:"Pipeline Context"})," - How state is shared across nodes"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Nodes are the fundamental building blocks of any NPipeline. They encapsulate the logic for producing, transforming, or consuming data items as they flow through your pipeline. NPipeline defines three primary types of nodes, each with a distinct role:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:["Source Nodes (",(0,r.jsx)(n.code,{children:"ISourceNode<TOut>"}),"):"]})," Initiate the data flow by producing items."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:["Transform Nodes (",(0,r.jsx)(n.code,{children:"ITransformNode<TIn, TOut>"}),"):"]})," Process and transform data items."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsxs)(n.strong,{children:["Sink Nodes (",(0,r.jsx)(n.code,{children:"ISinkNode<TIn>"}),"):"]})," Consume data items, typically as the final step in a pipeline."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"In addition to these core node types, NPipeline offers specialized nodes for complex data processing patterns like aggregation, batching, joining, and branching."}),"\n",(0,r.jsxs)(n.p,{children:["All nodes implement the ",(0,r.jsx)(n.code,{children:"INode"})," interface, which provides a common base for all processing units within NPipeline."]}),"\n",(0,r.jsx)(n.h2,{id:"the-node-hierarchy",children:"The Node Hierarchy"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"INode"})," interface is the common root for all pipeline nodes. It is a simple marker interface that also implements ",(0,r.jsx)(n.code,{children:"IAsyncDisposable"})," to allow for proper resource cleanup."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"public interface INode : IAsyncDisposable { }\n"})}),"\n",(0,r.jsx)(n.p,{children:"There are several specialized types of nodes, each with a distinct role in the pipeline:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ISourceNode<TOut>"})}),": Produces data to start a pipeline."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ITransformNode<TIn, TOut>"})}),": Processes data from an upstream node and passes it to a downstream node."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ISinkNode<TIn>"})}),": Consumes data, typically at the end of a pipeline."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Specialized Nodes"}),": Handle complex data processing patterns like aggregation, batching, joining, and branching."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"core-node-types",children:"Core Node Types"}),"\n",(0,r.jsx)(n.p,{children:"The three core node types handle the fundamental data flow in a pipeline:"}),"\n",(0,r.jsx)(n.h3,{id:"isourcenodetout",children:"ISourceNode<TOut>"}),"\n",(0,r.jsx)(n.p,{children:"A source node is the starting point of a pipeline. It is responsible for generating or fetching the initial data that will be processed. A pipeline must have at least one source node."}),"\n",(0,r.jsx)(n.h4,{id:"definition",children:"Definition"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"public interface ISourceNode<out TOut> : INode\r\n{\r\n    IDataPipe<TOut> ExecuteAsync(PipelineContext context, CancellationToken cancellationToken);\r\n}\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"TOut"})}),": The type of data that the source node produces (covariant)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ExecuteAsync"})}),": This method is called by the pipeline runner to start data production. It returns an ",(0,r.jsx)(n.code,{children:"IDataPipe<TOut>"})," synchronously, which is a channel through which data flows to the next node."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"key-design-pattern-synchronous-pipe-creation--asynchronous-iteration",children:"Key Design Pattern: Synchronous Pipe Creation + Asynchronous Iteration"}),"\n",(0,r.jsx)(n.p,{children:"NPipeline separates concerns into two distinct phases:"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Phase 1 (Synchronous):"})," Pipe Creation"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ExecuteAsync()"})," creates and returns the pipe immediately (synchronously)"]}),"\n",(0,r.jsxs)(n.li,{children:["No ",(0,r.jsx)(n.code,{children:"await"})," needed when calling this method"]}),"\n",(0,r.jsx)(n.li,{children:"The pipeline reference is established without blocking"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Phase 2 (Asynchronous):"})," Data Consumption"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["The returned pipe is an ",(0,r.jsx)(n.code,{children:"IAsyncEnumerable<T>"})]}),"\n",(0,r.jsx)(n.li,{children:"Data flows asynchronously when downstream nodes enumerate it"}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"await foreach"})," is used when consuming data items"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mental Model - File I/O Analogy:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"// File I/O pattern:\r\nvar stream = File.OpenRead(path);           // Sync - open stream immediately\r\nvar bytes = await stream.ReadAsync(...);    // Async - read from stream\r\n\r\n// NPipeline pattern:\r\nvar pipe = source.ExecuteAsync(...);        // Sync - create pipe immediately  \r\nvar item = await pipe.FirstAsync();         // Async - read item from pipe\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Why This Design?"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Clearer Intent:"}),' "ExecuteAsync" signals you\'re in the async execution system, but the pipe creation itself is fast and synchronous']}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Type Safety:"})," Covariant ",(0,r.jsx)(n.code,{children:"IDataPipe<T>"})," (not invariant ",(0,r.jsx)(n.code,{children:"Task<IDataPipe<T>>"}),") enables better type compatibility"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Performance:"})," No unnecessary ",(0,r.jsx)(n.code,{children:"Task"})," allocations for pipe creation"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Consistency:"})," Uniform pattern across all source nodes"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"example",children:"Example"}),"\n",(0,r.jsx)(n.p,{children:"Here is an example of a simple source node that produces a sequence of numbers:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"/// <summary>\r\n/// Simple source node that produces a sequence of numbers.\r\n/// Demonstrates the synchronous pipe creation + asynchronous iteration pattern\r\n/// that is fundamental to NPipeline's design.\r\n/// </summary>\r\npublic sealed class NumberSource : SourceNode<int>\r\n{\r\n    public override IDataPipe<int> ExecuteAsync(PipelineContext context, CancellationToken cancellationToken)\r\n    {\r\n        // Create and return the data pipe immediately (synchronous operation)\r\n        // The actual data streaming happens asynchronously when downstream nodes enumerate\r\n        return new StreamingDataPipe<int>(StreamNumbers());\r\n\r\n        static async IAsyncEnumerable<int> StreamNumbers()\r\n        {\r\n            for (int i = 1; i <= 10; i++)\r\n            {\r\n                yield return i;\r\n                // Simulate work or external dependency delay\r\n                await Task.Delay(100, cancellationToken);\r\n            }\r\n        }\r\n    }\r\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"itransformnodetin-tout",children:"ITransformNode<TIn, TOut>"}),"\n",(0,r.jsx)(n.p,{children:"A transform node sits between a source and a sink (or between other transforms). It receives data, performs an operation on it, and then outputs the modified data."}),"\n",(0,r.jsx)(n.h4,{id:"definition-1",children:"Definition"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"public interface ITransformNode : INode\r\n{\r\n    IExecutionStrategy ExecutionStrategy { get; set; }\r\n    INodeErrorHandler? ErrorHandler { get; set; }\r\n}\r\n\r\npublic interface ITransformNode<in TIn, TOut> : ITransformNode\r\n{\r\n    Task<TOut> ExecuteAsync(TIn item, PipelineContext context, CancellationToken cancellationToken);\r\n}\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"TIn"})}),": The type of data the node receives."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"TOut"})}),": The type of data the node outputs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ExecuteAsync"})}),": This method is called for each individual item that flows into the node."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ExecutionStrategy"})}),": Gets or sets the execution strategy for this node."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ErrorHandler"})}),": Gets or sets the error handler for this node."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"example-1",children:"Example"}),"\n",(0,r.jsx)(n.p,{children:"This transform takes an integer, squares it, and returns the result as a string."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'/// <summary>\r\n/// Transform that squares integers and converts to string representation.\r\n/// Demonstrates the basic transform pattern with synchronous execution.\r\n/// </summary>\r\npublic sealed class SquareAndStringifyTransform : ITransformNode<int, string>\r\n{\r\n    public IExecutionStrategy ExecutionStrategy { get; set; } = new SequentialExecutionStrategy();\r\n    public INodeErrorHandler? ErrorHandler { get; set; }\r\n\r\n    /// <summary>\r\n    /// Processes each integer by squaring it and returning a formatted string.\r\n    /// Uses Task.FromResult for synchronous operations to avoid unnecessary async overhead.\r\n    /// </summary>\r\n    public Task<string> ExecuteAsync(int item, PipelineContext context, CancellationToken cancellationToken)\r\n    {\r\n        // Synchronous calculation - no async work needed\r\n        int squared = item * item;\r\n        \r\n        // Wrap result in Task to satisfy interface, but avoid async state machine\r\n        return Task.FromResult($"The square is {squared}");\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"isinknodetin",children:"ISinkNode<TIn>"}),"\n",(0,r.jsx)(n.p,{children:"A sink node is a terminal point in a pipeline. It receives data but does not produce any output for other nodes. Its purpose is to perform a final action, such as writing to a database, logging to the console, or sending data to an external API."}),"\n",(0,r.jsx)(n.h4,{id:"definition-2",children:"Definition"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"public interface ISinkNode<in TIn> : INode\r\n{\r\n    Task ExecuteAsync(IDataPipe<TIn> input, PipelineContext context, CancellationToken cancellationToken);\r\n}\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"TIn"})}),": The type of data the node receives (contravariant)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"ExecuteAsync"})}),": This method receives the ",(0,r.jsx)(n.code,{children:"IDataPipe<TIn>"})," containing all the data from the upstream node and is responsible for consuming it."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"example-2",children:"Example"}),"\n",(0,r.jsx)(n.p,{children:"This sink node simply prints the incoming strings to the console."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"/// <summary>\r\n/// Sink node that outputs strings to the console.\r\n/// Demonstrates the consumption pattern for terminal nodes in a pipeline.\r\n/// </summary>\r\npublic sealed class ConsoleSink : ISinkNode<string>\r\n{\r\n    /// <summary>\r\n    /// Consumes all items from the input pipe and writes them to console.\r\n    /// Uses await foreach to efficiently iterate through the async stream.\r\n    /// </summary>\r\n    public async Task ExecuteAsync(IDataPipe<string> input, PipelineContext context, CancellationToken cancellationToken)\r\n    {\r\n        // Process each item as it arrives from the upstream node\r\n        await foreach (var item in input.WithCancellation(cancellationToken))\r\n        {\r\n            Console.WriteLine(item);\r\n        }\r\n    }\r\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"specialized-node-types",children:"Specialized Node Types"}),"\n",(0,r.jsx)(n.p,{children:"Beyond the basic source, transform, and sink nodes, NPipeline offers a suite of specialized node types designed to handle more complex data processing patterns. These nodes enable sophisticated operations like aggregating data, joining streams, batching items for efficiency, and duplicating data paths for branching logic or monitoring."}),"\n",(0,r.jsx)(n.h3,{id:"topics-in-this-section",children:"Topics in this Section"}),"\n",(0,r.jsx)(n.h4,{id:"core-node-types-1",children:"Core Node Types"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/source-nodes",children:"Source Nodes"})}),": Learn about nodes that initiate data flow in your pipeline."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/transform-nodes",children:"Transform Nodes"})}),": Explore nodes that process and transform data items."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/sink-nodes",children:"Sink Nodes"})}),": Understand nodes that consume data as the final step in a pipeline."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"specialized-node-types-1",children:"Specialized Node Types"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/aggregation",children:"Aggregation Nodes"})}),": Learn how to perform various aggregation operations on data streams."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/batching",children:"Batching Nodes"})}),": Understand how to batch data for improved processing efficiency."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/join",children:"Join Nodes"})}),": Explore different types of join operations for combining data streams."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/lookup",children:"Lookup Nodes"})}),": Learn how to enrich data by looking up values from external sources."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/time-windowed-join",children:"Time-Windowed Join Nodes"})}),": Discover how to join data streams based on defined time windows."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/branch",children:"Branch Nodes"})}),": Understand how to duplicate data streams for parallel processing."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/tap",children:"Tap Nodes"})}),": Learn about non-intrusive monitoring and side-channel processing."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"choosing-the-right-node-type",children:"Choosing the Right Node Type"}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TD\r\n    A[I need to process data] --\x3e B{What is my role?}\r\n    B --\x3e|Generate/produce data| C[Use SOURCE NODE]\r\n    B --\x3e|Transform/process data| D{Do I need to combine multiple inputs?}\r\n    B --\x3e|Consume/store data| E[Use SINK NODE]\r\n    \r\n    D --\x3e|Yes, combine streams| F[Use SPECIALIZED NODES<br>Join, Aggregate, Batch, or Branch]\r\n    D --\x3e|No, single input| G[Use TRANSFORM NODE]\r\n    \r\n    C --\x3e H[Configure data production<br>ISourceNode&lt;TOut&gt;]\r\n    G --\x3e I[Configure data transformation<br>ITransformNode&lt;TIn, TOut&gt;]\r\n    E --\x3e J[Configure data consumption<br>ISinkNode&lt;TIn&gt;]\r\n    F --\x3e K[Choose specific specialized node type]"}),"\n",(0,r.jsx)(n.p,{children:"This decision tree helps you select the appropriate node type based on your specific data processing needs:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Source Nodes"})," are your starting point when you need to generate or fetch data from external systems"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Transform Nodes"})," handle the processing of data from a single input stream to produce output"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sink Nodes"})," are endpoints that consume data, typically for storage or external system integration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Specialized Nodes"})," provide specific patterns for combining, grouping, or managing complex data flows"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"node-connectivity",children:"Node Connectivity"}),"\n",(0,r.jsxs)(n.p,{children:["Nodes are connected using ",(0,r.jsx)(n.code,{children:"PipelineBuilder"}),". The output type of an upstream node must match the input type of a downstream node. NPipeline ensures type compatibility during pipeline construction."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'using NPipeline;\r\nusing NPipeline.DataFlow;\r\nusing NPipeline.Execution;\r\nusing NPipeline.Nodes;\r\nusing NPipeline.Pipeline;\r\n\r\n/// <summary>\r\n/// Complete pipeline definition that connects source, transform, and sink nodes.\r\n/// Demonstrates the fluent API pattern for building executable pipelines.\r\n/// </summary>\r\npublic sealed class NumberPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        // Add nodes to the pipeline and get handles for connection\r\n        var sourceHandle = builder.AddSource<NumberSource, int>("number_source");\r\n        var transformHandle = builder.AddTransform<SquareTransform, int, int>("square_transform");\r\n        var sinkHandle = builder.AddSink<ConsoleSink<int>, int>("console_sink");\r\n\r\n        // Define data flow by connecting the nodes\r\n        builder.Connect(sourceHandle, transformHandle);\r\n        builder.Connect(transformHandle, sinkHandle);\r\n    }\r\n}\r\n\r\npublic static class Program\r\n{\r\n    public static async Task Main(string[] args)\r\n    {\r\n        // Create a pipeline runner to execute the defined pipeline\r\n        var runner = new PipelineRunner();\r\n        \r\n        // Run the pipeline using the definition\r\n        await runner.RunAsync<NumberPipelineDefinition>();\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/core-concepts/pipelinebuilder",children:"PipelineBuilder"})," - Learn how to connect nodes together"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/core-concepts/pipeline-execution",children:"Pipeline Execution"})," - Understand how nodes are executed"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/core-concepts/resilience/error-handling-guide",children:"Error Handling"})," - Handle errors within nodes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/architecture/core-concepts",children:"Architecture: Core Concepts"})," - Deep dive into node architecture"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/core-concepts/pipelinebuilder",children:"PipelineBuilder"})," - Learn how to connect these nodes together"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/core-concepts/pipeline-execution/execution-strategies",children:"Execution Strategies"})," - Control how nodes process data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/aggregation",children:"Specialized Node Types"})," - Explore more sophisticated node patterns"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>a});var s=i(6540);const r={},o=s.createContext(r);function t(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);