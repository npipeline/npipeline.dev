"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[5658],{834:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"tooling/analyzers/data-processing","title":"Data Processing Analyzers","description":"Ensure proper input consumption and streaming patterns in pipeline nodes.","source":"@site/docs/tooling/analyzers/data-processing.md","sourceDirName":"tooling/analyzers","slug":"/tooling/analyzers/data-processing","permalink":"/docs/tooling/analyzers/data-processing","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Data Processing Analyzers","description":"Ensure proper input consumption and streaming patterns in pipeline nodes.","sidebar_position":4},"sidebar":"docsSidebar","previous":{"title":"Performance Analyzers","permalink":"/docs/tooling/analyzers/performance"},"next":{"title":"Best Practice Analyzers","permalink":"/docs/tooling/analyzers/best-practices"}}');var r=t(4848),a=t(8453);const s={title:"Data Processing Analyzers",description:"Ensure proper input consumption and streaming patterns in pipeline nodes.",sidebar_position:4},o=void 0,c={},l=[{value:"Data Processing Analyzers",id:"data-processing-analyzers",level:2},{value:"NP9205: Non-Streaming Patterns in SourceNode",id:"np9205-non-streaming-patterns-in-sourcenode",level:3},{value:"Performance Impact",id:"performance-impact",level:4},{value:"Problematic Patterns",id:"problematic-patterns",level:4},{value:"Solution: Use Streaming Patterns",id:"solution-use-streaming-patterns",level:4},{value:"Advanced Streaming Patterns",id:"advanced-streaming-patterns",level:4},{value:"Streaming with Transformation",id:"streaming-with-transformation",level:5},{value:"Streaming with Filtering",id:"streaming-with-filtering",level:5},{value:"When to Use Each Pattern",id:"when-to-use-each-pattern",level:4},{value:"Implementation Guide",id:"implementation-guide",level:4},{value:"NP9302: Input Parameter Not Consumed",id:"np9302-input-parameter-not-consumed",level:3},{value:"Why This Matters (NP9210)",id:"why-this-matters-np9210",level:4},{value:"Solution: Always Consume Input",id:"solution-always-consume-input",level:4},{value:"Common Input Consumption Patterns",id:"common-input-consumption-patterns",level:4},{value:"Best Practices for SinkNode",id:"best-practices-for-sinknode",level:4},{value:"NP9210: StreamTransformNode Suggestion",id:"np9210-streamtransformnode-suggestion",level:3},{value:"Why This Matters",id:"why-this-matters",level:4},{value:"Problematic Pattern (NP9210)",id:"problematic-pattern-np9210",level:4},{value:"Solution: Use IStreamTransformNode",id:"solution-use-istreamtransformnode",level:4},{value:"Code Fix (NP9210)",id:"code-fix-np9210",level:4},{value:"When to Use Each Interface",id:"when-to-use-each-interface",level:4},{value:"NP9211: StreamTransformNode Execution Strategy Mismatch",id:"np9211-streamtransformnode-execution-strategy-mismatch",level:3},{value:"Why This Matters (NP9211)",id:"why-this-matters-np9211",level:4},{value:"Problematic Patterns (NP9211)",id:"problematic-patterns-np9211",level:4},{value:"Solution: Use Stream-Optimized Execution Strategies",id:"solution-use-stream-optimized-execution-strategies",level:4},{value:"Available Stream Execution Strategies",id:"available-stream-execution-strategies",level:4},{value:"Code Fix (NP9211)",id:"code-fix-np9211",level:4},{value:"Creating Custom Stream Execution Strategies",id:"creating-custom-stream-execution-strategies",level:4},{value:"Why Data Processing Analyzers Matter",id:"why-data-processing-analyzers-matter",level:2},{value:"Configuration",id:"configuration",level:2},{value:"See Also",id:"see-also",level:2}];function d(e){const n={a:"a",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",h5:"h5",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"data-processing-analyzers",children:"Data Processing Analyzers"}),"\n",(0,r.jsx)(n.p,{children:"Data processing analyzers protect the integrity of data flow through your pipelines. They detect patterns that cause data loss, memory bloat, or improper stream handling."}),"\n",(0,r.jsx)(n.h3,{id:"np9205-non-streaming-patterns-in-sourcenode",children:"NP9205: Non-Streaming Patterns in SourceNode"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ID:"})," ",(0,r.jsx)(n.code,{children:"NP9205"}),"\n",(0,r.jsx)(n.strong,{children:"Severity:"})," Warning",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.strong,{children:"Category:"})," Performance"]}),"\n",(0,r.jsx)(n.p,{children:"This analyzer detects non-streaming patterns in SourceNode implementations that can lead to memory issues and poor performance. The analyzer identifies the following problematic patterns:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"List and Array allocation and population"})," in Initialize methods"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:".ToAsyncEnumerable()"})," calls on materialized collections"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synchronous I/O operations"})," like File.ReadAllText, File.WriteAllBytes, etc."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:".ToList() and .ToArray()"})," calls that materialize collections in memory"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"performance-impact",children:"Performance Impact"}),"\n",(0,r.jsx)(n.p,{children:"Non-streaming patterns in SourceNode implementations cause:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"High Memory Usage"}),": Loading entire datasets into memory can cause OutOfMemoryException with large files"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Poor Startup Performance"}),": Applications must wait for all data to be loaded before processing begins"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Increased GC Pressure"}),": Large collections create more garbage collection work"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reduced Scalability"}),": Memory requirements grow linearly with data size"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Blocking I/O"}),": Synchronous operations block threads and reduce throughput"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"problematic-patterns",children:"Problematic Patterns"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'// :x: PROBLEM: Materializing all data in memory\npublic class BadSourceNode : SourceNode<string>\n{\n    public override IDataPipe<string> Initialize(PipelineContext context, CancellationToken cancellationToken)\n    {\n        var output = new DataPipe<string>();\n        \n        // NP9205: Allocating List<T> and populating it\n        var items = new List<string>();\n        \n        // Read all lines from file into memory\n        var lines = File.ReadAllLines("large-file.txt"); // NP9205: Synchronous I/O\n        \n        foreach (var line in lines)\n        {\n            items.Add(line);\n        }\n        \n        // NP9205: Materializing collection with ToList()\n        foreach (var item in items.ToList())\n        {\n            output.Produce(item);\n        }\n        \n        return output;\n    }\n}\n\n// :x: PROBLEM: Using ToAsyncEnumerable on materialized collection\npublic class AnotherBadSourceNode : SourceNode<int>\n{\n    public override IDataPipe<int> Initialize(PipelineContext context, CancellationToken cancellationToken)\n    {\n        var output = new DataPipe<int>();\n        \n        // NP9205: Creating array and then converting to async enumerable\n        var numbers = Enumerable.Range(0, 1000000).ToArray(); // NP9205: Array allocation\n        \n        // NP9205: Using ToAsyncEnumerable on materialized collection\n        foreach (var number in numbers.ToAsyncEnumerable())\n        {\n            output.Produce(number);\n        }\n        \n        return output;\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"solution-use-streaming-patterns",children:"Solution: Use Streaming Patterns"}),"\n",(0,r.jsx)(n.p,{children:"For SourceNode implementations, use IAsyncEnumerable with yield return for proper streaming:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'// :heavy_check_mark: CORRECT: Using IAsyncEnumerable with yield return\npublic class GoodSourceNode : SourceNode<string>\n{\n    public override IDataPipe<string> Initialize(PipelineContext context, CancellationToken cancellationToken)\n    {\n        return new StreamingDataPipe<string>(ReadLines("large-file.txt", cancellationToken));\n    }\n    \n    // Helper method that yields lines one at a time\n    private async IAsyncEnumerable<string> ReadLines(string filePath, [EnumeratorCancellation] CancellationToken cancellationToken)\n    {\n        using var reader = new StreamReader(\n            new FileStream(filePath, FileMode.Open, FileAccess.Read, FileShare.Read, bufferSize: 4096, useAsync: true));\n        \n        string? line;\n        while ((line = await reader.ReadLineAsync()) != null)\n        {\n            cancellationToken.ThrowIfCancellationRequested();\n            yield return line; // Stream one line at a time\n        }\n    }\n}\n\n// :heavy_check_mark: CORRECT: Streaming from database\npublic class DatabaseSourceNode : SourceNode<DataRecord>\n{\n    private readonly IDbConnection _connection;\n    \n    public DatabaseSourceNode(IDbConnection connection)\n    {\n        _connection = connection;\n    }\n    \n    public override IDataPipe<DataRecord> Initialize(PipelineContext context, CancellationToken cancellationToken)\n    {\n        return new StreamingDataPipe<DataRecord>(ReadRecords(cancellationToken));\n    }\n    \n    private async IAsyncEnumerable<DataRecord> ReadRecords([EnumeratorCancellation] CancellationToken cancellationToken)\n    {\n        await using var command = _connection.CreateCommand();\n        command.CommandText = "SELECT Id, Name FROM DataRecords";\n        \n        await using var reader = await command.ExecuteReaderAsync(cancellationToken);\n        \n        while (await reader.ReadAsync(cancellationToken))\n        {\n            cancellationToken.ThrowIfCancellationRequested();\n            yield return new DataRecord\n            {\n                Id = reader.GetInt32(0),\n                Name = reader.GetString(1)\n            };\n        }\n    }\n}\n\n// :heavy_check_mark: CORRECT: Generating data stream without materialization\npublic class NumberGeneratorSourceNode : SourceNode<int>\n{\n    private readonly int _start;\n    private readonly int _count;\n    \n    public NumberGeneratorSourceNode(int start, int count)\n    {\n        _start = start;\n        _count = count;\n    }\n    \n    public override IDataPipe<int> Initialize(PipelineContext context, CancellationToken cancellationToken)\n    {\n        return new StreamingDataPipe<int>(GenerateNumbers(cancellationToken));\n    }\n    \n    private async IAsyncEnumerable<int> GenerateNumbers([EnumeratorCancellation] CancellationToken cancellationToken)\n    {\n        for (int i = 0; i < _count; i++)\n        {\n            cancellationToken.ThrowIfCancellationRequested();\n            yield return _start + i;\n            \n            // Optional: Add small delay to prevent overwhelming downstream nodes\n            if (i % 1000 == 0)\n            {\n                await Task.Delay(1, cancellationToken);\n            }\n        }\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"advanced-streaming-patterns",children:"Advanced Streaming Patterns"}),"\n",(0,r.jsx)(n.h5,{id:"streaming-with-transformation",children:"Streaming with Transformation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"// :heavy_check_mark: GOOD: Streaming with transformation\npublic class TransformingSourceNode : SourceNode<ProcessedData>\n{\n    public override IDataPipe<ProcessedData> Initialize(PipelineContext context, CancellationToken cancellationToken)\n    {\n        return new StreamingDataPipe<ProcessedData>(TransformItems(cancellationToken));\n    }\n    \n    private async IAsyncEnumerable<ProcessedData> TransformItems([EnumeratorCancellation] CancellationToken cancellationToken)\n    {\n        await foreach (var rawItem in GetRawItemsAsync(cancellationToken))\n        {\n            // Transform item without materializing the entire collection\n            var processedItem = ProcessItem(rawItem);\n            yield return processedItem;\n        }\n    }\n    \n    private async IAsyncEnumerable<RawData> GetRawItemsAsync([EnumeratorCancellation] CancellationToken cancellationToken)\n    {\n        // Stream raw items from source\n        await foreach (var item in ReadFromSourceAsync(cancellationToken))\n        {\n            yield return item;\n        }\n    }\n    \n    private ProcessedData ProcessItem(RawData raw)\n    {\n        // Synchronous transformation is fine for individual items\n        return new ProcessedData\n        {\n            Id = raw.Id,\n            Value = raw.Value * 2,\n            Timestamp = DateTime.UtcNow\n        };\n    }\n}\n"})}),"\n",(0,r.jsx)(n.h5,{id:"streaming-with-filtering",children:"Streaming with Filtering"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"// :heavy_check_mark: GOOD: Streaming with filtering\npublic class FilteringSourceNode : SourceNode<FilteredData>\n{\n    private readonly Func<DataItem, bool> _filter;\n    \n    public FilteringSourceNode(Func<DataItem, bool> filter)\n    {\n        _filter = filter;\n    }\n    \n    public override IDataPipe<FilteredData> Initialize(PipelineContext context, CancellationToken cancellationToken)\n    {\n        return new StreamingDataPipe<FilteredData>(FilterItems(cancellationToken));\n    }\n    \n    private async IAsyncEnumerable<FilteredData> FilterItems([EnumeratorCancellation] CancellationToken cancellationToken)\n    {\n        await foreach (var item in GetAllItemsAsync(cancellationToken))\n        {\n            // Filter items without materializing the entire collection\n            if (_filter(item))\n            {\n                yield return new FilteredData(item);\n            }\n        }\n    }\n    \n    private async IAsyncEnumerable<DataItem> GetAllItemsAsync([EnumeratorCancellation] CancellationToken cancellationToken)\n    {\n        // Stream items from source\n        await foreach (var item in ReadFromSourceAsync(cancellationToken))\n        {\n            yield return item;\n        }\n    }\n}\n"})}),"\n",(0,r.jsx)(n.h4,{id:"when-to-use-each-pattern",children:"When to Use Each Pattern"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Scenario"}),(0,r.jsx)(n.th,{children:"Recommended Approach"}),(0,r.jsx)(n.th,{children:"Reason"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Large files/streams"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"IAsyncEnumerable"})," with ",(0,r.jsx)(n.code,{children:"yield return"})]}),(0,r.jsx)(n.td,{children:"Minimal memory usage"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Database queries"}),(0,r.jsx)(n.td,{children:"Stream from database cursor"}),(0,r.jsx)(n.td,{children:"Avoid loading entire result set"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"API calls with pagination"}),(0,r.jsx)(n.td,{children:"Page through results"}),(0,r.jsx)(n.td,{children:"Process data as it arrives"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Data generation"}),(0,r.jsx)(n.td,{children:"Generate and yield items"}),(0,r.jsx)(n.td,{children:"No need to store all items"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Small datasets (< 1000 items)"}),(0,r.jsx)(n.td,{children:"Either approach is fine"}),(0,r.jsx)(n.td,{children:"Memory impact is negligible"})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"implementation-guide",children:"Implementation Guide"}),"\n",(0,r.jsx)(n.p,{children:"To implement streaming SourceNode implementations:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Identify non-streaming patterns"})," using the NP9205 analyzer"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Replace List and Array allocations"})," with ",(0,r.jsx)(n.code,{children:"IAsyncEnumerable"})," methods"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Convert synchronous I/O"})," to async equivalents (",(0,r.jsx)(n.code,{children:"File.ReadAllText"})," \u2192 ",(0,r.jsx)(n.code,{children:"File.ReadAllTextAsync"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Remove .ToAsyncEnumerable()"})," calls on materialized collections"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use yield return"})," to stream items one at a time"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add cancellation support"})," with ",(0,r.jsx)(n.code,{children:"[EnumeratorCancellation]"})," attribute"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"np9302-input-parameter-not-consumed",children:"NP9302: Input Parameter Not Consumed"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ID:"})," ",(0,r.jsx)(n.code,{children:"NP9302"}),"\n",(0,r.jsx)(n.strong,{children:"Severity:"})," Error",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.strong,{children:"Category:"})," Data Processing"]}),"\n",(0,r.jsx)(n.p,{children:"This analyzer detects when a SinkNode implementation overrides ExecuteAsync but doesn't consume the input parameter. Sink nodes are designed to process all items from the input data pipe, but your implementation ignores the input."}),"\n",(0,r.jsx)(n.p,{children:"This analyzer identifies these problematic patterns:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SinkNode.ExecuteAsync override without input consumption"})," - The method doesn't use the input parameter"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Empty ExecuteAsync implementation"})," - The method returns without processing input"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ExecuteAsync with only side effects"})," - The method performs operations but ignores input data"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"why-this-matters-np9210",children:"Why This Matters (NP9210)"}),"\n",(0,r.jsx)(n.p,{children:"SinkNode is the terminal component in a pipeline that processes all data flowing through it. When a SinkNode doesn't consume its input:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data Loss"}),": Items in the input pipe are never processed"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pipeline Inefficiency"}),": The pipeline moves data but the sink doesn't handle it"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Resource Waste"}),": Memory and processing are used to move data that's never consumed"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Unexpected Behavior"}),": Applications may appear to work but silently ignore data"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"solution-always-consume-input",children:"Solution: Always Consume Input"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'// :heavy_check_mark: CORRECT: Process all items from input\npublic class MySinkNode : SinkNode<string>\n{\n    public override async Task ExecuteAsync(IDataPipe<string> input, PipelineContext context, CancellationToken cancellationToken)\n    {\n        // Process all items from input\n        await foreach (var item in input.WithCancellation(cancellationToken))\n        {\n            Console.WriteLine($"Processing: {item}");\n            // Save to database, write to file, etc.\n        }\n    }\n}\n\n// :heavy_check_mark: CORRECT: Use DataPipe operations\npublic class CountingSinkNode : SinkNode<string>\n{\n    public override async Task ExecuteAsync(IDataPipe<string> input, PipelineContext context, CancellationToken cancellationToken)\n    {\n        // Count all items\n        var count = await input.CountAsync(cancellationToken);\n        Console.WriteLine($"Total items processed: {count}");\n    }\n}\n\n// :heavy_check_mark: CORRECT: Handle empty input gracefully\npublic class RobustSinkNode : SinkNode<string>\n{\n    public override async Task ExecuteAsync(IDataPipe<string> input, PipelineContext context, CancellationToken cancellationToken)\n    {\n        var hasItems = false;\n        await foreach (var item in input.WithCancellation(cancellationToken))\n        {\n            hasItems = true;\n            Console.WriteLine($"Processing: {item}");\n        }\n        \n        if (!hasItems)\n        {\n            Console.WriteLine("No items to process");\n        }\n    }\n}\n\n// :heavy_check_mark: CORRECT: Conditional processing with default input consumption\npublic class ConditionalSinkNode : SinkNode<string>\n{\n    private readonly bool _shouldProcess;\n    \n    public ConditionalSinkNode(bool shouldProcess)\n    {\n        _shouldProcess = shouldProcess;\n    }\n    \n    public override async Task ExecuteAsync(IDataPipe<string> input, PipelineContext context, CancellationToken cancellationToken)\n    {\n        if (_shouldProcess)\n        {\n            await foreach (var item in input.WithCancellation(cancellationToken))\n            {\n                Console.WriteLine($"Processing: {item}");\n            }\n        }\n        else\n        {\n            // Always consume input even when not processing\n            await foreach (var _ in input.WithCancellation(cancellationToken))\n            {\n                // Just consume the items\n            }\n        }\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h4,{id:"common-input-consumption-patterns",children:"Common Input Consumption Patterns"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Pattern"}),(0,r.jsx)(n.th,{children:"Example"}),(0,r.jsx)(n.th,{children:"Use Case"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Process all items"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"await foreach (var item in input.WithCancellation(cancellationToken)) { ... }"})}),(0,r.jsx)(n.td,{children:"Standard processing of each item"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Count items"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"var count = await input.CountAsync(cancellationToken);"})}),(0,r.jsx)(n.td,{children:"When you only need the count"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Collect to list"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"var items = await input.ToListAsync(cancellationToken);"})}),(0,r.jsx)(n.td,{children:"When you need all items in memory"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"First item only"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"var first = await input.FirstAsync(cancellationToken);"})}),(0,r.jsx)(n.td,{children:"When you only need the first item"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Any items check"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"var hasItems = await input.AnyAsync(cancellationToken);"})}),(0,r.jsx)(n.td,{children:"When you just need to check if input is non-empty"})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"best-practices-for-sinknode",children:"Best Practices for SinkNode"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Always consume the input"})," - Use ",(0,r.jsx)(n.code,{children:"await foreach"})," or other data pipe operations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pass cancellation token"})," - Use ",(0,r.jsx)(n.code,{children:"WithCancellation(cancellationToken)"})," for proper cancellation support"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Handle empty input"})," - Your code should work correctly even if the input pipe is empty"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consider performance"})," - For large datasets, process items in a streaming fashion rather than collecting all items"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Don't silently ignore input"})," - Even if you don't need to process items, consume them to acknowledge receipt"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"np9210-streamtransformnode-suggestion",children:"NP9210: StreamTransformNode Suggestion"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ID:"})," ",(0,r.jsx)(n.code,{children:"NP9210"}),"\n",(0,r.jsx)(n.strong,{children:"Severity:"})," Info",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.strong,{children:"Category:"})," Design"]}),"\n",(0,r.jsxs)(n.p,{children:["This analyzer detects when a class implements ",(0,r.jsx)(n.code,{children:"ITransformNode<TIn, TOut>"})," but the ",(0,r.jsx)(n.code,{children:"TOut"})," generic argument is ",(0,r.jsx)(n.code,{children:"IAsyncEnumerable<T>"}),", meaning ",(0,r.jsx)(n.code,{children:"ExecuteAsync"})," returns ",(0,r.jsx)(n.code,{children:"Task<IAsyncEnumerable<T>>"}),". It suggests using ",(0,r.jsx)(n.code,{children:"IStreamTransformNode"})," instead for better interface segregation and optimized execution."]}),"\n",(0,r.jsx)(n.h4,{id:"why-this-matters",children:"Why This Matters"}),"\n",(0,r.jsxs)(n.p,{children:["When a transform node's ",(0,r.jsx)(n.code,{children:"ExecuteAsync"})," method returns ",(0,r.jsx)(n.code,{children:"Task<IAsyncEnumerable<T>>"}),", it indicates that the node is performing stream-based transformations. Using ",(0,r.jsx)(n.code,{children:"IStreamTransformNode"})," instead of ",(0,r.jsx)(n.code,{children:"ITransformNode"})," provides several benefits:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Better Interface Segregation"}),": ",(0,r.jsx)(n.code,{children:"IStreamTransformNode"})," is specifically designed for stream-based transformations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Clearer Intent"}),": Makes it obvious that the node processes streams rather than individual items"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimized Execution"}),": Allows the pipeline to use stream-specific execution strategies"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Type Safety"}),": Ensures proper handling of streaming data patterns"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"problematic-pattern-np9210",children:"Problematic Pattern (NP9210)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"using System.Globalization;\n\n// :x: PROBLEM: Using ITransformNode with IAsyncEnumerable return type\npublic class DataProcessor : ITransformNode<string, IAsyncEnumerable<int>>\n{\n    public Task<IAsyncEnumerable<int>> ExecuteAsync(\n        string input,\n        PipelineContext context,\n        CancellationToken cancellationToken)\n    {\n        // Each call returns a stream, which violates the single-output contract\n        return Task.FromResult(ParseNumbersAsync(input));\n    }\n\n    private static async IAsyncEnumerable<int> ParseNumbersAsync(string csv)\n    {\n        foreach (var token in csv.Split(',', StringSplitOptions.RemoveEmptyEntries))\n        {\n            yield return int.Parse(token, CultureInfo.InvariantCulture);\n            await Task.Yield();\n        }\n    }\n}\n"})}),"\n",(0,r.jsx)(n.h4,{id:"solution-use-istreamtransformnode",children:"Solution: Use IStreamTransformNode"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"// :heavy_check_mark: CORRECT: Using IStreamTransformNode for stream-based transformations\npublic class DataProcessor : IStreamTransformNode<InputData, OutputData>\n{\n    public async IAsyncEnumerable<OutputData> ExecuteAsync(\n        IAsyncEnumerable<InputData> input, \n        PipelineContext context, \n        CancellationToken cancellationToken)\n    {\n        // Process input stream and return output stream\n        await foreach (var item in input.WithCancellation(cancellationToken))\n        {\n            foreach (var result in ProcessInput(item))\n            {\n                yield return result;\n            }\n        }\n    }\n}\n"})}),"\n",(0,r.jsx)(n.h4,{id:"code-fix-np9210",children:"Code Fix (NP9210)"}),"\n",(0,r.jsx)(n.p,{children:"The analyzer provides a code fix that automatically:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Changes the base interface from ",(0,r.jsx)(n.code,{children:"ITransformNode<TIn, TOut>"})," to ",(0,r.jsx)(n.code,{children:"IStreamTransformNode<TIn, TOut>"})]}),"\n",(0,r.jsxs)(n.li,{children:["Updates the ",(0,r.jsx)(n.code,{children:"ExecuteAsync"})," method signature:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Changes the first parameter from ",(0,r.jsx)(n.code,{children:"TInput item"})," to ",(0,r.jsx)(n.code,{children:"IAsyncEnumerable<TInput> input"})]}),"\n",(0,r.jsxs)(n.li,{children:["Changes the return type to ",(0,r.jsx)(n.code,{children:"IAsyncEnumerable<TOutput>"})," (no ",(0,r.jsx)(n.code,{children:"Task"})," wrapper)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Adds the necessary using statement for ",(0,r.jsx)(n.code,{children:"System.Collections.Generic"})," if not present"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"when-to-use-each-interface",children:"When to Use Each Interface"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Scenario"}),(0,r.jsx)(n.th,{children:"Recommended Interface"}),(0,r.jsx)(n.th,{children:"Reason"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Single input \u2192 Single output"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"ITransformNode<TIn, TOut>"})}),(0,r.jsx)(n.td,{children:"Simple one-to-one transformation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Single input \u2192 Multiple outputs"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"IStreamTransformNode<TIn, TOut>"})}),(0,r.jsx)(n.td,{children:"Stream-based transformation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Stream input \u2192 Stream output"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"IStreamTransformNode<TIn, TOut>"})}),(0,r.jsx)(n.td,{children:"Optimized for streaming"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Batch processing"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"IStreamTransformNode<TIn, TOut>"})}),(0,r.jsx)(n.td,{children:"Better memory efficiency"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.em,{children:"Reasoning:"})," NP9210 highlights transform nodes that secretly produce streams so they can adopt ",(0,r.jsx)(n.code,{children:"IStreamTransformNode"})," and unlock stream-aware execution strategies."]}),"\n",(0,r.jsx)(n.h3,{id:"np9211-streamtransformnode-execution-strategy-mismatch",children:"NP9211: StreamTransformNode Execution Strategy Mismatch"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ID:"})," ",(0,r.jsx)(n.code,{children:"NP9211"}),"\n",(0,r.jsx)(n.strong,{children:"Severity:"})," Warning",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.strong,{children:"Category:"})," Design"]}),"\n",(0,r.jsxs)(n.p,{children:["This analyzer detects when a class implements ",(0,r.jsx)(n.code,{children:"IStreamTransformNode"})," but uses an execution strategy that doesn't implement ",(0,r.jsx)(n.code,{children:"IStreamExecutionStrategy"}),". It warns about potential performance issues from using non-stream-optimized execution strategies."]}),"\n",(0,r.jsx)(n.h4,{id:"why-this-matters-np9211",children:"Why This Matters (NP9211)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"IStreamTransformNode"})," is designed to work with execution strategies that implement ",(0,r.jsx)(n.code,{children:"IStreamExecutionStrategy"}),". Using a regular ",(0,r.jsx)(n.code,{children:"IExecutionStrategy"})," may result in:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Suboptimal Performance"}),": Non-stream strategies cannot take advantage of stream-specific optimizations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inefficient Memory Usage"}),": May buffer entire streams instead of processing them incrementally"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reduced Throughput"}),": Cannot leverage streaming parallelism and backpressure handling"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Poor Cancellation Support"}),": Stream strategies provide better cancellation propagation"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"problematic-patterns-np9211",children:"Problematic Patterns (NP9211)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"using System.Globalization;\n\n// :x: PROBLEM: Using non-stream execution strategy with IStreamTransformNode\npublic class StreamProcessor : IStreamTransformNode<InputData, OutputData>\n{\n    // NP9211: RegularExecutionStrategy doesn't implement IStreamExecutionStrategy\n    public IExecutionStrategy ExecutionStrategy { get; } = new RegularExecutionStrategy();\n    \n    public async IAsyncEnumerable<OutputData> ExecuteAsync(\n        IAsyncEnumerable<InputData> input, \n        PipelineContext context, \n        CancellationToken cancellationToken)\n    {\n        await foreach (var item in input.WithCancellation(cancellationToken))\n        {\n            yield return ProcessItem(item);\n        }\n    }\n}\n\n// :x: PROBLEM: Setting execution strategy in constructor\npublic class AnotherStreamProcessor : IStreamTransformNode<string, int>\n{\n    public IExecutionStrategy ExecutionStrategy { get; }\n    \n    public AnotherStreamProcessor()\n    {\n        // NP9211: SimpleExecutionStrategy doesn't implement IStreamExecutionStrategy\n        ExecutionStrategy = new SimpleExecutionStrategy();\n    }\n    \n    public async IAsyncEnumerable<int> ExecuteAsync(\n        IAsyncEnumerable<string> input, \n        PipelineContext context, \n        CancellationToken cancellationToken)\n    {\n        await foreach (var item in input.WithCancellation(cancellationToken))\n        {\n            yield return int.Parse(item, CultureInfo.InvariantCulture);\n        }\n    }\n}\n"})}),"\n",(0,r.jsx)(n.h4,{id:"solution-use-stream-optimized-execution-strategies",children:"Solution: Use Stream-Optimized Execution Strategies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"using System.Globalization;\n\n// :heavy_check_mark: CORRECT: Using BatchingExecutionStrategy with IStreamTransformNode\npublic class StreamProcessor : IStreamTransformNode<InputData, OutputData>\n{\n    // BatchingExecutionStrategy implements both IExecutionStrategy and IStreamExecutionStrategy\n    public IExecutionStrategy ExecutionStrategy { get; } = new BatchingExecutionStrategy(100, TimeSpan.FromSeconds(1));\n    \n    public async IAsyncEnumerable<OutputData> ExecuteAsync(\n        IAsyncEnumerable<InputData> input, \n        PipelineContext context, \n        CancellationToken cancellationToken)\n    {\n        await foreach (var item in input.WithCancellation(cancellationToken))\n        {\n            yield return ProcessItem(item);\n        }\n    }\n}\n\n// :heavy_check_mark: CORRECT: Using UnbatchingExecutionStrategy for individual item processing\npublic class ItemProcessor : IStreamTransformNode<string, int>\n{\n    // UnbatchingExecutionStrategy implements IStreamExecutionStrategy\n    public IExecutionStrategy ExecutionStrategy { get; } = new UnbatchingExecutionStrategy();\n    \n    public async IAsyncEnumerable<int> ExecuteAsync(\n        IAsyncEnumerable<string> input, \n        PipelineContext context, \n        CancellationToken cancellationToken)\n    {\n        await foreach (var item in input.WithCancellation(cancellationToken))\n        {\n            yield return int.Parse(item, CultureInfo.InvariantCulture);\n        }\n    }\n}\n"})}),"\n",(0,r.jsx)(n.h4,{id:"available-stream-execution-strategies",children:"Available Stream Execution Strategies"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Strategy"}),(0,r.jsx)(n.th,{children:"When to Use"}),(0,r.jsx)(n.th,{children:"Benefits"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"BatchingExecutionStrategy"})}),(0,r.jsx)(n.td,{children:"When you can process items in batches for better throughput"}),(0,r.jsx)(n.td,{children:"Reduces overhead, improves throughput"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"UnbatchingExecutionStrategy"})}),(0,r.jsx)(n.td,{children:"When items must be processed individually"}),(0,r.jsx)(n.td,{children:"Preserves item ordering, simpler processing"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["Custom strategy implementing ",(0,r.jsx)(n.code,{children:"IStreamExecutionStrategy"})]}),(0,r.jsx)(n.td,{children:"When you need specialized behavior"}),(0,r.jsx)(n.td,{children:"Tailored to specific use case"})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"code-fix-np9211",children:"Code Fix (NP9211)"}),"\n",(0,r.jsx)(n.p,{children:"The analyzer provides two code fix options:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Replace with BatchingExecutionStrategy"}),": Creates a new ",(0,r.jsx)(n.code,{children:"BatchingExecutionStrategy"})," with default parameters (batch size: 100, timeout: 1 second)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Replace with UnbatchingExecutionStrategy"}),": Creates a new ",(0,r.jsx)(n.code,{children:"UnbatchingExecutionStrategy"})," with no parameters"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"creating-custom-stream-execution-strategies",children:"Creating Custom Stream Execution Strategies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:"// :heavy_check_mark: CORRECT: Custom strategy implementing IExecutionStrategy, IStreamExecutionStrategy\npublic class CustomStreamExecutionStrategy : IExecutionStrategy, IStreamExecutionStrategy\n{\n    public async Task ExecuteAsync<TInput, TOutput>(\n        IAsyncEnumerable<TInput> input,\n        IAsyncEnumerable<TOutput> output,\n        Func<TInput, CancellationToken, Task<TOutput>> executeFunc,\n        PipelineContext context,\n        CancellationToken cancellationToken)\n    {\n        // Custom stream processing logic\n        await foreach (var item in input.WithCancellation(cancellationToken))\n        {\n            var result = await executeFunc(item, cancellationToken);\n            // Process result in stream-optimized way\n        }\n    }\n    \n    // Implement IExecutionStrategy members for compatibility\n    public async Task ExecuteAsync<TInput, TOutput>(\n        TInput input,\n        IAsyncEnumerable<TOutput> output,\n        Func<TInput, CancellationToken, Task<TOutput>> executeFunc,\n        PipelineContext context,\n        CancellationToken cancellationToken)\n    {\n        // Fallback implementation for non-stream scenarios\n        var result = await executeFunc(input, cancellationToken);\n        // Process single result\n    }\n}\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.em,{children:"Reasoning:"})," NP9211 ensures every ",(0,r.jsx)(n.code,{children:"IStreamTransformNode"})," pairs with a stream-aware execution strategy, preventing buffering and preserving streaming optimizations."]}),"\n",(0,r.jsx)(n.h2,{id:"why-data-processing-analyzers-matter",children:"Why Data Processing Analyzers Matter"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory Efficiency"}),": Streaming patterns use constant memory regardless of data size"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Better Performance"}),": Processing begins immediately without waiting for all data to load"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Scalability"}),": Can handle arbitrarily large datasets without running out of memory"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data Integrity"}),": All data flowing through pipelines is properly consumed"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Resource Utilization"}),": Lower GC pressure and better cache locality"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["Adjust analyzer severity in ",(0,r.jsx)(n.code,{children:".editorconfig"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ini",children:"# Treat non-streaming patterns as errors\ndotnet_diagnostic.NP9205.severity = error\n\n# Treat unconsumed input as errors\ndotnet_diagnostic.NP9302.severity = error\n\n# Treat StreamTransformNode suggestion as info\ndotnet_diagnostic.NP9210.severity = info\n\n# Treat StreamTransformNode execution strategy mismatch as warnings\ndotnet_diagnostic.NP9211.severity = warning\n"})}),"\n",(0,r.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/streaming-vs-buffering",children:"Streaming vs Buffering"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/data-pipes",children:"Data Pipes"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/architecture/performance-characteristics",children:"Performance Characteristics"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var i=t(6540);const r={},a=i.createContext(r);function s(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);