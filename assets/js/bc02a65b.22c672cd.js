"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[9632],{28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>l});var r=t(96540);const i={},s=r.createContext(i);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(s.Provider,{value:n},e.children)}},31068:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"core-concepts/resilience/retry-delay-monitoring","title":"Monitoring Retry Metrics","description":"Observe and measure retry behavior in production NPipeline systems","source":"@site/docs/core-concepts/resilience/retry-delay-monitoring.md","sourceDirName":"core-concepts/resilience","slug":"/core-concepts/resilience/retry-delay-monitoring","permalink":"/docs/core-concepts/resilience/retry-delay-monitoring","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8.6,"frontMatter":{"title":"Monitoring Retry Metrics","description":"Observe and measure retry behavior in production NPipeline systems","sidebar_position":8.6},"sidebar":"docsSidebar","previous":{"title":"Testing Retry Behavior","permalink":"/docs/core-concepts/resilience/retry-delay-testing"},"next":{"title":"Dead-Letter Queues","permalink":"/docs/core-concepts/resilience/dead-letter-queues"}}');var i=t(74848),s=t(28453);const a={title:"Monitoring Retry Metrics",description:"Observe and measure retry behavior in production NPipeline systems",sidebar_position:8.6},l="Monitoring Retry Metrics",o={},c=[{value:"Key Metrics to Track",id:"key-metrics-to-track",level:2},{value:"Retry Rate",id:"retry-rate",level:3},{value:"Retry Counts",id:"retry-counts",level:3},{value:"Delay Analysis",id:"delay-analysis",level:3},{value:"Basic Metrics Collection",id:"basic-metrics-collection",level:2},{value:"Simple Retry Collector",id:"simple-retry-collector",level:3},{value:"Structured Logging",id:"structured-logging",level:2},{value:"Aggregated Metrics",id:"aggregated-metrics",level:2},{value:"Strategy Performance Comparison",id:"strategy-performance-comparison",level:2},{value:"Production Monitoring Dashboard",id:"production-monitoring-dashboard",level:2},{value:"Alerts and Thresholds",id:"alerts-and-thresholds",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Related Topics",id:"related-topics",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"monitoring-retry-metrics",children:"Monitoring Retry Metrics"})}),"\n",(0,i.jsx)(n.p,{children:"Production systems require visibility into retry behavior. Monitor metrics to understand failure patterns, tune retry strategies, and detect emerging issues."}),"\n",(0,i.jsx)(n.h2,{id:"key-metrics-to-track",children:"Key Metrics to Track"}),"\n",(0,i.jsx)(n.h3,{id:"retry-rate",children:"Retry Rate"}),"\n",(0,i.jsx)(n.p,{children:"Percentage of operations that required at least one retry:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:"public class RetryRateMetric\n{\n    public int TotalOperations { get; set; }\n    public int OperationsWithRetry { get; set; }\n    \n    public double RetryRate => \n        (double)OperationsWithRetry / TotalOperations;\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Interpretation:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"0-5%: Healthy (occasional transient failures)"}),"\n",(0,i.jsx)(n.li,{children:"5-10%: Watch (increasing trend concerning)"}),"\n",(0,i.jsx)(n.li,{children:"10%+: Problem (systematic issues likely)"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"retry-counts",children:"Retry Counts"}),"\n",(0,i.jsx)(n.p,{children:"Distribution of retry attempts:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:"public class RetryCountMetrics\n{\n    public Dictionary<int, int> AttemptDistribution { get; set; }\n    \n    public double AverageRetries { get; set; }\n    public int MaxRetries { get; set; }\n    public int SuccessOnFirstAttempt { get; set; }\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Useful for:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Tuning max retry limits"}),"\n",(0,i.jsx)(n.li,{children:"Identifying systematic issues"}),"\n",(0,i.jsx)(n.li,{children:"Capacity planning"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"delay-analysis",children:"Delay Analysis"}),"\n",(0,i.jsx)(n.p,{children:"Time spent waiting between retries:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:"public class DelayMetrics\n{\n    public TimeSpan TotalRetryTime { get; set; }\n    public TimeSpan AverageDelay { get; set; }\n    public TimeSpan MaxDelay { get; set; }\n    public TimeSpan MinDelay { get; set; }\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Monitor for:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Delays longer than configured max"}),"\n",(0,i.jsx)(n.li,{children:"Increasing delay times (hint of degradation)"}),"\n",(0,i.jsx)(n.li,{children:"Consistent patterns vs. random variations"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"basic-metrics-collection",children:"Basic Metrics Collection"}),"\n",(0,i.jsx)(n.h3,{id:"simple-retry-collector",children:"Simple Retry Collector"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:'public class RetryMetricsCollector\n{\n    private readonly ConcurrentDictionary<string, RetryNodeMetrics> _nodeMetrics = new();\n    \n    public void RecordAttempt(string nodeId, int attemptNumber, TimeSpan delay)\n    {\n        var nodeMetrics = _nodeMetrics.GetOrAdd(\n            nodeId,\n            _ => new RetryNodeMetrics());\n\n        nodeMetrics.TotalAttempts++;\n        nodeMetrics.DelayHistory.Add(delay);\n        \n        if (attemptNumber == 0)\n            nodeMetrics.FirstAttemptCount++;\n    }\n\n    public RetryNodeMetrics GetMetrics(string nodeId)\n    {\n        return _nodeMetrics.TryGetValue(nodeId, out var metrics)\n            ? metrics\n            : null;\n    }\n\n    public void PrintReport()\n    {\n        foreach (var (nodeId, metrics) in _nodeMetrics)\n        {\n            var retryRate = 1.0 - (metrics.FirstAttemptCount / (double)metrics.TotalAttempts);\n            var avgDelay = metrics.DelayHistory.Count > 0\n                ? TimeSpan.FromMilliseconds(\n                    metrics.DelayHistory.Average(d => d.TotalMilliseconds))\n                : TimeSpan.Zero;\n\n            Console.WriteLine($"Node: {nodeId}");\n            Console.WriteLine($"  Total attempts: {metrics.TotalAttempts}");\n            Console.WriteLine($"  Retry rate: {retryRate:P}");\n            Console.WriteLine($"  Average delay: {avgDelay.TotalMilliseconds:F2}ms");\n        }\n    }\n}\n\npublic class RetryNodeMetrics\n{\n    public int TotalAttempts { get; set; }\n    public int FirstAttemptCount { get; set; }\n    public List<TimeSpan> DelayHistory { get; } = new();\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"structured-logging",children:"Structured Logging"}),"\n",(0,i.jsx)(n.p,{children:"Log retry events with full context for analysis:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:'public class RetryEventLogger\n{\n    private readonly ILogger<RetryEventLogger> _logger;\n\n    public async Task LogRetryAsync(\n        string nodeId,\n        int attempt,\n        Exception error,\n        TimeSpan delay,\n        PipelineContext context)\n    {\n        _logger.LogWarning(\n            new EventId(1001, "NodeRetry"),\n            "Node {NodeId} retry attempt {Attempt}: " +\n            "Error={ErrorType}, Message={ErrorMessage}, " +\n            "NextDelay={NextDelayMs}ms",\n            nodeId,\n            attempt,\n            error.GetType().Name,\n            error.Message,\n            delay.TotalMilliseconds);\n    }\n\n    public void LogRetryExhausted(string nodeId, int maxRetries, Exception finalError)\n    {\n        _logger.LogError(\n            new EventId(1002, "RetriesExhausted"),\n            "Node {NodeId} exhausted {MaxRetries} retries: {Error}",\n            nodeId,\n            maxRetries,\n            finalError.Message);\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"aggregated-metrics",children:"Aggregated Metrics"}),"\n",(0,i.jsx)(n.p,{children:"Collect metrics by error type and time window:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:'public class AggregatedRetryMetrics\n{\n    private readonly ConcurrentDictionary<string, ErrorTypeMetrics> _byErrorType = new();\n    private readonly ConcurrentDictionary<string, TimeWindowMetrics> _byTimeWindow = new();\n\n    public void RecordRetry(string errorType, int attemptNumber, TimeSpan delay)\n    {\n        // By error type\n        var errorMetrics = _byErrorType.GetOrAdd(errorType, _ => new ErrorTypeMetrics());\n        errorMetrics.RetryCount++;\n        errorMetrics.Attempts.Add(attemptNumber);\n\n        // By time window\n        var window = GetTimeWindow();\n        var windowMetrics = _byTimeWindow.GetOrAdd(window, _ => new TimeWindowMetrics());\n        windowMetrics.RetryCount++;\n    }\n\n    public void PrintErrorTypeReport()\n    {\n        foreach (var (errorType, metrics) in _byErrorType.OrderByDescending(x => x.Value.RetryCount))\n        {\n            var avgAttempt = metrics.Attempts.Average();\n            Console.WriteLine($"{errorType}: {metrics.RetryCount} retries, " +\n                            $"avg attempt: {avgAttempt:F1}");\n        }\n    }\n\n    private string GetTimeWindow()\n    {\n        var now = DateTime.UtcNow;\n        return $"{now:yyyy-MM-dd HH:00}"; // Hourly buckets\n    }\n\n    private class ErrorTypeMetrics\n    {\n        public int RetryCount { get; set; }\n        public List<int> Attempts { get; } = new();\n    }\n\n    private class TimeWindowMetrics\n    {\n        public int RetryCount { get; set; }\n        public DateTime WindowStart { get; set; }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"strategy-performance-comparison",children:"Strategy Performance Comparison"}),"\n",(0,i.jsx)(n.p,{children:"Compare actual retry behavior across strategies:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:'public class StrategyPerformanceAnalyzer\n{\n    private readonly Dictionary<string, StrategyMetrics> _strategyMetrics = new();\n\n    public void RecordStrategyUsage(\n        string strategyName,\n        int attemptNumber,\n        TimeSpan actualDelay,\n        TimeSpan configuredDelay)\n    {\n        var metrics = _strategyMetrics.GetOrAdd(strategyName, _ => new StrategyMetrics());\n        \n        metrics.TotalUsages++;\n        metrics.AverageDelay = \n            (metrics.AverageDelay * (metrics.TotalUsages - 1) + actualDelay.TotalMilliseconds) \n            / metrics.TotalUsages;\n        \n        metrics.MaxDelay = Math.Max(metrics.MaxDelay, actualDelay.TotalMilliseconds);\n        metrics.DeviationSum += Math.Abs(\n            actualDelay.TotalMilliseconds - configuredDelay.TotalMilliseconds);\n    }\n\n    public void PrintComparison()\n    {\n        Console.WriteLine("Strategy Performance Comparison:");\n        foreach (var (strategy, metrics) in _strategyMetrics)\n        {\n            var avgDeviation = metrics.DeviationSum / metrics.TotalUsages;\n            Console.WriteLine($"  {strategy}:");\n            Console.WriteLine($"    - Uses: {metrics.TotalUsages}");\n            Console.WriteLine($"    - Avg delay: {metrics.AverageDelay:F2}ms");\n            Console.WriteLine($"    - Max delay: {metrics.MaxDelay:F2}ms");\n            Console.WriteLine($"    - Avg deviation: {avgDeviation:F2}ms");\n        }\n    }\n\n    private class StrategyMetrics\n    {\n        public int TotalUsages { get; set; }\n        public double AverageDelay { get; set; }\n        public double MaxDelay { get; set; }\n        public double DeviationSum { get; set; }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"production-monitoring-dashboard",children:"Production Monitoring Dashboard"}),"\n",(0,i.jsx)(n.p,{children:"Example metrics for a monitoring dashboard:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:'public class RetryDashboardMetrics\n{\n    public class HealthIndicators\n    {\n        public double RetryRatePercentage { get; set; } // 0-100\n        public int HealthScore { get; set; } // 0-100, 100 = healthy\n        \n        public string Status => HealthScore switch\n        {\n            >= 90 => "Healthy",\n            >= 70 => "Warning",\n            _ => "Critical"\n        };\n    }\n\n    public class TimeSeriesData\n    {\n        public DateTime Timestamp { get; set; }\n        public int RetryCount { get; set; }\n        public double AverageDelayMs { get; set; }\n        public int MaxConsecutiveRetries { get; set; }\n    }\n\n    public class NodeSummary\n    {\n        public string NodeName { get; set; }\n        public int TotalOperations { get; set; }\n        public int FailedOperations { get; set; }\n        public double SuccessRate { get; set; }\n        public int AverageRetriesPerFailure { get; set; }\n    }\n}\n\n// Usage\npublic class DashboardPublisher\n{\n    public async Task PublishMetricsAsync(RetryDashboardMetrics metrics)\n    {\n        var health = new RetryDashboardMetrics.HealthIndicators\n        {\n            RetryRatePercentage = 3.5, // 3.5% of operations retried\n            HealthScore = 92 // Healthy\n        };\n\n        // Publish to monitoring system (Prometheus, AppInsights, etc.)\n        await PublishToMonitoringAsync("pipeline.retry.health", health);\n    }\n\n    private async Task PublishToMonitoringAsync(string metric, object value)\n    {\n        // Implementation depends on monitoring platform\n        await Task.CompletedTask;\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"alerts-and-thresholds",children:"Alerts and Thresholds"}),"\n",(0,i.jsx)(n.p,{children:"Define alerting rules:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-csharp",children:'public class RetryAlertingPolicy\n{\n    private readonly ILogger<RetryAlertingPolicy> _logger;\n\n    public void EvaluateAndAlert(RetryMetricsSnapshot snapshot)\n    {\n        // Alert: High retry rate\n        if (snapshot.RetryRatePercentage > 10)\n        {\n            _logger.LogError("Alert: High retry rate {RetryRate}% (threshold: 10%)",\n                snapshot.RetryRatePercentage);\n        }\n\n        // Alert: Long delays\n        if (snapshot.AverageDelayMs > 5000)\n        {\n            _logger.LogWarning("Alert: Average delay {DelayMs}ms exceeds threshold",\n                snapshot.AverageDelayMs);\n        }\n\n        // Alert: Max retries consistently hit\n        if (snapshot.ExhaustedRetriesPercentage > 5)\n        {\n            _logger.LogError("Alert: {Percent}% of retries exhausted",\n                snapshot.ExhaustedRetriesPercentage);\n        }\n\n        // Alert: Increasing trend\n        if (snapshot.RetryRateTrend > 0.2) // 20% increase\n        {\n            _logger.LogWarning("Alert: Retry rate increasing {TrendPercent}%",\n                snapshot.RetryRateTrend * 100);\n        }\n    }\n\n    public class RetryMetricsSnapshot\n    {\n        public double RetryRatePercentage { get; set; }\n        public double AverageDelayMs { get; set; }\n        public double ExhaustedRetriesPercentage { get; set; }\n        public double RetryRateTrend { get; set; }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Track retry rate by node"}),": Identify problematic nodes"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitor delay distributions"}),": Detect strategy mismatches"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Set up alerts"}),": Act on rising retry rates"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Compare strategies"}),": Measure real-world performance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Log error types"}),": Understand failure patterns"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use time windows"}),": Detect temporal patterns"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dashboard visibility"}),": Make metrics accessible to team"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"related-topics",children:"Related Topics"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/core-concepts/resilience/retries",children:"Retry Configuration"})," - Configuration options"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/core-concepts/resilience/retry-delays",children:"Retry Delays"})," - Strategy overview"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/core-concepts/resilience/retry-delay-exponential",children:"Exponential Backoff"})," - Exponential strategy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/core-concepts/resilience/retry-delay-linear",children:"Linear Backoff"})," - Linear strategy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/core-concepts/resilience/retry-delay-fixed",children:"Fixed Delay"})," - Fixed delay strategy"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/core-concepts/resilience/retry-delay-advanced",children:"Advanced Patterns"})," - Custom strategies"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/core-concepts/resilience/retry-delay-testing",children:"Testing Retries"})," - Testing strategies"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);