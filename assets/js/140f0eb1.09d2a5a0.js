"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[328],{7872:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"extensions/parallelism","title":"Parallelism","description":"Enhance your NPipeline\'s performance by leveraging parallel processing capabilities.","source":"@site/docs/extensions/parallelism.md","sourceDirName":"extensions","slug":"/extensions/parallelism","permalink":"/docs/extensions/parallelism","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Parallelism","description":"Enhance your NPipeline\'s performance by leveraging parallel processing capabilities.","sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Dependency Injection","permalink":"/docs/extensions/dependency-injection"},"next":{"title":"Testing Extensions","permalink":"/docs/extensions/testing"}}');var l=r(74848),s=r(28453);const a={title:"Parallelism",description:"Enhance your NPipeline's performance by leveraging parallel processing capabilities.",sidebar_position:2},t="Parallelism",o={},d=[{value:"Understanding Parallelism in NPipeline",id:"understanding-parallelism-in-npipeline",level:2},{value:"<code>NPipeline.Extensions.Parallelism</code>",id:"npipelineextensionsparallelism",level:2},{value:"Important: Thread Safety",id:"important-thread-safety",level:3},{value:"Example: Parallel Transform",id:"example-parallel-transform",level:3},{value:"Non-Ordered Parallel Execution for Maximum Throughput",id:"non-ordered-parallel-execution-for-maximum-throughput",level:2},{value:"Example: Non-Ordered Parallel Processing",id:"example-non-ordered-parallel-processing",level:3},{value:"When to Use Non-Ordered Execution",id:"when-to-use-non-ordered-execution",level:3},{value:"Trade-offs",id:"trade-offs",level:3},{value:"Advanced Parallel Options",id:"advanced-parallel-options",level:2},{value:"Metrics Configuration",id:"metrics-configuration",level:3},{value:"Queue Policies",id:"queue-policies",level:3},{value:"Default Queue Length",id:"default-queue-length",level:3},{value:"Thread Safety in Parallel Execution",id:"thread-safety-in-parallel-execution",level:2},{value:"Key Principles",id:"key-principles",level:3},{value:"Three Approaches to Shared State",id:"three-approaches-to-shared-state",level:3},{value:"1. IPipelineStateManager (Recommended)",id:"1-ipipelinestatemanager-recommended",level:4},{value:"2. Node-Level Synchronization",id:"2-node-level-synchronization",level:4},{value:"3. Atomic Operations for Simple Counters",id:"3-atomic-operations-for-simple-counters",level:4},{value:"Thread Safety DO&#39;s",id:"thread-safety-dos",level:3},{value:"Thread Safety DON&#39;Ts",id:"thread-safety-donts",level:3},{value:"Parallel Execution Configuration Methods",id:"parallel-execution-configuration-methods",level:2},{value:"Preset API: Using Workload Type Presets",id:"preset-api-using-workload-type-presets",level:3},{value:"Workload Type Presets",id:"workload-type-presets",level:3},{value:"<code>ParallelWorkloadType.General</code> (Default)",id:"parallelworkloadtypegeneral-default",level:4},{value:"<code>ParallelWorkloadType.CpuBound</code>",id:"parallelworkloadtypecpubound",level:4},{value:"<code>ParallelWorkloadType.IoBound</code>",id:"parallelworkloadtypeiobound",level:4},{value:"<code>ParallelWorkloadType.NetworkBound</code>",id:"parallelworkloadtypenetworkbound",level:4},{value:"Builder API: Fine-Grained Control with ParallelOptionsBuilder",id:"builder-api-fine-grained-control-with-paralleloptionsbuilder",level:3},{value:"Comparison: Configuration Methods",id:"comparison-configuration-methods",level:3},{value:"When to Use Each Approach",id:"when-to-use-each-approach",level:3},{value:"Example: Full Pipeline with Simplified API",id:"example-full-pipeline-with-simplified-api",level:3},{value:"Validation of Parallel Configuration",id:"validation-of-parallel-configuration",level:2},{value:"Automatic Validation",id:"automatic-validation",level:3},{value:"Validation in Action",id:"validation-in-action",level:3},{value:"Quick Fix Examples",id:"quick-fix-examples",level:3},{value:"Considerations for Parallelism",id:"considerations-for-parallelism",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"parallelism",children:"Parallelism"})}),"\n",(0,l.jsxs)(n.p,{children:["NPipeline is designed for high performance, and a key aspect of this is its ability to execute parts of your pipeline in parallel. The ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/NPipeline.Extensions.Parallelism.csproj",children:(0,l.jsx)(n.code,{children:"NPipeline.Extensions.Parallelism"})})," package provides tools and extensions to easily introduce parallel processing into your data flows, allowing you to scale out your computations and maximize throughput."]}),"\n",(0,l.jsx)(n.h2,{id:"understanding-parallelism-in-npipeline",children:"Understanding Parallelism in NPipeline"}),"\n",(0,l.jsx)(n.p,{children:"Parallelism in NPipeline typically means processing multiple data items concurrently, either within a single node or across multiple independent branches of a pipeline. This is distinct from concurrency, which is about managing multiple tasks that may or may not run simultaneously."}),"\n",(0,l.jsx)(n.h2,{id:"npipelineextensionsparallelism",children:(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/NPipeline.Extensions.Parallelism.csproj",children:(0,l.jsx)(n.code,{children:"NPipeline.Extensions.Parallelism"})})}),"\n",(0,l.jsxs)(n.p,{children:["This extension package provides the ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/ParallelExecutionStrategy.cs",children:(0,l.jsx)(n.code,{children:"ParallelExecutionStrategy"})})," class and builder extensions to enable and manage parallel execution."]}),"\n",(0,l.jsx)(n.h3,{id:"important-thread-safety",children:"Important: Thread Safety"}),"\n",(0,l.jsxs)(n.p,{children:["When using parallel execution, it's critical to understand NPipeline's thread-safety model. Each worker thread processes ",(0,l.jsx)(n.strong,{children:"independent data items"}),"\u2014the ",(0,l.jsx)(n.code,{children:"PipelineContext"})," itself is not shared across threads. However, if your nodes need to access shared state during parallel execution, you must use thread-safe mechanisms."]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsxs)(n.strong,{children:["See ",(0,l.jsx)(n.a,{href:"/docs/core-concepts/thread-safety",children:"Thread Safety Guidelines"})," for detailed guidance on:"]})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Safe patterns for accessing context during parallel execution"}),"\n",(0,l.jsxs)(n.li,{children:["Using ",(0,l.jsx)(n.code,{children:"IPipelineStateManager"})," for shared state"]}),"\n",(0,l.jsx)(n.li,{children:"Node-level synchronization strategies"}),"\n",(0,l.jsx)(n.li,{children:"When and how to use atomic operations"}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"This is essential reading if your parallel nodes interact with shared state."}),"\n",(0,l.jsx)(n.h3,{id:"example-parallel-transform",children:"Example: Parallel Transform"}),"\n",(0,l.jsx)(n.p,{children:"Imagine you have a computationally intensive transformation that can be applied independently to each item. You can use parallel execution to process multiple items simultaneously."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:'using NPipeline.Extensions.Parallelism;\r\nusing NPipeline.Extensions.Testing;\r\nusing NPipeline.Execution;\r\nusing NPipeline.Nodes;\r\n\r\npublic sealed class IntensiveTransform : TransformNode<int, int>\r\n{\r\n    public override async Task<int> ExecuteAsync(\r\n        int item,\r\n        PipelineContext context,\r\n        CancellationToken cancellationToken)\r\n    {\r\n        var logger = context.LoggerFactory.CreateLogger("IntensiveTransform");\r\n        logger.Log(NPipeline.Observability.Logging.LogLevel.Information,\r\n            $"Processing item {item} on Thread {Environment.CurrentManagedThreadId}");\r\n        await Task.Delay(100, cancellationToken); // Simulate intensive work\r\n        return item * 2;\r\n    }\r\n}\r\n\r\npublic sealed class ParallelPipeline : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var source = builder.AddInMemorySource<int>();\r\n        var transform = builder.AddTransform<IntensiveTransform, int, int>();\r\n        var sink = builder.AddInMemorySink<int>();\r\n\r\n        builder.Connect(source, transform);\r\n        builder.Connect(transform, sink);\r\n\r\n        // Configure parallel execution for the transform\r\n        builder.WithParallelOptions(transform,\r\n            new ParallelOptions { MaxDegreeOfParallelism = 4 });\r\n\r\n        // Set execution strategy to ParallelExecutionStrategy\r\n        transform.NodeDefinition.ExecutionConfig.ExecutionStrategy = new ParallelExecutionStrategy();\r\n    }\r\n}\r\n\r\npublic static class Program\r\n{\r\n    public static async Task Main(string[] args)\r\n    {\r\n        // Set up test data\r\n        var testData = new[] { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };\r\n        var context = new PipelineContext();\r\n        context.SetSourceData(testData);\r\n\r\n        Console.WriteLine("Starting parallel pipeline...");\r\n        var runner = PipelineRunner.Create();\r\n        await runner.RunAsync<ParallelPipeline>(context);\r\n        Console.WriteLine("Parallel pipeline finished.");\r\n    }\r\n}\n'})}),"\n",(0,l.jsx)(n.p,{children:"In this example, we:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Use ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/ParallelOptions.cs:47",children:(0,l.jsx)(n.code,{children:"WithParallelOptions(transform, new ParallelOptions { MaxDegreeOfParallelism = 4 })"})})," to configure parallel execution options for the transform"]}),"\n",(0,l.jsxs)(n.li,{children:["Set the ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline/Graph/NodeDefinition.cs",children:(0,l.jsx)(n.code,{children:"ExecutionStrategy"})})," property to ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/ParallelExecutionStrategy.cs",children:(0,l.jsx)(n.code,{children:"ParallelExecutionStrategy"})})," to enable parallel processing"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"non-ordered-parallel-execution-for-maximum-throughput",children:"Non-Ordered Parallel Execution for Maximum Throughput"}),"\n",(0,l.jsx)(n.p,{children:"By default, NPipeline preserves the order of items even when processing them in parallel. While this ensures predictable output, it can introduce overhead that reduces throughput. When the order of output items is not important for your use case, you can configure parallel execution to not preserve order, which can significantly increase throughput."}),"\n",(0,l.jsx)(n.h3,{id:"example-non-ordered-parallel-processing",children:"Example: Non-Ordered Parallel Processing"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:'using NPipeline.Extensions.Parallelism;\r\nusing NPipeline.Extensions.Testing;\r\nusing NPipeline.Execution;\r\nusing NPipeline.Nodes;\r\nusing NPipeline.Pipeline;\r\n\r\npublic sealed class IntensiveTransform : TransformNode<int, int>\r\n{\r\n    public override async Task<int> ExecuteAsync(\r\n        int item,\r\n        PipelineContext context,\r\n        CancellationToken cancellationToken)\r\n    {\r\n        var logger = context.LoggerFactory.CreateLogger("IntensiveTransform");\r\n        logger.Log(NPipeline.Observability.Logging.LogLevel.Information,\r\n            $"Processing item {item} on Thread {Environment.CurrentManagedThreadId}");\r\n        await Task.Delay(new Random().Next(50, 150), cancellationToken); // Simulate variable work\r\n        return item * 2;\r\n    }\r\n}\r\n\r\npublic sealed class NonOrderedParallelPipeline : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var source = builder.AddInMemorySource<int>();\r\n        var transform = builder.AddTransform<IntensiveTransform, int, int>();\r\n        var sink = builder.AddInMemorySink<int>();\r\n\r\n        builder.Connect(source, transform);\r\n        builder.Connect(transform, sink);\r\n\r\n        // Configure parallel execution with non-ordered output for maximum throughput\r\n        builder.WithParallelOptions(transform,\r\n            new ParallelOptions\r\n            {\r\n                MaxDegreeOfParallelism = 4,\r\n                PreserveOrdering = false  // Disable ordering to maximize throughput\r\n            });\r\n\r\n        // Set execution strategy to ParallelExecutionStrategy\r\n        transform.NodeDefinition.ExecutionConfig.ExecutionStrategy = new ParallelExecutionStrategy();\r\n    }\r\n}\r\n\r\npublic static class Program\r\n{\r\n    public static async Task Main(string[] args)\r\n    {\r\n        // Set up test data\r\n        var testData = new[] { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };\r\n        var context = new PipelineContext();\r\n        context.SetSourceData(testData);\r\n\r\n        Console.WriteLine("Starting non-ordered parallel pipeline...");\r\n        var runner = PipelineRunner.Create();\r\n        await runner.RunAsync<NonOrderedParallelPipeline>(context);\r\n        Console.WriteLine("Non-ordered parallel pipeline finished.");\r\n    }\r\n}\n'})}),"\n",(0,l.jsxs)(n.p,{children:["In this example, we explicitly set ",(0,l.jsx)(n.code,{children:"PreserveOrdering = false"})," in the ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/ParallelOptions.cs:34",children:(0,l.jsx)(n.code,{children:"ParallelOptions"})}),". This configuration:"]}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Allows items to be emitted as soon as they are processed, without waiting for slower items"}),"\n",(0,l.jsx)(n.li,{children:"Eliminates the overhead of tracking and reordering items"}),"\n",(0,l.jsx)(n.li,{children:"Can significantly increase throughput, especially when processing times vary widely"}),"\n",(0,l.jsx)(n.li,{children:"Results in output that may not match the input order"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"when-to-use-non-ordered-execution",children:"When to Use Non-Ordered Execution"}),"\n",(0,l.jsxs)(n.p,{children:["Consider using ",(0,l.jsx)(n.code,{children:"PreserveOrdering = false"})," when:"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Order is irrelevant"}),": Your downstream processing doesn't depend on the input order"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Maximum throughput is critical"}),": You need to process as many items as possible per unit of time"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Processing times vary significantly"}),": Some items take much longer to process than others"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"You're aggregating results"}),": You're collecting statistics or aggregating data where order doesn't matter"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"trade-offs",children:"Trade-offs"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Aspect"}),(0,l.jsx)(n.th,{children:"PreserveOrdering: true (Default)"}),(0,l.jsx)(n.th,{children:"PreserveOrdering: false"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Throughput"})}),(0,l.jsx)(n.td,{children:"Good"}),(0,l.jsx)(n.td,{children:"Excellent"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Output Order"})}),(0,l.jsx)(n.td,{children:"Matches input order"}),(0,l.jsx)(n.td,{children:"May be out of order"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Memory Usage"})}),(0,l.jsx)(n.td,{children:"Higher (needs to buffer)"}),(0,l.jsx)(n.td,{children:"Lower"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Latency"})}),(0,l.jsx)(n.td,{children:"Higher (waits for slow items)"}),(0,l.jsx)(n.td,{children:"Lower (emits immediately)"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Use Case"})}),(0,l.jsx)(n.td,{children:"Order-sensitive processing"}),(0,l.jsx)(n.td,{children:"Maximum throughput scenarios"})]})]})]}),"\n",(0,l.jsx)(n.h2,{id:"advanced-parallel-options",children:"Advanced Parallel Options"}),"\n",(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/ParallelOptions.cs:34",children:(0,l.jsx)(n.code,{children:"ParallelOptions"})})," class provides additional configuration options for fine-tuning parallel execution:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"var options = new ParallelOptions\r\n{\r\n    MaxDegreeOfParallelism = 8,           // Maximum concurrent operations\r\n    MaxQueueLength = 1000,               // Bounded input queue for backpressure\r\n    QueuePolicy = BoundedQueuePolicy.Block, // Behavior when queue is full\r\n    OutputBufferCapacity = 500,           // Bounded output buffer\r\n    PreserveOrdering = true,              // Whether to preserve input order\r\n    MetricsInterval = TimeSpan.FromSeconds(1) // Interval for metrics emission\r\n};\n"})}),"\n",(0,l.jsx)(n.h3,{id:"metrics-configuration",children:"Metrics Configuration"}),"\n",(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/ParallelOptions.cs:45",children:(0,l.jsx)(n.code,{children:"MetricsInterval"})})," property controls how frequently parallel execution metrics are emitted:"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Default value"}),": 1 second"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Purpose"}),": Determines the interval at which performance metrics (throughput, queue depth, worker utilization) are collected and reported"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"When to adjust"}),":","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Decrease for more granular monitoring in high-frequency trading or real-time analytics"}),"\n",(0,l.jsx)(n.li,{children:"Increase to reduce monitoring overhead in batch processing scenarios"}),"\n",(0,l.jsx)(n.li,{children:"Set to longer intervals when using custom metrics collection systems that batch data"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"// Example: Fine-grained monitoring for real-time systems\r\nvar realtimeOptions = new ParallelOptions\r\n{\r\n    MaxDegreeOfParallelism = 4,\r\n    MetricsInterval = TimeSpan.FromMilliseconds(500) // Emit metrics every 500ms\r\n};\r\n\r\n// Example: Reduced monitoring overhead for batch processing\r\nvar batchOptions = new ParallelOptions\r\n{\r\n    MaxDegreeOfParallelism = 8,\r\n    MetricsInterval = TimeSpan.FromSeconds(10) // Emit metrics every 10 seconds\r\n};\n"})}),"\n",(0,l.jsx)(n.h3,{id:"queue-policies",children:"Queue Policies"}),"\n",(0,l.jsxs)(n.p,{children:["When ",(0,l.jsx)(n.code,{children:"MaxQueueLength"})," is specified, you can control the behavior when the queue reaches its capacity:"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.code,{children:"BoundedQueuePolicy.Block"})}),": Wait until space becomes available (default)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.code,{children:"BoundedQueuePolicy.DropNewest"})}),": Drop the incoming item"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.code,{children:"BoundedQueuePolicy.DropOldest"})}),": Remove the oldest item to make space"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"default-queue-length",children:"Default Queue Length"}),"\n",(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.a,{href:"../../../src/NPipeline.Extensions.Parallelism/ParallelNodeConfigurationExtensions.cs:27",children:(0,l.jsx)(n.code,{children:"ParallelNodeConfigurationExtensions.DefaultQueueLength"})})," constant defines the default queue length for bounded parallel execution strategies:"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Default value"}),": 100 items"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Applied to"}),": Drop-oldest and drop-newest parallel strategies when no explicit queue length is provided"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Rationale"}),": This value balances memory usage with throughput, providing sufficient buffer for most workloads while preventing excessive memory consumption"]}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"// Example: Using default queue length (100)\r\nvar transform = builder.AddTransform<MyTransform, int, string>()\r\n    .WithDropOldestParallelism(builder, maxDegreeOfParallelism: 4);\r\n    // Uses DefaultQueueLength of 100 automatically\r\n\r\n// Example: Custom queue length for high-volume scenarios\r\nvar highVolumeTransform = builder.AddTransform<MyTransform, int, string>()\r\n    .WithDropOldestParallelism(\r\n        builder, \r\n        maxDegreeOfParallelism: 4,\r\n        maxQueueLength: 1000); // Override default with larger queue\n"})}),"\n",(0,l.jsx)(n.p,{children:"When to adjust the default queue length:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Increase"})," for high-throughput scenarios with bursty input patterns"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Decrease"})," for memory-constrained environments or when processing large items"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Keep default"})," for most typical workloads where balanced performance is desired"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"thread-safety-in-parallel-execution",children:"Thread Safety in Parallel Execution"}),"\n",(0,l.jsx)(n.p,{children:"One of the most important aspects of parallel processing is understanding and managing thread safety correctly. NPipeline's parallel execution model is designed to be safe by default, but requires careful attention when accessing shared state."}),"\n",(0,l.jsx)(n.h3,{id:"key-principles",children:"Key Principles"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Independent Item Processing:"})," Each worker thread processes a different data item. The core processing is inherently thread-safe because workers operate on independent data."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"// SAFE: Each thread processes different items independently\r\npublic override async ValueTask<TOut> TransformAsync(\r\n    TIn input,                    // Each thread gets a different item\r\n    PipelineContext context,\r\n    CancellationToken ct)\r\n{\r\n    // Safe to process input without synchronization\r\n    return await ProcessItemAsync(input, ct);\r\n}\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Shared State is NOT Thread-Safe:"})," The ",(0,l.jsx)(n.code,{children:"PipelineContext"})," dictionaries (Items, Parameters, Properties) are NOT thread-safe. If multiple worker threads need to access or modify shared state, you must use explicit synchronization."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:'// UNSAFE: Multiple threads accessing context.Items without synchronization\r\ncontext.Items["counter"] = (int)context.Items.GetValueOrDefault("counter", 0) + 1;\r\n\r\n// SAFE: Use IPipelineStateManager for thread-safe shared state\r\nvar stateManager = context.StateManager;\r\nif (stateManager != null)\r\n{\r\n    await stateManager.IncrementCounterAsync("counter", ct);\r\n}\n'})}),"\n",(0,l.jsx)(n.h3,{id:"three-approaches-to-shared-state",children:"Three Approaches to Shared State"}),"\n",(0,l.jsxs)(n.p,{children:["See ",(0,l.jsx)(n.a,{href:"/docs/core-concepts/thread-safety",children:"Thread Safety Guidelines"})," for comprehensive guidance, but here's a quick summary for parallel scenarios:"]}),"\n",(0,l.jsx)(n.h4,{id:"1-ipipelinestatemanager-recommended",children:"1. IPipelineStateManager (Recommended)"}),"\n",(0,l.jsx)(n.p,{children:"For complex shared state that needs coordination across parallel workers:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:'public override async ValueTask<TOut> TransformAsync(\r\n    TIn input,\r\n    PipelineContext context,\r\n    CancellationToken ct)\r\n{\r\n    var result = ProcessItem(input);\r\n    \r\n    // Thread-safe state update via state manager\r\n    var stateManager = context.StateManager;\r\n    if (stateManager != null)\r\n    {\r\n        await stateManager.RecordMetricAsync("items_processed", 1, ct);\r\n    }\r\n    \r\n    return result;\r\n}\n'})}),"\n",(0,l.jsx)(n.h4,{id:"2-node-level-synchronization",children:"2. Node-Level Synchronization"}),"\n",(0,l.jsx)(n.p,{children:"For simple synchronization within a single node:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"public class SynchronizedTransform : TransformNode<int, int>\r\n{\r\n    private readonly object _syncLock = new();\r\n    private int _total = 0;\r\n    \r\n    public override async ValueTask<int> TransformAsync(\r\n        int input,\r\n        PipelineContext context,\r\n        CancellationToken ct)\r\n    {\r\n        lock (_syncLock)\r\n        {\r\n            _total += input;\r\n        }\r\n        return input;\r\n    }\r\n}\n"})}),"\n",(0,l.jsx)(n.h4,{id:"3-atomic-operations-for-simple-counters",children:"3. Atomic Operations for Simple Counters"}),"\n",(0,l.jsx)(n.p,{children:"For single-value counters without additional logic:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"public class CountingTransform : TransformNode<int, int>\r\n{\r\n    private long _processedCount = 0;\r\n    \r\n    public override async ValueTask<int> TransformAsync(\r\n        int input,\r\n        PipelineContext context,\r\n        CancellationToken ct)\r\n    {\r\n        Interlocked.Increment(ref _processedCount);\r\n        return input;\r\n    }\r\n}\n"})}),"\n",(0,l.jsx)(n.h3,{id:"thread-safety-dos",children:"Thread Safety DO's"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Process independent data items in parallel (inherently safe)"}),"\n",(0,l.jsxs)(n.li,{children:["Use ",(0,l.jsx)(n.code,{children:"IPipelineStateManager"})," for shared state"]}),"\n",(0,l.jsxs)(n.li,{children:["Use ",(0,l.jsx)(n.code,{children:"lock"})," for simple critical sections"]}),"\n",(0,l.jsxs)(n.li,{children:["Use ",(0,l.jsx)(n.code,{children:"Interlocked"})," for atomic counter operations"]}),"\n",(0,l.jsx)(n.li,{children:"Keep synchronization scopes small and fast"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"thread-safety-donts",children:"Thread Safety DON'Ts"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Directly access or modify ",(0,l.jsx)(n.code,{children:"context.Items"})," from multiple threads"]}),"\n",(0,l.jsx)(n.li,{children:"Share mutable state between nodes without explicit synchronization"}),"\n",(0,l.jsxs)(n.li,{children:["Assume dictionaries in ",(0,l.jsx)(n.code,{children:"PipelineContext"})," are thread-safe"]}),"\n",(0,l.jsx)(n.li,{children:"Hold locks across I/O operations (causes contention)"}),"\n",(0,l.jsx)(n.li,{children:"Create complex multi-step interlocked sequences (use locks instead)"}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsxs)(n.strong,{children:["For comprehensive guidance, see ",(0,l.jsx)(n.a,{href:"/docs/core-concepts/thread-safety",children:"Thread Safety Guidelines"}),"."]})}),"\n",(0,l.jsx)(n.h2,{id:"parallel-execution-configuration-methods",children:"Parallel Execution Configuration Methods"}),"\n",(0,l.jsx)(n.p,{children:"NPipeline provides multiple ways to configure parallel execution, each suited to different needs:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Preset API"}),": Best for common workload patterns with automatically optimized defaults"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Builder API"}),": Best for flexible customization while starting from sensible defaults"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Manual Configuration API"}),": Best for advanced performance tuning and complex scenarios"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"preset-api-using-workload-type-presets",children:"Preset API: Using Workload Type Presets"}),"\n",(0,l.jsxs)(n.p,{children:["For common workload patterns, use the ",(0,l.jsx)(n.code,{children:"RunParallel"})," extension method with a workload type to automatically select optimal parallelism configuration:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"using NPipeline.Extensions.Parallelism;\r\nusing NPipeline.Pipeline;\r\n\r\npublic sealed class SimplifiedParallelPipeline : IPipelineDefinition\r\n{\r\n    public void DefinePipeline(PipelineBuilder builder)\r\n    {\r\n        builder\r\n            .AddTransform<MyTransform, Input, Output>()\r\n            .RunParallel(builder, ParallelWorkloadType.IoBound)\r\n            .AddSink<MySink>();\r\n    }\r\n}\n"})}),"\n",(0,l.jsxs)(n.p,{children:["That's it! The ",(0,l.jsx)(n.code,{children:"RunParallel"})," method with ",(0,l.jsx)(n.code,{children:"ParallelWorkloadType.IoBound"})," automatically configures:"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Degree of parallelism: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 4"})," (hide I/O latency)"]}),"\n",(0,l.jsxs)(n.li,{children:["Queue length: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 8"})]}),"\n",(0,l.jsxs)(n.li,{children:["Output buffer: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 16"})]}),"\n",(0,l.jsx)(n.li,{children:"Queue policy: Block (apply backpressure)"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"workload-type-presets",children:"Workload Type Presets"}),"\n",(0,l.jsx)(n.p,{children:"NPipeline provides four built-in presets optimized for common workload patterns:"}),"\n",(0,l.jsxs)(n.h4,{id:"parallelworkloadtypegeneral-default",children:[(0,l.jsx)(n.code,{children:"ParallelWorkloadType.General"})," (Default)"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Best for"}),": Mixed CPU and I/O workloads, when you're unsure"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"builder\r\n    .AddTransform<MyTransform, Input, Output>()\r\n    .RunParallel(builder, ParallelWorkloadType.General)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Configuration"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["DOP: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 2"})]}),"\n",(0,l.jsxs)(n.li,{children:["Queue: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 4"})]}),"\n",(0,l.jsxs)(n.li,{children:["Buffer: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 8"})]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"parallelworkloadtypecpubound",children:(0,l.jsx)(n.code,{children:"ParallelWorkloadType.CpuBound"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Best for"}),": CPU-intensive operations, mathematical computations, DSP"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"builder\r\n    .AddTransform<IntensiveMathTransform, double, double>()\r\n    .RunParallel(builder, ParallelWorkloadType.CpuBound)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Configuration"})," (avoids oversubscription):"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["DOP: ",(0,l.jsx)(n.code,{children:"ProcessorCount"})," (1:1 with CPU cores)"]}),"\n",(0,l.jsxs)(n.li,{children:["Queue: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 2"})]}),"\n",(0,l.jsxs)(n.li,{children:["Buffer: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 4"})]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"parallelworkloadtypeiobound",children:(0,l.jsx)(n.code,{children:"ParallelWorkloadType.IoBound"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Best for"}),": File I/O, database operations, local service calls"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"builder\r\n    .AddTransform<DatabaseTransform, int, Record>()\r\n    .RunParallel(builder, ParallelWorkloadType.IoBound)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Configuration"})," (high parallelism hides I/O latency):"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["DOP: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 4"})]}),"\n",(0,l.jsxs)(n.li,{children:["Queue: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 8"})]}),"\n",(0,l.jsxs)(n.li,{children:["Buffer: ",(0,l.jsx)(n.code,{children:"ProcessorCount * 16"})]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"parallelworkloadtypenetworkbound",children:(0,l.jsx)(n.code,{children:"ParallelWorkloadType.NetworkBound"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Best for"}),": HTTP calls, remote service calls, high-latency network operations"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"builder\r\n    .AddTransform<WebServiceTransform, Request, Response>()\r\n    .RunParallel(builder, ParallelWorkloadType.NetworkBound)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Configuration"})," (maximum throughput under high latency):"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["DOP: ",(0,l.jsx)(n.code,{children:"Min(ProcessorCount * 8, 100)"})," (capped at 100)"]}),"\n",(0,l.jsxs)(n.li,{children:["Queue: ",(0,l.jsx)(n.code,{children:"200"})," (large buffer)"]}),"\n",(0,l.jsxs)(n.li,{children:["Buffer: ",(0,l.jsx)(n.code,{children:"400"})]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"builder-api-fine-grained-control-with-paralleloptionsbuilder",children:"Builder API: Fine-Grained Control with ParallelOptionsBuilder"}),"\n",(0,l.jsx)(n.p,{children:"When you need to customize beyond the presets, use the fluent builder API for flexible configuration:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"builder\r\n    .AddTransform<MyTransform, Input, Output>()\r\n    .RunParallel(builder, opt => opt\r\n        .MaxDegreeOfParallelism(8)\r\n        .MaxQueueLength(100)\r\n        .DropOldestOnBackpressure()\r\n        .OutputBufferCapacity(50)\r\n        .AllowUnorderedOutput()\r\n        .MetricsInterval(TimeSpan.FromSeconds(2)))\r\n    .AddSink<MySink>();\n"})}),"\n",(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.code,{children:"ParallelOptionsBuilder"})," provides full configuration:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"public class ParallelOptionsBuilder\r\n{\r\n    // Configure degree of parallelism\r\n    public ParallelOptionsBuilder MaxDegreeOfParallelism(int value)\r\n\r\n    // Configure input queue behavior\r\n    public ParallelOptionsBuilder MaxQueueLength(int value)\r\n    public ParallelOptionsBuilder BlockOnBackpressure()\r\n    public ParallelOptionsBuilder DropOldestOnBackpressure()\r\n    public ParallelOptionsBuilder DropNewestOnBackpressure()\r\n\r\n    // Configure output buffering\r\n    public ParallelOptionsBuilder OutputBufferCapacity(int value)\r\n    public ParallelOptionsBuilder AllowUnorderedOutput()\r\n\r\n    // Configure metrics\r\n    public ParallelOptionsBuilder MetricsInterval(TimeSpan interval)\r\n\r\n    // Build the final options\r\n    public ParallelOptions Build()\r\n}\n"})}),"\n",(0,l.jsx)(n.h3,{id:"comparison-configuration-methods",children:"Comparison: Configuration Methods"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Aspect"}),(0,l.jsx)(n.th,{children:"Manual API"}),(0,l.jsx)(n.th,{children:"Preset API"}),(0,l.jsx)(n.th,{children:"Builder API"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Lines of code"})}),(0,l.jsx)(n.td,{children:"5-6"}),(0,l.jsx)(n.td,{children:"1"}),(0,l.jsx)(n.td,{children:"2-3"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Parameters to understand"})}),(0,l.jsx)(n.td,{children:"All 5+"}),(0,l.jsx)(n.td,{children:"0"}),(0,l.jsx)(n.td,{children:"1-2 (as needed)"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Configuration style"})}),(0,l.jsx)(n.td,{children:"Explicit"}),(0,l.jsx)(n.td,{children:"Predefined"}),(0,l.jsx)(n.td,{children:"Fluent"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"When to use"})}),(0,l.jsx)(n.td,{children:"Advanced tuning"}),(0,l.jsx)(n.td,{children:"Common patterns"}),(0,l.jsx)(n.td,{children:"Custom needs"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Learning curve"})}),(0,l.jsx)(n.td,{children:"Steeper"}),(0,l.jsx)(n.td,{children:"Gentle"}),(0,l.jsx)(n.td,{children:"Gradual"})]})]})]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Manual Configuration"}),":"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:".WithBlockingParallelism(\r\n    builder,\r\n    maxDegreeOfParallelism: Environment.ProcessorCount * 4,\r\n    maxQueueLength: Environment.ProcessorCount * 8,\r\n    outputBufferCapacity: Environment.ProcessorCount * 16)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Preset API"}),":"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:".RunParallel(builder, ParallelWorkloadType.IoBound)\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Builder API"}),":"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:".RunParallel(builder, opt => opt\r\n    .MaxDegreeOfParallelism(Environment.ProcessorCount * 4)\r\n    .MaxQueueLength(Environment.ProcessorCount * 8))\n"})}),"\n",(0,l.jsx)(n.h3,{id:"when-to-use-each-approach",children:"When to Use Each Approach"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Scenario"}),(0,l.jsx)(n.th,{children:"Recommendation"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"New to NPipeline"}),(0,l.jsxs)(n.td,{children:["Preset API with ",(0,l.jsx)(n.code,{children:"ParallelWorkloadType"})]})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Typical workloads"}),(0,l.jsx)(n.td,{children:"Preset API"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Need slight customization"}),(0,l.jsx)(n.td,{children:"Builder API"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Advanced performance tuning"}),(0,l.jsx)(n.td,{children:"Manual API"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Prototyping"}),(0,l.jsx)(n.td,{children:"Preset API"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Production optimization"}),(0,l.jsx)(n.td,{children:"Builder or Manual API (after profiling)"})]})]})]}),"\n",(0,l.jsx)(n.h3,{id:"example-full-pipeline-with-simplified-api",children:"Example: Full Pipeline with Simplified API"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"using NPipeline.Extensions.Parallelism;\r\nusing NPipeline.Pipeline;\r\n\r\npublic class FileProcessingPipeline : IPipelineDefinition\r\n{\r\n    public void DefinePipeline(PipelineBuilder builder)\r\n    {\r\n        builder\r\n            // Read files (I/O-bound)\r\n            .AddTransform<FileReaderTransform, string, FileContent>()\r\n            .RunParallel(builder, ParallelWorkloadType.IoBound)\r\n            \r\n            // Parse content (CPU-bound)\r\n            .AddTransform<ParserTransform, FileContent, ParsedData>()\r\n            .RunParallel(builder, ParallelWorkloadType.CpuBound)\r\n            \r\n            // Upload results (network-bound)\r\n            .AddTransform<UploaderTransform, ParsedData, UploadResult>()\r\n            .RunParallel(builder, ParallelWorkloadType.NetworkBound)\r\n            \r\n            // Store results\r\n            .AddSink<DatabaseSinkNode<UploadResult>>();\r\n    }\r\n}\n"})}),"\n",(0,l.jsx)(n.p,{children:"This example shows how different stages of a pipeline can use different workload types, automatically configured for their specific characteristics."}),"\n",(0,l.jsx)(n.h2,{id:"validation-of-parallel-configuration",children:"Validation of Parallel Configuration"}),"\n",(0,l.jsxs)(n.p,{children:["NPipeline includes a ",(0,l.jsx)(n.strong,{children:"ParallelConfigurationRule"})," that validates your parallel execution settings at build time, helping prevent common mistakes that can cause performance issues or resource exhaustion."]}),"\n",(0,l.jsx)(n.h3,{id:"automatic-validation",children:"Automatic Validation"}),"\n",(0,l.jsx)(n.p,{children:"When you build a pipeline with parallel nodes, the validation rule automatically checks:"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Queue Limits with High Parallelism"})," - Warns if you have high parallelism (>4) without setting ",(0,l.jsx)(n.code,{children:"MaxQueueLength"})]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"This prevents unbounded memory growth if downstream processing is slower than upstream production"}),"\n",(0,l.jsxs)(n.li,{children:["Set ",(0,l.jsx)(n.code,{children:"MaxQueueLength"})," to 2-10x your ",(0,l.jsx)(n.code,{children:"MaxDegreeOfParallelism"})]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Order Preservation Overhead"})," - Warns if you preserve ordering with high parallelism (>8)"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Preserving order with many workers requires significant buffering and reordering"}),"\n",(0,l.jsx)(n.li,{children:"Causes latency as items wait for slower workers to complete"}),"\n",(0,l.jsx)(n.li,{children:"Only preserve ordering if downstream requires it"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Drop Policies Without Queue Bounds"})," - Warns if you use drop policies without bounded queues"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Drop policies (",(0,l.jsx)(n.code,{children:"DropOldest"}),", ",(0,l.jsx)(n.code,{children:"DropNewest"}),") only work with bounded queues"]}),"\n",(0,l.jsxs)(n.li,{children:["Without ",(0,l.jsx)(n.code,{children:"MaxQueueLength"}),", the drop policy has no effect"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Thread Explosion Detection"})," - Warns if parallelism exceeds ",(0,l.jsx)(n.code,{children:"ProcessorCount * 4"})]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"May indicate configuration error or unusual workload"}),"\n",(0,l.jsx)(n.li,{children:"Excessive parallelism can cause thread pool starvation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"validation-in-action",children:"Validation in Action"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:'var builder = new PipelineBuilder();\r\n\r\n// ... build pipeline ...\r\n\r\n// Validate before running\r\nvar result = builder.Validate();\r\n\r\nif (!result.IsValid)\r\n{\r\n    Console.WriteLine("Errors:");\r\n    foreach (var error in result.Errors)\r\n        Console.WriteLine($"  \u274c {error}");\r\n}\r\n\r\nif (result.Warnings.Count > 0)\r\n{\r\n    Console.WriteLine("Warnings:");\r\n    foreach (var warning in result.Warnings)\r\n        Console.WriteLine($"  \u26a0\ufe0f  {warning}");\r\n}\r\n\r\n// Example output:\r\n// \u26a0\ufe0f  Node \'transform\' has high parallelism (16) but no queue limit (MaxQueueLength is null).\r\n//     Consider setting MaxQueueLength to prevent unbounded memory growth.\r\n// \u26a0\ufe0f  Node \'transform\' preserves ordering with high parallelism (16). This may cause \r\n//     significant output buffering and latency. If ordering is not critical, consider \r\n//     .AllowUnorderedOutput() to improve throughput.\n'})}),"\n",(0,l.jsx)(n.h3,{id:"quick-fix-examples",children:"Quick Fix Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-csharp",children:"// PROBLEM: High parallelism without queue limits\r\nvar parallelOptions = new ParallelOptions(\r\n    MaxDegreeOfParallelism: 16,\r\n    MaxQueueLength: null);  // \u26a0\ufe0f Warning!\r\n\r\n// FIX: Set appropriate queue length\r\nvar parallelOptions = new ParallelOptions(\r\n    MaxDegreeOfParallelism: 16,\r\n    MaxQueueLength: 100);  // \u2705 OK - Bounded to 6x parallelism\r\n\r\n// PROBLEM: Preserving order with high parallelism\r\nvar options = builder.AddTransform<MyTransform, Input, Output>()\r\n    .RunParallel(builder, opt => opt\r\n        .MaxDegreeOfParallelism(16)\r\n        .PreserveOrdering: true);  // \u26a0\ufe0f High latency warning!\r\n\r\n// FIX: Disable ordering for throughput\r\nvar options = builder.AddTransform<MyTransform, Input, Output>()\r\n    .RunParallel(builder, opt => opt\r\n        .MaxDegreeOfParallelism(16)\r\n        .AllowUnorderedOutput());  // \u2705 Better throughput\n"})}),"\n",(0,l.jsxs)(n.p,{children:["For complete validation documentation, see ",(0,l.jsx)(n.a,{href:"/docs/core-concepts/pipeline-validation#parallel-configuration-rule-details",children:"Parallel Configuration Rule Details"}),"."]}),"\n",(0,l.jsx)(n.h2,{id:"considerations-for-parallelism",children:"Considerations for Parallelism"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Degree of Parallelism:"})," Carefully choose the ",(0,l.jsx)(n.code,{children:"MaxDegreeOfParallelism"}),". Too high a value can lead to excessive resource consumption (CPU, memory, threads) and diminish returns due to context switching overhead. Too low a value might underutilize available resources."]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Thread Safety:"})," Ensure that any shared state or external resources accessed by your parallel nodes are thread-safe. If your nodes are pure functions (operating only on their input and producing output without side effects), this is less of a concern."]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Order Preservation:"})," By default, NPipeline maintains the order of items even when processing them in parallel. If order is not critical and you need maximum throughput, you can configure nodes to not preserve order by setting ",(0,l.jsx)(n.code,{children:"PreserveOrdering = false"}),"."]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Resource Contention:"})," Be aware of potential bottlenecks when multiple parallel tasks try to access the same limited resource (e.g., a single database connection, a slow API)."]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Debugging:"})," Debugging parallel code can be more complex. Ensure you have good logging and monitoring in place."]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Identify Parallelizable Work:"})," Apply parallelism to parts of your pipeline where operations are independent and computationally intensive."]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Start Small:"})," Begin with a low degree of parallelism and incrementally increase it while monitoring performance metrics (CPU, memory, throughput) to find the optimal balance."]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Profile:"})," Use profiling tools to identify bottlenecks and ensure that parallelism is indeed improving performance."]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"By strategically applying parallelism, you can significantly boost the processing capabilities of your NPipelines for demanding workloads."}),"\n",(0,l.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/docs/core-concepts/thread-safety",children:"Thread Safety Guidelines"})}),": Comprehensive guide to thread safety and shared state management"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/docs/extensions/dependency-injection",children:"Dependency Injection"})}),": Learn how to integrate NPipeline with dependency injection frameworks"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/docs/extensions/testing",children:"Testing Pipelines"})}),": Understand how to effectively test your parallel pipelines"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>t});var i=r(96540);const l={},s=i.createContext(l);function a(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);