"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[7192],{2174:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"architecture/performance-characteristics","title":"Performance Characteristics","description":"Memory usage, throughput, and scalability of NPipeline.","source":"@site/docs/architecture/performance-characteristics.md","sourceDirName":"architecture","slug":"/architecture/performance-characteristics","permalink":"/docs/architecture/performance-characteristics","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"title":"Performance Characteristics","description":"Memory usage, throughput, and scalability of NPipeline.","sidebar_position":8},"sidebar":"docsSidebar","previous":{"title":"Cancellation Model","permalink":"/docs/architecture/cancellation-model"},"next":{"title":"Extension Points","permalink":"/docs/architecture/extension-points"}}');var s=n(4848),t=n(8453);const a={title:"Performance Characteristics",description:"Memory usage, throughput, and scalability of NPipeline.",sidebar_position:8},l="Performance Characteristics",c={},o=[{value:"Memory Usage",id:"memory-usage",level:2},{value:"Streaming Model",id:"streaming-model",level:3},{value:"Memory Per Item",id:"memory-per-item",level:3},{value:"Throughput Characteristics",id:"throughput-characteristics",level:2},{value:"Sequential Processing",id:"sequential-processing",level:3},{value:"Parallel Processing",id:"parallel-processing",level:3},{value:"Scalability",id:"scalability",level:2},{value:"Vertical Scaling",id:"vertical-scaling",level:3},{value:"Horizontal Scaling",id:"horizontal-scaling",level:3},{value:"Comparative Performance",id:"comparative-performance",level:2},{value:"NPipeline vs Alternatives",id:"npipeline-vs-alternatives",level:3},{value:"Optimization Tips",id:"optimization-tips",level:2},{value:"1. Use Async/Await Properly",id:"1-use-asyncawait-properly",level:3},{value:"2. Batch Expensive Operations",id:"2-batch-expensive-operations",level:3},{value:"3. Avoid Materialization",id:"3-avoid-materialization",level:3},{value:"4. Use Parallelism for CPU Work",id:"4-use-parallelism-for-cpu-work",level:3},{value:"Benchmarking",id:"benchmarking",level:2},{value:"\u27a1\ufe0f Next Steps",id:"arrow_right-next-steps",level:2}];function d(e){const r={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(r.header,{children:(0,s.jsx)(r.h1,{id:"performance-characteristics",children:"Performance Characteristics"})}),"\n",(0,s.jsx)(r.p,{children:"NPipeline is designed from the ground up for performance. Understanding its characteristics helps you build efficient pipelines."}),"\n",(0,s.jsx)(r.h2,{id:"memory-usage",children:"Memory Usage"}),"\n",(0,s.jsx)(r.h3,{id:"streaming-model",children:"Streaming Model"}),"\n",(0,s.jsxs)(r.p,{children:["Memory usage is proportional to the number of items ",(0,s.jsx)(r.strong,{children:"in flight"}),", not total dataset size:"]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-text",children:"Lazy Evaluation (NPipeline):\r\nItem 1: [Read] \u2192 [Transform] \u2192 [Write] \u2192 [GC] \u2192 Item 2\r\nMemory: ~1 item worth of data at any time\r\n\r\nEager Evaluation (.ToList()):\r\n[All items in memory] \u2192 Process all \u2192 [GC]\r\nMemory: ~N \xd7 item_size for N items\n"})}),"\n",(0,s.jsx)(r.p,{children:(0,s.jsx)(r.strong,{children:"Real-world Example:"})}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"// Processing 1 million CSV records (500 bytes each)\r\n// Streaming: ~1-2 MB peak memory (1-2 items buffered)\r\n// Eager (.ToList()): ~500 MB+ required\r\nvar pipeline = PipelineBuilder\r\n    .AddSourceNode<CsvSourceNode>()\r\n    .AddTransformNode<TransformNode>()\r\n    .AddSinkNode<SinkNode>()\r\n    .BuildPipeline();\n"})}),"\n",(0,s.jsx)(r.h3,{id:"memory-per-item",children:"Memory Per Item"}),"\n",(0,s.jsx)(r.p,{children:"The memory used per item in the pipeline is minimal:"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"// Memory footprint:\r\n// - Source item: varies (100 bytes - 10 KB typical)\r\n// - Transform: composes items, minimal overhead\r\n// - Sink: determines lifetime of item reference\n"})}),"\n",(0,s.jsx)(r.h2,{id:"throughput-characteristics",children:"Throughput Characteristics"}),"\n",(0,s.jsx)(r.h3,{id:"sequential-processing",children:"Sequential Processing"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-text",children:"Time:    0ms         10ms        20ms        30ms\r\n         \u2193           \u2193           \u2193           \u2193\r\nItem 1: [Read]\u2192[Trans]\u2192[Write]\r\nItem 2:              [Read]\u2192[Trans]\u2192[Write]\r\nItem 3:                         [Read]\u2192[Trans]\u2192[Write]\r\n\r\nThroughput: 1 item / 10ms = 100 items/second\n"})}),"\n",(0,s.jsx)(r.h3,{id:"parallel-processing",children:"Parallel Processing"}),"\n",(0,s.jsxs)(r.p,{children:["Using ",(0,s.jsx)(r.code,{children:"ParallelismExtension"}),":"]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-text",children:"Time:    0ms         10ms        20ms        30ms\r\n         \u2193           \u2193           \u2193           \u2193\r\nItem 1: [Read]\u2192[Trans]\u2192[Write]\r\nItem 2: [Read]\u2192[Trans]\u2192[Write]\r\nItem 3: [Read]\u2192[Trans]\u2192[Write]\r\n\r\nThroughput: 3 items / 10ms = 300 items/second (3x speedup)\n"})}),"\n",(0,s.jsx)(r.p,{children:(0,s.jsx)(r.strong,{children:"Implementation:"})}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"var pipeline = PipelineBuilder\r\n    .AddSourceNode<SourceNode>()\r\n    .AddTransformNode<SlowTransform>(parallelism: 4)\r\n    .AddSinkNode<SinkNode>()\r\n    .BuildPipeline();\n"})}),"\n",(0,s.jsx)(r.h2,{id:"scalability",children:"Scalability"}),"\n",(0,s.jsx)(r.h3,{id:"vertical-scaling",children:"Vertical Scaling"}),"\n",(0,s.jsx)(r.p,{children:"Scale within a single machine:"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"// Use parallelism for CPU-bound transforms\r\n.AddTransformNode<CpuIntensiveTransform>(parallelism: Environment.ProcessorCount)\r\n\r\n// Use batching for IO-bound transforms\r\n.AddNode(new BatchNode<Item>(batchSize: 100))\r\n.AddTransformNode<DatabaseInsertTransform>()\n"})}),"\n",(0,s.jsx)(r.h3,{id:"horizontal-scaling",children:"Horizontal Scaling"}),"\n",(0,s.jsx)(r.p,{children:"Scale across multiple machines:"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"// Partition source data\r\nvar machineId = GetMachineId();\r\nvar totalMachines = GetTotalMachines();\r\n\r\nvar pipeline = PipelineBuilder\r\n    .AddSourceNode(new PartitionedSourceNode(machineId, totalMachines))\r\n    .AddTransformNode<TransformNode>()\r\n    .AddSinkNode(new CentralizedSinkNode()) // Write to shared storage\r\n    .BuildPipeline();\n"})}),"\n",(0,s.jsx)(r.h2,{id:"comparative-performance",children:"Comparative Performance"}),"\n",(0,s.jsx)(r.h3,{id:"npipeline-vs-alternatives",children:"NPipeline vs Alternatives"}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Aspect"}),(0,s.jsx)(r.th,{children:"NPipeline"}),(0,s.jsx)(r.th,{children:"LINQ Streaming"}),(0,s.jsx)(r.th,{children:"Message Queues"}),(0,s.jsx)(r.th,{children:"Direct Iteration"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Memory"})}),(0,s.jsx)(r.td,{children:"O(k) active items*"}),(0,s.jsx)(r.td,{children:"O(1) per item"}),(0,s.jsx)(r.td,{children:"O(batch)"}),(0,s.jsx)(r.td,{children:"O(N) all items"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Latency"})}),(0,s.jsx)(r.td,{children:"< 1ms first item"}),(0,s.jsx)(r.td,{children:"< 1ms first item"}),(0,s.jsx)(r.td,{children:"10-100ms"}),(0,s.jsx)(r.td,{children:"N/A (batch)"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Setup"})}),(0,s.jsx)(r.td,{children:"Low"}),(0,s.jsx)(r.td,{children:"Low"}),(0,s.jsx)(r.td,{children:"High"}),(0,s.jsx)(r.td,{children:"Very Low"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Typed Composition"})}),(0,s.jsx)(r.td,{children:"Yes"}),(0,s.jsx)(r.td,{children:"Yes"}),(0,s.jsx)(r.td,{children:"Weak"}),(0,s.jsx)(r.td,{children:"No"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Error Handling"})}),(0,s.jsx)(r.td,{children:"Flexible"}),(0,s.jsx)(r.td,{children:"Basic"}),(0,s.jsx)(r.td,{children:"Rich"}),(0,s.jsx)(r.td,{children:"None"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Observability"})}),(0,s.jsx)(r.td,{children:"Built-in"}),(0,s.jsx)(r.td,{children:"Limited"}),(0,s.jsx)(r.td,{children:"Rich"}),(0,s.jsx)(r.td,{children:"None"})]})]})]}),"\n",(0,s.jsx)(r.p,{children:"*k = number of items actively in the pipeline's processing stages at any given time (typically 1-2 for sequential execution, k = parallelism factor for parallel execution). This is independent of total dataset size N."}),"\n",(0,s.jsx)(r.h2,{id:"optimization-tips",children:"Optimization Tips"}),"\n",(0,s.jsx)(r.h3,{id:"1-use-asyncawait-properly",children:"1. Use Async/Await Properly"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"// Good - respects async model\r\npublic async IAsyncEnumerable<Output> ProcessAsync(\r\n    Input input,\r\n    [EnumeratorCancellation] CancellationToken cancellationToken = default)\r\n{\r\n    var result = await _service.ProcessAsync(input, cancellationToken);\r\n    yield return result;\r\n}\r\n\r\n// Bad - blocks thread\r\npublic async IAsyncEnumerable<Output> ProcessAsync(\r\n    Input input,\r\n    [EnumeratorCancellation] CancellationToken cancellationToken = default)\r\n{\r\n    var result = _service.Process(input); // Blocks! Use await instead\r\n    yield return result;\r\n}\n"})}),"\n",(0,s.jsx)(r.h3,{id:"2-batch-expensive-operations",children:"2. Batch Expensive Operations"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"// Process 10,000 items one-by-one: 10,000 DB roundtrips (slow)\r\n.AddTransformNode<SingleInsertTransform>()\r\n\r\n// vs batch them: 100 DB roundtrips (100x faster)\r\n.AddNode(new BatchNode<Order>(batchSize: 100))\r\n.AddTransformNode<BatchInsertTransform>()\n"})}),"\n",(0,s.jsx)(r.h3,{id:"3-avoid-materialization",children:"3. Avoid Materialization"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"// Bad - materializes everything\r\n.AddNode(new MaterializationNode<Item>())\r\n.AddTransformNode<Transform>()\r\n\r\n// Good - processes streaming\r\n.AddTransformNode<Transform>()\n"})}),"\n",(0,s.jsx)(r.h3,{id:"4-use-parallelism-for-cpu-work",children:"4. Use Parallelism for CPU Work"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:"// CPU-bound: parallelize\r\n.AddTransformNode<JsonParsingTransform>(parallelism: 8)\r\n\r\n// IO-bound: lower parallelism needed\r\n.AddTransformNode<DatabaseQueryTransform>(parallelism: 2)\n"})}),"\n",(0,s.jsx)(r.h2,{id:"benchmarking",children:"Benchmarking"}),"\n",(0,s.jsx)(r.p,{children:"Run your own benchmarks with realistic data:"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-csharp",children:'var stopwatch = Stopwatch.StartNew();\r\n\r\nvar pipeline = BuildPipeline();\r\nvar context = PipelineContext.Default;\r\nvar result = await runner.ExecuteAsync(pipeline, context);\r\n\r\nstopwatch.Stop();\r\nConsole.WriteLine($"Processed {result.ItemsProcessed} items in {stopwatch.ElapsedMilliseconds}ms");\r\nConsole.WriteLine($"Throughput: {result.ItemsProcessed / stopwatch.Elapsed.TotalSeconds:F0} items/sec");\n'})}),"\n",(0,s.jsxs)(r.h2,{id:"arrow_right-next-steps",children:["\u27a1\ufe0f"," Next Steps"]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"/docs/architecture/extension-points",children:"Extension Points"})})," - Build custom nodes optimized for your use case"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"/docs/advanced-topics/performance-hygiene",children:"Advanced Topics - Performance Hygiene"})})," - Deep dive into performance optimization"]}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>a,x:()=>l});var i=n(6540);const s={},t=i.createContext(s);function a(e){const r=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(t.Provider,{value:r},e.children)}}}]);