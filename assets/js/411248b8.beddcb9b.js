"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[9081],{8453:(e,r,n)=>{n.d(r,{R:()=>s,x:()=>a});var i=n(6540);const t={},o=i.createContext(t);function s(e){const r=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(o.Provider,{value:r},e.children)}},9866:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"core-concepts/pipeline-execution/retry-configuration","title":"Retry Configuration","description":"Learn how to configure retry behavior in NPipeline using PipelineRetryOptions to manage item retries and node restarts.","source":"@site/docs/core-concepts/pipeline-execution/retry-configuration.md","sourceDirName":"core-concepts/pipeline-execution","slug":"/core-concepts/pipeline-execution/retry-configuration","permalink":"/docs/core-concepts/pipeline-execution/retry-configuration","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"title":"Retry Configuration","description":"Learn how to configure retry behavior in NPipeline using PipelineRetryOptions to manage item retries and node restarts.","sidebar_position":7},"sidebar":"docsSidebar","previous":{"title":"Pipeline-level Error Handling","permalink":"/docs/core-concepts/pipeline-execution/pipeline-error-handling"},"next":{"title":"Circuit Breaker Configuration","permalink":"/docs/core-concepts/pipeline-execution/circuit-breaker-configuration"}}');var t=n(4848),o=n(8453);const s={title:"Retry Configuration",description:"Learn how to configure retry behavior in NPipeline using PipelineRetryOptions to manage item retries and node restarts.",sidebar_position:7},a="Retry Configuration",l={},c=[{value:"Overview",id:"overview",level:2},{value:"PipelineRetryOptions",id:"pipelineretryoptions",level:2},{value:"Basic Retry Configuration",id:"basic-retry-configuration",level:2},{value:"Global Retry Options",id:"global-retry-options",level:3},{value:"Per-Node Retry Options",id:"per-node-retry-options",level:3},{value:"Use Cases for Per-Node Retry Configuration",id:"use-cases-for-per-node-retry-configuration",level:4},{value:"Precedence Rules",id:"precedence-rules",level:4},{value:"Integrating External Retry Libraries",id:"integrating-external-retry-libraries",level:2},{value:"Retry Strategies",id:"retry-strategies",level:2},{value:"Fixed Delay Retry",id:"fixed-delay-retry",level:3},{value:"Exponential Backoff with Jitter",id:"exponential-backoff-with-jitter",level:3},{value:"Context-Aware Retry",id:"context-aware-retry",level:2},{value:"\u2705 Best Practices",id:"white_check_mark-best-practices",level:2},{value:"Production Example",id:"production-example",level:2},{value:"\u2139\ufe0f See Also",id:"information_source-see-also",level:2},{value:"\ud83d\udd17 Related Topics",id:"link-related-topics",level:2}];function d(e){const r={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.header,{children:(0,t.jsx)(r.h1,{id:"retry-configuration",children:"Retry Configuration"})}),"\n",(0,t.jsx)(r.p,{children:"Retry configuration in NPipeline allows you to define how the pipeline should respond to transient failures by retrying operations. This is essential for building resilient pipelines that can recover from temporary issues without manual intervention."}),"\n",(0,t.jsx)(r.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(r.p,{children:"NPipeline provides configurable retry options that control both individual item retries (for node-level errors) and node restart attempts (for pipeline-level errors). These options can be set globally for the entire pipeline or overridden for specific nodes."}),"\n",(0,t.jsx)(r.h2,{id:"pipelineretryoptions",children:"PipelineRetryOptions"}),"\n",(0,t.jsxs)(r.p,{children:["The ",(0,t.jsx)(r.a,{href:"../../src/NPipeline/Configuration/PipelineRetryOptions.cs",children:(0,t.jsx)(r.code,{children:"PipelineRetryOptions"})})," record configures retry behavior for items and node restarts."]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:"public sealed record PipelineRetryOptions(\r\n    int MaxItemRetries,\r\n    int MaxNodeRestartAttempts,\r\n    int MaxSequentialNodeAttempts,\r\n    int? MaxMaterializedItems = null) // Null => unbounded (no cap)\r\n{\r\n    public static PipelineRetryOptions Default { get; } = new(0, 3, 5);\r\n\r\n    public PipelineRetryOptions With(\r\n        int? maxItemRetries = null,\r\n        int? maxNodeRestartAttempts = null,\r\n        int? maxSequentialNodeAttempts = null,\r\n        int? maxMaterializedItems = null)\r\n    {\r\n        return new PipelineRetryOptions(\r\n            maxItemRetries ?? MaxItemRetries,\r\n            maxNodeRestartAttempts ?? MaxNodeRestartAttempts,\r\n            maxSequentialNodeAttempts ?? MaxSequentialNodeAttempts,\r\n            maxMaterializedItems ?? MaxMaterializedItems);\r\n    }\r\n}\n"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.code,{children:"MaxItemRetries"})}),": The maximum number of times an individual item will be re-processed by a node's execution strategy if its ",(0,t.jsx)(r.code,{children:"INodeErrorHandler"})," returns ",(0,t.jsx)(r.code,{children:"NodeErrorDecision.Retry"}),"."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.code,{children:"MaxNodeRestartAttempts"})}),": The maximum number of times a node's entire stream will be re-executed by ",(0,t.jsx)(r.code,{children:"ResilientExecutionStrategy"})," if ",(0,t.jsx)(r.code,{children:"IPipelineErrorHandler"})," returns ",(0,t.jsx)(r.code,{children:"PipelineErrorDecision.RestartNode"}),"."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.code,{children:"MaxSequentialNodeAttempts"})}),": (Used by ",(0,t.jsx)(r.code,{children:"SequentialExecutionStrategy"})," for node restarts) The maximum number of attempts for a node in a sequential pipeline."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.code,{children:"MaxMaterializedItems"})}),": An optional cap on the number of items to materialize (buffer) for replay when using ",(0,t.jsx)(r.code,{children:"ResilientExecutionStrategy"}),".","\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["When ",(0,t.jsx)(r.code,{children:"null"})," (default): Unbounded materialization - all items are buffered"]}),"\n",(0,t.jsx)(r.li,{children:"When has a value: Limited materialization - only the specified number of items are buffered, after which new items replace the oldest ones"}),"\n",(0,t.jsx)(r.li,{children:"This parameter prevents excessive memory consumption in case of large streams and is particularly important for long-running pipelines with high throughput"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"basic-retry-configuration",children:"Basic Retry Configuration"}),"\n",(0,t.jsx)(r.h3,{id:"global-retry-options",children:"Global Retry Options"}),"\n",(0,t.jsx)(r.p,{children:"You can set retry options globally for the pipeline:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:"using NPipeline;\r\nusing NPipeline.Nodes;\r\nusing NPipeline.Pipeline;\r\n\r\npublic sealed class RetryPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var sourceHandle = builder.AddSource<DataSource, string>();\r\n        var transformHandle = builder.AddTransform<DataTransform, string, string>();\r\n        var sinkHandle = builder.AddSink<DataSink, string>();\r\n\r\n        builder.Connect(sourceHandle, transformHandle);\r\n        builder.Connect(transformHandle, sinkHandle);\r\n\r\n        // Configure retry policy using PipelineRetryOptions\r\n        builder.WithRetryOptions(new PipelineRetryOptions(\r\n            MaxItemRetries: 3,\r\n            MaxNodeRestartAttempts: 2,\r\n            MaxSequentialNodeAttempts: 5\r\n        ));\r\n    }\r\n}\r\n\r\npublic static class Program\r\n{\r\n    public static async Task Main(string[] args)\r\n    {\r\n        var runner = new PipelineRunner();\r\n        await runner.RunAsync<RetryPipelineDefinition>();\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(r.h3,{id:"per-node-retry-options",children:"Per-Node Retry Options"}),"\n",(0,t.jsxs)(r.p,{children:["You can override the global retry options for a specific node using the ",(0,t.jsx)(r.code,{children:"WithRetryOptions"})," method that accepts a ",(0,t.jsx)(r.code,{children:"NodeHandle"}),":"]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:'using NPipeline;\r\nusing NPipeline.Nodes;\r\nusing NPipeline.Pipeline;\r\n\r\npublic sealed class PerNodeRetryPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var sourceHandle = builder.AddSource<DataSource, string>("source");\r\n        var criticalTransformHandle = builder.AddTransform<CriticalDataTransform, string, string>("critical-transform");\r\n        var normalTransformHandle = builder.AddTransform<NormalDataTransform, string, string>("normal-transform");\r\n        var sinkHandle = builder.AddSink<DataSink, string>("sink");\r\n\r\n        builder.Connect(sourceHandle, criticalTransformHandle);\r\n        builder.Connect(criticalTransformHandle, normalTransformHandle);\r\n        builder.Connect(normalTransformHandle, sinkHandle);\r\n\r\n        // Configure global retry options (default for all nodes)\r\n        builder.WithRetryOptions(new PipelineRetryOptions(\r\n            MaxItemRetries: 2,\r\n            MaxNodeRestartAttempts: 3,\r\n            MaxSequentialNodeAttempts: 5\r\n        ));\r\n\r\n        // Override retry options for the critical transform\r\n        builder.WithRetryOptions(criticalTransformHandle, new PipelineRetryOptions(\r\n            MaxItemRetries: 5,              // More retries for critical processing\r\n            MaxNodeRestartAttempts: 10,      // More restart attempts\r\n            MaxSequentialNodeAttempts: 15,   // Higher total attempt limit\r\n            MaxMaterializedItems: 1000       // Higher memory limit for replay\r\n        ));\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(r.h4,{id:"use-cases-for-per-node-retry-configuration",children:"Use Cases for Per-Node Retry Configuration"}),"\n",(0,t.jsx)(r.p,{children:"Per-node retry options are useful in scenarios where different parts of your pipeline have different resilience requirements:"}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"1. External API Calls vs. Internal Processing"})}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:"// More aggressive retries for external API calls\r\nbuilder.WithRetryOptions(apiTransformHandle, new PipelineRetryOptions(\r\n    MaxItemRetries: 5,\r\n    MaxNodeRestartAttempts: 3,\r\n    MaxSequentialNodeAttempts: 10\r\n));\r\n\r\n// Conservative retries for internal data processing\r\nbuilder.WithRetryOptions(internalTransformHandle, new PipelineRetryOptions(\r\n    MaxItemRetries: 1,\r\n    MaxNodeRestartAttempts: 2,\r\n    MaxSequentialNodeAttempts: 3\r\n));\n"})}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"2. Critical vs. Non-Critical Processing"})}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:"// Maximum resilience for critical business logic\r\nbuilder.WithRetryOptions(criticalProcessorHandle, new PipelineRetryOptions(\r\n    MaxItemRetries: 10,\r\n    MaxNodeRestartAttempts: 5,\r\n    MaxSequentialNodeAttempts: 20,\r\n    MaxMaterializedItems: 5000\r\n));\r\n\r\n// Best-effort processing for non-critical data\r\nbuilder.WithRetryOptions(loggingProcessorHandle, new PipelineRetryOptions(\r\n    MaxItemRetries: 0,  // No retries for logging\r\n    MaxNodeRestartAttempts: 1,\r\n    MaxSequentialNodeAttempts: 2\r\n));\n"})}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"3. Resource-Intensive Operations"})}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:"// Limited retries for memory-intensive operations\r\nbuilder.WithRetryOptions(memoryIntensiveHandle, new PipelineRetryOptions(\r\n    MaxItemRetries: 1,\r\n    MaxNodeRestartAttempts: 1,\r\n    MaxSequentialNodeAttempts: 2,\r\n    MaxMaterializedItems: 100  // Strict memory limit\r\n));\n"})}),"\n",(0,t.jsx)(r.h4,{id:"precedence-rules",children:"Precedence Rules"}),"\n",(0,t.jsx)(r.p,{children:"When both global and per-node retry options are configured:"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Per-node options take precedence"})," over global options"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Unspecified properties"})," in per-node options inherit from global options"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Global options"})," apply to all nodes without specific overrides"]}),"\n"]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:"// Global configuration\r\nbuilder.WithRetryOptions(new PipelineRetryOptions(\r\n    MaxItemRetries: 2,\r\n    MaxNodeRestartAttempts: 3,\r\n    MaxSequentialNodeAttempts: 5\r\n));\r\n\r\n// Per-node override (only MaxItemRetries is overridden)\r\nbuilder.WithRetryOptions(specificNodeHandle, new PipelineRetryOptions(\r\n    MaxItemRetries: 5,              // Overridden\r\n    MaxNodeRestartAttempts: 3,       // Inherited from global\r\n    MaxSequentialNodeAttempts: 5      // Inherited from global\r\n));\n"})}),"\n",(0,t.jsx)(r.h2,{id:"integrating-external-retry-libraries",children:"Integrating External Retry Libraries"}),"\n",(0,t.jsx)(r.p,{children:"For advanced retry patterns like exponential backoff and jitter, you can integrate external libraries like Polly:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:'using Polly;\r\nusing Polly.Retry;\r\nusing NPipeline.ErrorHandling;\r\n\r\npublic class AdvancedRetryHandler : INodeErrorHandler<ITransformNode<string, string>, string>\r\n{\r\n    private readonly AsyncRetryPolicy _retryPolicy;\r\n\r\n    public AdvancedRetryHandler()\r\n    {\r\n        // Configure exponential backoff with jitter\r\n        _retryPolicy = Policy\r\n            .Handle<HttpRequestException>() // Retry on network errors\r\n            .WaitAndRetryAsync(\r\n                retryCount: 5,\r\n                sleepDurationProvider: retryAttempt =>\r\n                    TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + // Exponential backoff\r\n                    TimeSpan.FromMilliseconds(new Random().Next(0, 1000)), // Add jitter\r\n                onRetry: (outcome, timespan, retryAttempt, context) =>\r\n                {\r\n                    Console.WriteLine($"Retry {retryAttempt} after {timespan.TotalSeconds}s due to: {outcome.Exception?.Message}");\r\n                });\r\n    }\r\n\r\n    public async Task<NodeErrorDecision> HandleAsync(\r\n        ITransformNode<string, string> node,\r\n        string failedItem,\r\n        Exception error,\r\n        PipelineContext context,\r\n        CancellationToken cancellationToken)\r\n    {\r\n        if (error is HttpRequestException)\r\n        {\r\n            try\r\n            {\r\n                // Execute the retry policy\r\n                await _retryPolicy.ExecuteAsync(async () =>\r\n                {\r\n                    // In a real implementation, you would re-execute the node logic here\r\n                    // This is a simplified example\r\n                    Console.WriteLine($"Retrying processing of: {failedItem}");\r\n                    await Task.Delay(100, cancellationToken);\r\n                });\r\n\r\n                return NodeErrorDecision.Retry;\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                Console.WriteLine($"All retries failed: {ex.Message}");\r\n                return NodeErrorDecision.DeadLetter; // Send to dead-letter after all retries fail\r\n            }\r\n        }\r\n\r\n        return NodeErrorDecision.Skip; // For other error types, just skip\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(r.h2,{id:"retry-strategies",children:"Retry Strategies"}),"\n",(0,t.jsx)(r.h3,{id:"fixed-delay-retry",children:"Fixed Delay Retry"}),"\n",(0,t.jsx)(r.p,{children:"The simplest retry strategy uses a fixed delay between attempts:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:'public class FixedDelayRetryHandler : INodeErrorHandler<ITransformNode<string, string>, string>\r\n{\r\n    private readonly TimeSpan _delay = TimeSpan.FromSeconds(2);\r\n    private readonly ILogger _logger;\r\n\r\n    public FixedDelayRetryHandler(ILogger logger)\r\n    {\r\n        _logger = logger;\r\n    }\r\n\r\n    public async Task<NodeErrorDecision> HandleAsync(\r\n        ITransformNode<string, string> node,\r\n        string failedItem,\r\n        Exception error,\r\n        PipelineContext context,\r\n        CancellationToken cancellationToken)\r\n    {\r\n        if (IsTransientError(error))\r\n        {\r\n            _logger.LogInformation("Retrying in {Delay}ms for item: {Item}", _delay.TotalMilliseconds, failedItem);\r\n            await Task.Delay(_delay, cancellationToken);\r\n            return NodeErrorDecision.Retry;\r\n        }\r\n\r\n        return NodeErrorDecision.Skip;\r\n    }\r\n\r\n    private static bool IsTransientError(Exception error)\r\n    {\r\n        return error is TimeoutException or HttpRequestException;\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(r.h3,{id:"exponential-backoff-with-jitter",children:"Exponential Backoff with Jitter"}),"\n",(0,t.jsx)(r.p,{children:"Exponential backoff with jitter is a more sophisticated strategy that helps prevent thundering herd problems:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:'public class ExponentialBackoffRetryHandler : INodeErrorHandler<ITransformNode<string, string>, string>\r\n{\r\n    private readonly TimeSpan _baseDelay = TimeSpan.FromSeconds(1);\r\n    private readonly TimeSpan _maxDelay = TimeSpan.FromMinutes(1);\r\n    private readonly Random _jitter = new();\r\n    private readonly ILogger _logger;\r\n\r\n    public ExponentialBackoffRetryHandler(ILogger logger)\r\n    {\r\n        _logger = logger;\r\n    }\r\n\r\n    public async Task<NodeErrorDecision> HandleAsync(\r\n        ITransformNode<string, string> node,\r\n        string failedItem,\r\n        Exception error,\r\n        PipelineContext context,\r\n        CancellationToken cancellationToken)\r\n    {\r\n        if (IsTransientError(error))\r\n        {\r\n            // Get retry count from context (you would need to implement this)\r\n            var retryCount = GetRetryCount(context, failedItem);\r\n\r\n            // Calculate exponential delay with jitter\r\n            var exponentialDelay = TimeSpan.FromSeconds(Math.Pow(2, retryCount));\r\n            var jitter = TimeSpan.FromMilliseconds(_jitter.Next(0, 1000));\r\n            var delay = TimeSpan.FromTicks(Math.Min(\r\n                (_baseDelay + exponentialDelay + jitter).Ticks,\r\n                _maxDelay.Ticks));\r\n\r\n            _logger.LogInformation("Retrying in {Delay}ms (attempt {RetryCount}) for item: {Item}",\r\n                delay.TotalMilliseconds, retryCount + 1, failedItem);\r\n\r\n            await Task.Delay(delay, cancellationToken);\r\n            return NodeErrorDecision.Retry;\r\n        }\r\n\r\n        return NodeErrorDecision.Skip;\r\n    }\r\n\r\n    private static bool IsTransientError(Exception error)\r\n    {\r\n        return error is TimeoutException or HttpRequestException;\r\n    }\r\n\r\n    private int GetRetryCount(PipelineContext context, string item)\r\n    {\r\n        // In a real implementation, you would track retry count in the context\r\n        // This is a simplified example\r\n        return 0;\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(r.h2,{id:"context-aware-retry",children:"Context-Aware Retry"}),"\n",(0,t.jsx)(r.p,{children:"Sometimes you want to adjust retry behavior based on the context:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:'public class ContextAwareRetryHandler : INodeErrorHandler<ITransformNode<string, string>, string>\r\n{\r\n    private readonly ILogger _logger;\r\n    private readonly Dictionary<string, RetryPolicy> _policies;\r\n\r\n    public ContextAwareRetryHandler(ILogger logger)\r\n    {\r\n        _logger = logger;\r\n        _policies = new Dictionary<string, RetryPolicy>\r\n        {\r\n            ["critical"] = new RetryPolicy(maxRetries: 5, baseDelay: TimeSpan.FromSeconds(1)),\r\n            ["normal"] = new RetryPolicy(maxRetries: 3, baseDelay: TimeSpan.FromSeconds(2)),\r\n            ["low"] = new RetryPolicy(maxRetries: 1, baseDelay: TimeSpan.FromSeconds(5))\r\n        };\r\n    }\r\n\r\n    public async Task<NodeErrorDecision> HandleAsync(\r\n        ITransformNode<string, string> node,\r\n        string failedItem,\r\n        Exception error,\r\n        PipelineContext context,\r\n        CancellationToken cancellationToken)\r\n    {\r\n        // Determine priority from context or item\r\n        var priority = GetPriority(context, failedItem);\r\n        var policy = _policies[priority];\r\n\r\n        if (IsTransientError(error) && policy.CanRetry)\r\n        {\r\n            _logger.LogInformation("Retrying with {Priority} policy (attempt {RetryCount}/{MaxRetries}) for item: {Item}",\r\n                priority, policy.CurrentRetry + 1, policy.MaxRetries, failedItem);\r\n\r\n            await Task.Delay(policy.GetDelay(), cancellationToken);\r\n            policy.IncrementRetry();\r\n\r\n            return NodeErrorDecision.Retry;\r\n        }\r\n\r\n        return NodeErrorDecision.Skip;\r\n    }\r\n\r\n    private static bool IsTransientError(Exception error)\r\n    {\r\n        return error is TimeoutException or HttpRequestException;\r\n    }\r\n\r\n    private string GetPriority(PipelineContext context, string item)\r\n    {\r\n        // In a real implementation, you would determine priority from context or item\r\n        // This is a simplified example\r\n        return item.Contains("critical") ? "critical" :\r\n               item.Contains("low") ? "low" : "normal";\r\n    }\r\n\r\n    private class RetryPolicy\r\n    {\r\n        public int MaxRetries { get; }\r\n        public TimeSpan BaseDelay { get; }\r\n        public int CurrentRetry { get; private set; }\r\n\r\n        public bool CanRetry => CurrentRetry < MaxRetries;\r\n\r\n        public RetryPolicy(int maxRetries, TimeSpan baseDelay)\r\n        {\r\n            MaxRetries = maxRetries;\r\n            BaseDelay = baseDelay;\r\n        }\r\n\r\n        public TimeSpan GetDelay()\r\n        {\r\n            // Simple exponential backoff\r\n            return TimeSpan.FromSeconds(Math.Pow(2, CurrentRetry) * BaseDelay.TotalSeconds);\r\n        }\r\n\r\n        public void IncrementRetry()\r\n        {\r\n            CurrentRetry++;\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,t.jsxs)(r.h2,{id:"white_check_mark-best-practices",children:["\u2705"," Best Practices"]}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Differentiate between transient and permanent errors"}),": Only retry transient errors that might resolve themselves."]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Implement appropriate delays"}),": Use delays between retries to give the system time to recover."]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Set reasonable retry limits"}),": Prevent infinite loops by setting maximum retry counts."]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Use jitter in distributed systems"}),": Add randomness to retry delays to prevent thundering herd problems."]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Monitor retry patterns"}),": Track retry metrics to identify systemic issues."]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Consider resource constraints"}),": Be mindful of the resources consumed by retries, especially in high-volume scenarios."]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"Implement circuit breakers"}),": Combine retries with circuit breakers to prevent cascading failures."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"production-example",children:"Production Example"}),"\n",(0,t.jsx)(r.p,{children:"Here's a comprehensive example that combines multiple retry strategies:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-csharp",children:'using NPipeline;\r\nusing NPipeline.ErrorHandling;\r\nusing NPipeline.Pipeline;\r\n\r\npublic class ProductionRetryHandler : INodeErrorHandler<ITransformNode<string, string>, string>\r\n{\r\n    private readonly ILogger _logger;\r\n    private readonly IMetrics _metrics;\r\n    private readonly Dictionary<string, RetryState> _retryStates = new();\r\n    private readonly TimeSpan _baseDelay = TimeSpan.FromSeconds(1);\r\n    private readonly TimeSpan _maxDelay = TimeSpan.FromMinutes(1);\r\n    private readonly Random _jitter = new();\r\n\r\n    private class RetryState\r\n    {\r\n        public int RetryCount { get; set; }\r\n        public DateTime FirstFailureTime { get; set; }\r\n    }\r\n\r\n    public ProductionRetryHandler(ILogger logger, IMetrics metrics)\r\n    {\r\n        _logger = logger;\r\n        _metrics = metrics;\r\n    }\r\n\r\n    public async Task<NodeErrorDecision> HandleAsync(\r\n        ITransformNode<string, string> node,\r\n        string failedItem,\r\n        Exception error,\r\n        PipelineContext context,\r\n        CancellationToken cancellationToken)\r\n    {\r\n        var itemKey = $"{node.Id}:{failedItem}";\r\n\r\n        if (!_retryStates.TryGetValue(itemKey, out var retryState))\r\n        {\r\n            retryState = new RetryState { FirstFailureTime = DateTime.UtcNow };\r\n            _retryStates[itemKey] = retryState;\r\n        }\r\n\r\n        // Record metrics\r\n        _metrics.Increment("item_retries", new[]\r\n        {\r\n            new KeyValuePair<string, object>("node_id", node.Id),\r\n            new KeyValuePair<string, object>("error_type", error.GetType().Name),\r\n            new KeyValuePair<string, object>("retry_count", retryState.RetryCount)\r\n        });\r\n\r\n        if (IsTransientError(error))\r\n        {\r\n            // Check if we\'ve exceeded the maximum retry count\r\n            if (retryState.RetryCount >= 3)\r\n            {\r\n                _logger.LogWarning("Maximum retries exceeded for item {Item} in node {NodeId}", failedItem, node.Id);\r\n                _retryStates.Remove(itemKey);\r\n                return NodeErrorDecision.DeadLetter;\r\n            }\r\n\r\n            // Calculate delay with exponential backoff and jitter\r\n            var exponentialDelay = TimeSpan.FromSeconds(Math.Pow(2, retryState.RetryCount));\r\n            var jitter = TimeSpan.FromMilliseconds(_jitter.Next(0, 1000));\r\n            var delay = TimeSpan.FromTicks(Math.Min(\r\n                (_baseDelay + exponentialDelay + jitter).Ticks,\r\n                _maxDelay.Ticks));\r\n\r\n            _logger.LogInformation("Retrying item {Item} in node {NodeId} (attempt {RetryCount}/{MaxRetries}) after {Delay}ms",\r\n                failedItem, node.Id, retryState.RetryCount + 1, 3, delay.TotalMilliseconds);\r\n\r\n            retryState.RetryCount++;\r\n            await Task.Delay(delay, cancellationToken);\r\n            return NodeErrorDecision.Retry;\r\n        }\r\n\r\n        // For non-transient errors, don\'t retry\r\n        _logger.LogWarning("Non-transient error for item {Item} in node {NodeId}: {ErrorType}",\r\n            failedItem, node.Id, error.GetType().Name);\r\n\r\n        _retryStates.Remove(itemKey);\r\n        return NodeErrorDecision.Skip;\r\n    }\r\n\r\n    private static bool IsTransientError(Exception error)\r\n    {\r\n        return error is TimeoutException or HttpRequestException or OperationCanceledException;\r\n    }\r\n}\n'})}),"\n",(0,t.jsxs)(r.blockquote,{children:["\n",(0,t.jsxs)(r.p,{children:["\u26a0\ufe0f"," Materialization Requirements\r\nWhen configuring retries with ",(0,t.jsx)(r.code,{children:"MaxMaterializedItems"}),", it's important to understand how buffering enables replay functionality. Materialization is critical because it creates a snapshot of input items that can be replayed if a node fails and needs to restart, preventing data loss and ensuring processing continuity. See ",(0,t.jsx)(r.a,{href:"/docs/core-concepts/resilience/materialization-and-buffering",children:"Materialization and Buffering"})," in the resilience section for detailed guidance."]}),"\n"]}),"\n",(0,t.jsxs)(r.h2,{id:"information_source-see-also",children:["\u2139\ufe0f"," See Also"]}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/resilience/",children:"Resilience Overview"})}),": Comprehensive guide to building fault-tolerant pipelines"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/resilience/materialization-and-buffering",children:"Materialization and Buffering"})}),": Understanding buffer requirements for resilience"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/resilience/configuration-guide",children:"Configuration Guide"})}),": Practical implementation guidance with code examples"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/resilience/troubleshooting",children:"Troubleshooting"})}),": Diagnose and resolve common resilience issues"]}),"\n"]}),"\n",(0,t.jsxs)(r.h2,{id:"link-related-topics",children:["\ud83d\udd17"," Related Topics"]}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/pipeline-execution/node-error-handling",children:"Node-level Error Handling"})}),": Learn about handling errors for individual items."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/pipeline-execution/pipeline-error-handling",children:"Pipeline-level Error Handling"})}),": Learn about handling errors that affect entire node streams."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/pipeline-execution/circuit-breaker-configuration",children:"Circuit Breaker Configuration"})}),": Configure circuit breaker patterns."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/pipeline-execution/dead-letter-queues",children:"Dead-Letter Queues"})}),": Implement dead-letter queues for problematic items."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:(0,t.jsx)(r.a,{href:"/docs/core-concepts/pipeline-execution/error-handling",children:"Error Handling Overview"})}),": Return to the error handling overview."]}),"\n"]})]})}function p(e={}){const{wrapper:r}={...(0,o.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);