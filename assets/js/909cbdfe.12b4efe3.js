"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[7473],{8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>t});var s=i(6540);const a={},l=s.createContext(a);function r(e){const n=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(l.Provider,{value:n},e.children)}},9579:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"samples/basic","title":"Basic Samples","description":"Fundamental NPipeline samples for beginners (Samples 1-5)","source":"@site/docs/samples/basic.md","sourceDirName":"samples","slug":"/samples/basic","permalink":"/docs/samples/basic","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Basic Samples","description":"Fundamental NPipeline samples for beginners (Samples 1-5)","sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Sample Applications","permalink":"/docs/samples/"},"next":{"title":"Intermediate Samples","permalink":"/docs/samples/intermediate"}}');var a=i(4848),l=i(8453);const r={title:"Basic Samples",description:"Fundamental NPipeline samples for beginners (Samples 1-5)",sidebar_position:2},t="Basic Samples (1-5)",o={},c=[{value:"Sample 01: Basic Pipeline",id:"sample-01-basic-pipeline",level:2},{value:"Sample 02: File Processing Pipeline",id:"sample-02-file-processing-pipeline",level:2},{value:"Sample 03: Basic Error Handling",id:"sample-03-basic-error-handling",level:2},{value:"Sample 04: Simple Data Transformation",id:"sample-04-simple-data-transformation",level:2},{value:"Sample 05: Parallel Processing",id:"sample-05-parallel-processing",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"basic-samples-1-5",children:"Basic Samples (1-5)"})}),"\n",(0,a.jsx)(n.p,{children:"These samples cover the fundamental concepts and patterns you need to get started with NPipeline. Perfect for learning the basics."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"sample-01-basic-pipeline",children:"Sample 01: Basic Pipeline"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Concepts demonstrated:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Basic source, transform, and sink nodes"}),"\n",(0,a.jsx)(n.li,{children:"Simple data flow between nodes"}),"\n",(0,a.jsx)(n.li,{children:"Pipeline definition and execution"}),"\n",(0,a.jsx)(n.li,{children:"Dependency injection integration"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"What it does:"}),' A "Hello World" pipeline that demonstrates the fundamental NPipeline concepts with a source that generates data, a transform that processes it, and a sink that outputs the results.']}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Key takeaways:"})," How to structure a basic pipeline and connect nodes together. Start here if you're new to NPipeline."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"sample-02-file-processing-pipeline",children:"Sample 02: File Processing Pipeline"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Concepts demonstrated:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"File-based source and sink nodes"}),"\n",(0,a.jsx)(n.li,{children:"Stream processing for memory efficiency"}),"\n",(0,a.jsx)(n.li,{children:"Line-by-line text transformation"}),"\n",(0,a.jsx)(n.li,{children:"Atomic file writing operations"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"What it does:"})," Reads text files line by line, processes each line with configurable transformations (prefixes, line numbers, case conversion), and writes the results to output files using atomic operations."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Key takeaways:"})," Working with file-based data sources and sinks in NPipeline."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"sample-03-basic-error-handling",children:"Sample 03: Basic Error Handling"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Concepts demonstrated:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Try-catch patterns in pipeline nodes"}),"\n",(0,a.jsx)(n.li,{children:"Basic retry logic with exponential backoff"}),"\n",(0,a.jsx)(n.li,{children:"Error logging and collection"}),"\n",(0,a.jsx)(n.li,{children:"Graceful degradation with fallback mechanisms"}),"\n",(0,a.jsx)(n.li,{children:"Error isolation to prevent cascading failures"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"What it does:"})," Implements a pipeline with comprehensive error handling, including retries with exponential backoff, fallback mechanisms, and error tracking. Shows how to build resilient pipelines that maintain service availability during failures."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Key takeaways:"})," Designing pipelines that gracefully handle failures and maintain data integrity. Builds on Sample 01 concepts and is essential for production systems."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"sample-04-simple-data-transformation",children:"Sample 04: Simple Data Transformation"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Concepts demonstrated:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"CSV to object transformation"}),"\n",(0,a.jsx)(n.li,{children:"Data validation patterns"}),"\n",(0,a.jsx)(n.li,{children:"Filtering mechanisms"}),"\n",(0,a.jsx)(n.li,{children:"Data enrichment"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"What it does:"})," Reads CSV data, validates it according to business rules, filters based on age and location, and enriches it with additional information like country and age categories."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Key takeaways:"})," Implementing data validation, filtering, and enrichment patterns in data processing pipelines."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"sample-05-parallel-processing",children:"Sample 05: Parallel Processing"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Concepts demonstrated:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Parallel execution strategies"}),"\n",(0,a.jsx)(n.li,{children:"Resource management"}),"\n",(0,a.jsx)(n.li,{children:"Thread safety"}),"\n",(0,a.jsx)(n.li,{children:"Performance monitoring"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"What it does:"})," Demonstrates parallel processing capabilities for CPU-intensive workloads, showing how to configure and use parallel execution strategies for optimal resource utilization."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Key takeaways:"})," How to leverage parallelism while avoiding common pitfalls and managing resources effectively."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Ready for intermediate patterns? \u2192 ",(0,a.jsx)(n.a,{href:"/docs/samples/intermediate",children:"Intermediate Samples (6-10)"})]}),"\n",(0,a.jsxs)(n.li,{children:["Need advanced techniques? \u2192 ",(0,a.jsx)(n.a,{href:"/docs/samples/advanced",children:"Advanced Samples (11-23)"})]}),"\n",(0,a.jsxs)(n.li,{children:["Looking for a specific topic? \u2192 ",(0,a.jsx)(n.a,{href:"/docs/samples/by-topic",children:"Samples by Topic"})]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);