"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[685],{2965:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"core-concepts/nodes/batching","title":"Batching Nodes","description":"Learn how to group data items into batches for efficient processing in NPipeline.","source":"@site/docs/core-concepts/nodes/batching.md","sourceDirName":"core-concepts/nodes","slug":"/core-concepts/nodes/batching","permalink":"/docs/core-concepts/nodes/batching","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Batching Nodes","description":"Learn how to group data items into batches for efficient processing in NPipeline.","sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Source Nodes","permalink":"/docs/core-concepts/nodes/source-nodes"},"next":{"title":"Transform Nodes","permalink":"/docs/core-concepts/nodes/transform-nodes"}}');var r=i(4848),a=i(8453);const o={title:"Batching Nodes",description:"Learn how to group data items into batches for efficient processing in NPipeline.",sidebar_position:2},s="Batching Nodes",c={},l=[{value:"<code>BatchingNode&lt;T&gt;</code>",id:"batchingnodet",level:2},{value:"How It Works: A Practical Operational Choice",id:"how-it-works-a-practical-operational-choice",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Example: Basic Batching",id:"example-basic-batching",level:3},{value:"<code>BatchingPipelineBuilderExtensions</code>",id:"batchingpipelinebuilderextensions",level:2},{value:"Architectural Costs and Considerations",id:"architectural-costs-and-considerations",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"batching-nodes",children:"Batching Nodes"})}),"\n",(0,r.jsxs)(n.p,{children:["Batching nodes represent a deliberate operational shift in how NPipeline processes data. While NPipeline is built on the principle of ",(0,r.jsx)(n.strong,{children:"strict item-by-item flow control"}),"\u2014where each data item is processed individually and immediately forwarded\u2014batching groups items together for specific practical reasons."]}),"\n",(0,r.jsxs)(n.p,{children:["Batching is used when downstream operations need collecting a specified number of input items or items over a certain time period before processing them as a group. This is not an optimization but often a ",(0,r.jsx)(n.strong,{children:"necessity"})," for certain workloads: ",(0,r.jsx)(n.strong,{children:"bulk database inserts, transactional boundaries, and API calls that accept multiple records"})," require this grouping approach."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Architectural Pattern Shared with Aggregation:"})," Like ",(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/aggregation",children:"aggregation nodes"}),", batching represents a shift from NPipeline's item-level streaming model to higher-level data grouping. Both require you to step outside the default item-by-item pattern. The key difference: ",(0,r.jsx)(n.strong,{children:"batching groups by count/time"})," for operational efficiency, while ",(0,r.jsx)(n.strong,{children:"aggregation groups by key and event time"})," for data correctness. See ",(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/aggregation",children:"Aggregation Nodes"})," for patterns that handle temporal ordering of events."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["NPipeline provides the ",(0,r.jsx)(n.a,{href:"src/NPipeline/Nodes/Batching/BatchingNode.cs",children:(0,r.jsx)(n.code,{children:"BatchingNode<T>"})})," transform node and related extensions to simplify batching operations."]}),"\n",(0,r.jsx)(n.h2,{id:"batchingnodet",children:(0,r.jsx)(n.a,{href:"src/NPipeline/Nodes/Batching/BatchingNode.cs",children:(0,r.jsx)(n.code,{children:"BatchingNode<T>"})})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.a,{href:"src/NPipeline/Nodes/Batching/BatchingNode.cs",children:(0,r.jsx)(n.code,{children:"BatchingNode<T>"})})," is a transform that takes individual items of type ",(0,r.jsx)(n.code,{children:"T"})," and outputs ",(0,r.jsx)(n.code,{children:"IReadOnlyCollection<T>"}),", representing a batch of items."]}),"\n",(0,r.jsx)(n.h3,{id:"how-it-works-a-practical-operational-choice",children:"How It Works: A Practical Operational Choice"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"BatchingNode<T>"})," relies on the ",(0,r.jsx)(n.a,{href:"src/NPipeline/Execution/Strategies/BatchingExecutionStrategy.cs",children:(0,r.jsx)(n.code,{children:"BatchingExecutionStrategy"})})," to handle batching logic. The ",(0,r.jsx)(n.code,{children:"ExecuteAsync"})," method throws a ",(0,r.jsx)(n.code,{children:"NotSupportedException"})," when called directly\u2014this signals that batching requires special handling: control shifts from processing individual items to the execution strategy's management of collected batches."]}),"\n",(0,r.jsxs)(n.p,{children:["The batching strategy collects items until either the configured batch size is reached or a timeout expires, then emits the collected batch as ",(0,r.jsx)(n.code,{children:"IReadOnlyCollection<T>"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsx)(n.p,{children:"When you configure batching, you define explicit trade-offs:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch Size:"})," Maximum items per batch. Larger sizes increase throughput but increase latency and memory usage\u2014items wait in the accumulator before processing."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch Timeout:"})," Maximum time to wait before emitting a partial batch. Shorter timeouts reduce latency; longer timeouts allow more accumulation and better efficiency."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-basic-batching",children:"Example: Basic Batching"}),"\n",(0,r.jsx)(n.p,{children:"Let's create a pipeline that batches individual integers into lists of 3."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'using NPipeline;\r\nusing NPipeline.Nodes;\r\nusing NPipeline.Pipeline;\r\n\r\n/// <summary>\r\n/// Source node that produces a sequence of integers.\r\n/// Demonstrates basic source pattern with controlled output.\r\n/// </summary>\r\npublic sealed class IntSource : SourceNode<int>\r\n{\r\n    public override IDataPipe<int> ExecuteAsync(PipelineContext context, CancellationToken cancellationToken)\r\n    {\r\n        // Create streaming data pipe immediately (synchronous operation)\r\n        return new StreamingDataPipe<int>(GenerateNumbers());\r\n\r\n        static async IAsyncEnumerable<int> GenerateNumbers()\r\n        {\r\n            // Produce 7 items with small delays to simulate work\r\n            for (int i = 1; i <= 7; i++)\r\n            {\r\n                if (cancellationToken.IsCancellationRequested) yield break;\r\n                Console.WriteLine($"Source: Producing {i}");\r\n                yield return i;\r\n                await Task.Delay(10, cancellationToken);\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n/// <summary>\r\n/// Sink node that consumes batches of integers.\r\n/// Demonstrates batch processing pattern for grouped data.\r\n/// </summary>\r\npublic sealed class BatchConsumerSink : SinkNode<IReadOnlyCollection<int>>\r\n{\r\n    /// <summary>\r\n    /// Processes each batch as it arrives from batching node.\r\n    /// Uses await foreach to efficiently iterate through batch stream.\r\n    /// </summary>\r\n    public async Task ExecuteAsync(\r\n        IDataPipe<IReadOnlyCollection<int>> input, \r\n        PipelineContext context, \r\n        CancellationToken cancellationToken)\r\n    {\r\n        await foreach (var batch in input.WithCancellation(cancellationToken))\r\n        {\r\n            // Process entire batch at once\r\n            Console.WriteLine($"Sink: Consumed batch of {batch.Count} items: [{string.Join(", ", batch)}]");\r\n        }\r\n    }\r\n}\r\n\r\n/// <summary>\r\n/// Pipeline definition demonstrating basic batching functionality.\r\n/// Shows how to configure batching with size and timeout parameters.\r\n/// </summary>\r\npublic sealed class BatchingPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        // Add nodes to pipeline with descriptive names\r\n        var sourceHandle = builder.AddSource<IntSource, int>("int_source");\r\n        var batchHandle = builder.AddTransform<BatchingNode<int>, int, IReadOnlyCollection<int>>("batch_node");\r\n        var sinkHandle = builder.AddSink<BatchConsumerSink, IReadOnlyCollection<int>>("batch_sink");\r\n\r\n        // Connect nodes to define data flow\r\n        builder.Connect(sourceHandle, batchHandle);\r\n        builder.Connect(batchHandle, sinkHandle);\r\n    }\r\n}\r\n\r\npublic static class Program\r\n{\r\n    public static async Task Main(string[] args)\r\n    {\r\n        var context = PipelineContext.Default;\r\n        var runner = PipelineRunner.Create();\r\n        \r\n        Console.WriteLine("Starting batching pipeline...");\r\n        await runner.RunAsync<BatchingPipelineDefinition>(context);\r\n        Console.WriteLine("Batching pipeline finished.");\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Expected Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"Starting batching pipeline...\r\nSource: Producing 1\r\nSource: Producing 2\r\nSource: Producing 3\r\nSink: Consumed batch of 3 items: [1, 2, 3]\r\nSource: Producing 4\r\nSource: Producing 5\r\nSource: Producing 6\r\nSink: Consumed batch of 3 items: [4, 5, 6]\r\nSource: Producing 7\r\nSink: Consumed batch of 1 items: [7]\r\nBatching pipeline finished.\n"})}),"\n",(0,r.jsx)(n.p,{children:"Notice that the last batch contains only 1 item because the source finished producing, and the timeout (or end of pipeline) triggered the emission of the partial batch."}),"\n",(0,r.jsx)(n.h2,{id:"batchingpipelinebuilderextensions",children:(0,r.jsx)(n.a,{href:"src/NPipeline/Pipeline/BatchingPipelineBuilderExtensions.cs",children:(0,r.jsx)(n.code,{children:"BatchingPipelineBuilderExtensions"})})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.a,{href:"src/NPipeline/Pipeline/BatchingPipelineBuilderExtensions.cs",children:(0,r.jsx)(n.code,{children:"BatchingPipelineBuilderExtensions"})})," provide a convenient fluent API for adding batching functionality to your pipeline. The ",(0,r.jsx)(n.code,{children:"Batch()"})," extension method simplifies the creation and configuration of ",(0,r.jsx)(n.a,{href:"src/NPipeline/Nodes/Batching/BatchingNode.cs",children:(0,r.jsx)(n.code,{children:"BatchingNode<T>"})}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'using NPipeline;\r\nusing NPipeline.Pipeline;\r\n\r\n/// <summary>\r\n/// Pipeline definition using batching extension method.\r\n/// Demonstrates fluent API for configuring batching behavior.\r\n/// </summary>\r\npublic sealed class BatchExtensionPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        // Add source node\r\n        var sourceHandle = builder.AddSource<MySource, int>("source");\r\n        \r\n        // Add batching with explicit configuration\r\n        // Batch size: 10 items maximum per batch\r\n        // Timeout: 5 seconds maximum wait before emitting partial batch\r\n        var batchHandle = builder.AddBatch<int>(\r\n            batchSize: 10, \r\n            batchTimeout: TimeSpan.FromSeconds(5)\r\n        );\r\n        \r\n        // Add sink for batch processing\r\n        var sinkHandle = builder.AddSink<MyBatchProcessingSink, IReadOnlyCollection<int>>("sink");\r\n\r\n        // Connect nodes to define data flow\r\n        builder.Connect(sourceHandle, batchHandle);\r\n        builder.Connect(batchHandle, sinkHandle);\r\n    }\r\n}\r\n\r\n/// <summary>\r\n/// Source node for demonstration purposes.\r\n/// </summary>\r\npublic sealed class MySource : SourceNode<int>\r\n{\r\n    public override IDataPipe<int> ExecuteAsync(PipelineContext context, CancellationToken cancellationToken)\r\n    {\r\n        return new StreamingDataPipe<int>(GenerateItems());\r\n\r\n        static async IAsyncEnumerable<int> GenerateItems()\r\n        {\r\n            var random = new Random();\r\n            for (int i = 0; i < 25; i++) // Produce 25 items\r\n            {\r\n                if (cancellationToken.IsCancellationRequested) yield break;\r\n                yield return random.Next(1, 100);\r\n                await Task.Delay(100, cancellationToken);\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n/// <summary>\r\n/// Sink node that processes batches with business logic.\r\n/// </summary>\r\npublic sealed class MyBatchProcessingSink : SinkNode<IReadOnlyCollection<int>>\r\n{\r\n    public async Task ExecuteAsync(\r\n        IDataPipe<IReadOnlyCollection<int>> input, \r\n        PipelineContext context, \r\n        CancellationToken cancellationToken)\r\n    {\r\n        await foreach (var batch in input.WithCancellation(cancellationToken))\r\n        {\r\n            // Process batch with business logic\r\n            ProcessBatch(batch);\r\n        }\r\n    }\r\n\r\n    private void ProcessBatch(IReadOnlyCollection<int> batch)\r\n    {\r\n        var sum = batch.Sum();\r\n        var average = batch.Count > 0 ? (double)sum / batch.Count : 0;\r\n        var min = batch.Min();\r\n        var max = batch.Max();\r\n        \r\n        Console.WriteLine($"Batch of {batch.Count} items: Sum={sum}, Avg={average:F2}, Min={min}, Max={max}");\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"architectural-costs-and-considerations",children:"Architectural Costs and Considerations"}),"\n",(0,r.jsx)(n.p,{children:"Batching represents a deliberate choice to group items together. Understand these practical trade-offs:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Latency vs. Throughput:"})," Batching increases throughput by deferring item emission, which necessarily increases latency. Individual items wait in the accumulator before processing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"State Management:"})," Unlike streaming, batching requires higher-level state management (the accumulated batch). If an error occurs within a batch, the entire batch's context is affected\u2014you cannot isolate errors to single items."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Partial Batches:"})," Ensure downstream nodes handle partial batches gracefully, especially at pipeline completion or timeout."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Error Handling:"})," Decide whether errors should fail the entire batch or only problematic items\u2014more complex than item-by-item processing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Memory Footprint:"})," Large batch sizes consume more memory. Balance throughput requirements against available memory."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Use batching when operational necessity (database efficiency, transactional boundaries, API constraints) justifies this architectural cost."}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/join",children:"Join Nodes"})}),": Learn how to merge data from multiple input streams."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/core-concepts/nodes/lookup",children:"Lookup Nodes"})}),": Discover how to enrich data by querying external sources."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>s});var t=i(6540);const r={},a=t.createContext(r);function o(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);