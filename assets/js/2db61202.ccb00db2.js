"use strict";(self.webpackChunknpipeline=self.webpackChunknpipeline||[]).push([[2282],{5450:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"core-concepts/pipeline-execution/execution-strategies","title":"Execution Strategies","description":"Learn how to control the execution flow and resilience of your NPipeline nodes using various execution strategies.","source":"@site/docs/core-concepts/pipeline-execution/execution-strategies.md","sourceDirName":"core-concepts/pipeline-execution","slug":"/core-concepts/pipeline-execution/execution-strategies","permalink":"/docs/core-concepts/pipeline-execution/execution-strategies","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Execution Strategies","description":"Learn how to control the execution flow and resilience of your NPipeline nodes using various execution strategies.","sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"IPipelineRunner","permalink":"/docs/core-concepts/pipeline-execution/ipipelinerunner"},"next":{"title":"Error Handling","permalink":"/docs/core-concepts/pipeline-execution/error-handling"}}');var t=r(4848),s=r(8453);const o={title:"Execution Strategies",description:"Learn how to control the execution flow and resilience of your NPipeline nodes using various execution strategies.",sidebar_position:3},l="Execution Strategies",a={},c=[{value:"<code>IExecutionStrategy</code>",id:"iexecutionstrategy",level:2},{value:"Applying an Execution Strategy",id:"applying-an-execution-strategy",level:2},{value:"Built-in Execution Strategies",id:"built-in-execution-strategies",level:2},{value:"1. <code>SequentialExecutionStrategy</code>",id:"1-sequentialexecutionstrategy",level:3},{value:"2. <code>ParallelExecutionStrategy</code>",id:"2-parallelexecutionstrategy",level:3},{value:"Configuration Options (<code>ParallelOptions</code>)",id:"configuration-options-paralleloptions",level:4},{value:"Example: Parallel Processing with Bounded Queue",id:"example-parallel-processing-with-bounded-queue",level:4},{value:"Example: Non-Ordered Parallel Execution for Maximum Throughput",id:"example-non-ordered-parallel-execution-for-maximum-throughput",level:4},{value:"When to Use Non-Ordered Execution",id:"when-to-use-non-ordered-execution",level:4},{value:"3. <code>ResilientExecutionStrategy</code>",id:"3-resilientexecutionstrategy",level:3},{value:"Materialization Behavior",id:"materialization-behavior",level:4},{value:"Example: Resilient Parallel Execution",id:"example-resilient-parallel-execution",level:4},{value:"\ud83d\udca1 Comprehensive Documentation",id:"bulb-comprehensive-documentation",level:2},{value:"\u2139\ufe0f See Also",id:"information_source-see-also",level:2},{value:"\u27a1\ufe0f Next Steps",id:"arrow_right-next-steps",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"execution-strategies",children:"Execution Strategies"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["\u2139\ufe0f"," ",(0,t.jsx)(n.strong,{children:"Documentation Scope"}),"\r\nThis guide covers ",(0,t.jsx)(n.strong,{children:"all execution strategies"})," - sequential, parallel, and resilient. If you need to add ",(0,t.jsx)(n.strong,{children:"resilience capabilities"})," (error handling, retries, node restart) to a strategy, see ",(0,t.jsx)(n.a,{href:"/docs/core-concepts/resilience/resilient-execution-strategy",children:"Resilient Execution Strategy"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Execution strategies define how a node processes its input stream and produces its output. They are crucial for controlling parallelism, managing backpressure, and implementing resilience patterns within your NPipeline. By default, nodes execute sequentially, but you can configure them to run in parallel or with built-in fault tolerance."}),"\n",(0,t.jsxs)(n.p,{children:["Execution strategies primarily apply to ",(0,t.jsx)(n.a,{href:"/docs/core-concepts/nodes/#transform-nodes",children:"Transform Nodes"})," and custom nodes that implement ",(0,t.jsx)(n.code,{children:"ITransformNode"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"iexecutionstrategy",children:(0,t.jsx)(n.code,{children:"IExecutionStrategy"})}),"\n",(0,t.jsxs)(n.p,{children:["The core interface for all execution strategies is ",(0,t.jsx)(n.a,{href:"../../../src/NPipeline/Abstractions/Execution/IExecutionStrategy.cs",children:(0,t.jsx)(n.code,{children:"IExecutionStrategy"})}),". It defines a single method:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"public interface IExecutionStrategy\r\n{\r\n    Task<IDataPipe<TOut>> ExecuteAsync<TIn, TOut>(\r\n        IDataPipe<TIn> input,\r\n        ITransformNode<TIn, TOut> node,\r\n        PipelineContext context,\r\n        IPipelineActivity parentActivity,\r\n        CancellationToken cancellationToken);\r\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:"This method takes an input data pipe, the transform node itself, the pipeline context, a parent tracing activity, and a cancellation token, returning an output data pipe."}),"\n",(0,t.jsx)(n.h2,{id:"applying-an-execution-strategy",children:"Applying an Execution Strategy"}),"\n",(0,t.jsx)(n.p,{children:"You apply an execution strategy to a node using fluent extension methods on the node handle. This provides a chainable, expressive API:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"var transform = builder\r\n    .AddTransform<MyTransform, int, string>()\r\n    .WithExecutionStrategy(builder, new ParallelExecutionStrategy(maxDegreeOfParallelism: 4));\n"})}),"\n",(0,t.jsx)(n.p,{children:"For parallel strategies in the Extensions.Parallelism package, use specialized convenience methods:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"var transform = builder\r\n    .AddTransform<MyTransform, int, string>()\r\n    .WithBlockingParallelism(builder, maxDegreeOfParallelism: 4);  // Blocks/applies backpressure\n"})}),"\n",(0,t.jsx)(n.h2,{id:"built-in-execution-strategies",children:"Built-in Execution Strategies"}),"\n",(0,t.jsx)(n.p,{children:"NPipeline provides several out-of-the-box execution strategies:"}),"\n",(0,t.jsxs)(n.h3,{id:"1-sequentialexecutionstrategy",children:["1. ",(0,t.jsx)(n.code,{children:"SequentialExecutionStrategy"})]}),"\n",(0,t.jsx)(n.mermaid,{value:"graph TD\r\n    A[Input: 1, 2, 3] --\x3e B[Process: 1]\r\n    B --\x3e C[Output: 1]\r\n    C --\x3e D[Process: 2]\r\n    D --\x3e E[Output: 2]\r\n    E --\x3e F[Process: 3]\r\n    F --\x3e G[Output: 3]"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Figure: Sequential execution processes items one by one in order."})}),"\n",(0,t.jsx)(n.p,{children:"This is the default execution strategy. Items are processed one by one, in the order they arrive. It's simple, predictable, and suitable for scenarios where order is critical and parallelism is not required or would introduce unnecessary complexity."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"// Explicitly applying the default strategy (usually the default, so not necessary)\r\nvar transform = builder\r\n    .AddTransform<MyTransform, int, string>()\r\n    .WithExecutionStrategy(builder, new SequentialExecutionStrategy());\n"})}),"\n",(0,t.jsxs)(n.h3,{id:"2-parallelexecutionstrategy",children:["2. ",(0,t.jsx)(n.code,{children:"ParallelExecutionStrategy"})]}),"\n",(0,t.jsx)(n.mermaid,{value:"graph TD\r\n    A[Input: 1, 2, 3, 4, 5] --\x3e B[Worker 1: Process 1]\r\n    A --\x3e C[Worker 2: Process 2]\r\n    A --\x3e D[Worker 3: Process 3]\r\n\r\n    B --\x3e E[Output: 1]\r\n    C --\x3e F[Output: 2]\r\n    D --\x3e G[Output: 3]\r\n\r\n    B -.-> H[Worker 1: Process 4]\r\n    C -.-> I[Worker 2: Process 5]\r\n\r\n    H --\x3e J[Output: 4]\r\n    I --\x3e K[Output: 5]"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Figure: Parallel execution distributes items across multiple workers."})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"ParallelExecutionStrategy"})," processes items concurrently using TPL Dataflow. This is ideal for CPU-bound or I/O-bound operations where items can be processed independently to improve throughput."]}),"\n",(0,t.jsxs)(n.p,{children:["This strategy is part of the ",(0,t.jsx)(n.code,{children:"NPipeline.Extensions.Parallelism"})," NuGet package."]}),"\n",(0,t.jsxs)(n.h4,{id:"configuration-options-paralleloptions",children:["Configuration Options (",(0,t.jsx)(n.code,{children:"ParallelOptions"}),")"]}),"\n",(0,t.jsxs)(n.p,{children:["When using ",(0,t.jsx)(n.code,{children:"ParallelExecutionStrategy"}),", you can configure its behavior using ",(0,t.jsx)(n.code,{children:"ParallelOptions"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"MaxDegreeOfParallelism"})}),": The maximum number of items to process concurrently. Defaults to ",(0,t.jsx)(n.code,{children:"Environment.ProcessorCount"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"MaxQueueLength"})}),": The maximum number of input items to buffer. This controls backpressure."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"QueuePolicy"})}),": Defines how to handle new items when ",(0,t.jsx)(n.code,{children:"MaxQueueLength"})," is reached:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"BoundedQueuePolicy.Block"})," (default): The pipeline will pause upstream to wait for space in the queue."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"BoundedQueuePolicy.DropNewest"}),": New incoming items are dropped when the queue is full."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"BoundedQueuePolicy.DropOldest"}),": The oldest items in the queue are dropped to make space for new ones."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"PreserveOrdering"})}),": If ",(0,t.jsx)(n.code,{children:"true"}),", output items are emitted in the same order as their corresponding input items. If ",(0,t.jsx)(n.code,{children:"false"}),", items are emitted as soon as they are processed, potentially out of order, which can increase throughput. Defaults to ",(0,t.jsx)(n.code,{children:"true"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"OutputBufferCapacity"})}),": The maximum number of processed items to buffer before sending them downstream. This can help smooth out bursts in processing."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"example-parallel-processing-with-bounded-queue",children:"Example: Parallel Processing with Bounded Queue"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using NPipeline;\r\nusing NPipeline.Pipeline;\r\nusing NPipeline.Extensions.Parallelism;\r\nusing NPipeline.Extensions.Testing;\r\n\r\n// A simple transform that simulates some work and potentially reorders items\r\npublic class AsyncTransform : TransformNode<int, string>\r\n{\r\n    private readonly int _delayMs;\r\n\r\n    public AsyncTransform(int delayMs) => _delayMs = delayMs;\r\n\r\n    public override async Task<string> ExecuteAsync(int item, PipelineContext context, CancellationToken cancellationToken)\r\n    {\r\n        await Task.Delay(_delayMs, cancellationToken);\r\n        return $"Processed:{item}";\r\n    }\r\n}\r\n\r\n// Pipeline definition with parameterless constructor\r\npublic sealed class ParallelPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var sourceHandle = builder.AddSource<InMemorySourceNode<int>, int>("source");\r\n        var transformHandle = builder\r\n            .AddTransform<AsyncTransform, int, string>("asyncProcessor")\r\n            .WithExecutionStrategy(builder, new ParallelExecutionStrategy());\r\n        var sinkHandle = builder.AddSink<ConsoleSink<string>, string>("sink");\r\n\r\n        builder.Connect(sourceHandle, transformHandle);\r\n        builder.Connect(transformHandle, sinkHandle);\r\n\r\n        builder.SetNodeExecutionOption(transformHandle.Id, new ParallelOptions\r\n        {\r\n            MaxDegreeOfParallelism = 4,      // Process up to 4 items concurrently\r\n            MaxQueueLength = 2,              // Allow up to 2 items in the input buffer\r\n            QueuePolicy = BoundedQueuePolicy.Block, // Block if the queue is full\r\n            PreserveOrdering = true          // Ensure output order matches input order\r\n        });\r\n    }\r\n}\r\n\r\npublic static class Program\r\n{\r\n    public static async Task Main(string[] args)\r\n    {\r\n        var runner = new PipelineRunner();\r\n        var context = PipelineContext.Default;\r\n\r\n        // Configure parallel execution for the \'asyncProcessor\' node\r\n        await runner.RunAsync<ParallelPipelineDefinition>(context);\r\n    }\r\n}\r\n\r\npublic sealed class ParallelPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var sourceHandle = builder.AddSource<InMemorySourceNode<int>, int>("source");\r\n        var transformHandle = builder\r\n            .AddTransform<AsyncTransform, int, string>("asyncProcessor")\r\n            .WithExecutionStrategy(builder, new ParallelExecutionStrategy());\r\n        var sinkHandle = builder.AddSink<ConsoleSink<string>, string>("sink");\r\n\r\n        builder.Connect(sourceHandle, transformHandle);\r\n        builder.Connect(transformHandle, sinkHandle);\r\n\r\n        builder.SetNodeExecutionOption(transformHandle.Id, new ParallelOptions\r\n        {\r\n            MaxDegreeOfParallelism = 4,      // Process up to 4 items concurrently\r\n            MaxQueueLength = 2,              // Allow up to 2 items in the input buffer\r\n            QueuePolicy = BoundedQueuePolicy.Block, // Block if the queue is full\r\n            PreserveOrdering = true          // Ensure output order matches input order\r\n        });\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h4,{id:"example-non-ordered-parallel-execution-for-maximum-throughput",children:"Example: Non-Ordered Parallel Execution for Maximum Throughput"}),"\n",(0,t.jsxs)(n.p,{children:["When order preservation is not required, setting ",(0,t.jsx)(n.code,{children:"PreserveOrdering"})," to ",(0,t.jsx)(n.code,{children:"false"})," can significantly increase throughput, especially when processing times vary:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using NPipeline;\r\nusing NPipeline.Pipeline;\r\nusing NPipeline.Extensions.Parallelism;\r\nusing NPipeline.Extensions.Testing;\r\n\r\n// A transform with variable processing time\r\npublic class VariableTimeTransform : TransformNode<int, string>\r\n{\r\n    private readonly Random _random = new();\r\n\r\n    public override async Task<string> ExecuteAsync(int item, PipelineContext context, CancellationToken cancellationToken)\r\n    {\r\n        // Simulate variable processing time (50ms to 200ms)\r\n        var delay = _random.Next(50, 200);\r\n        await Task.Delay(delay, cancellationToken);\r\n\r\n        return $"Item:{item} (Processed in {delay}ms)";\r\n    }\r\n}\r\n\r\n// Pipeline definition with fluent configuration\r\npublic sealed class NonOrderedParallelPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var sourceHandle = builder.AddSource<InMemorySourceNode<int>, int>("source");\r\n        var transformHandle = builder\r\n            .AddTransform<VariableTimeTransform, int, string>("variableProcessor")\r\n            .WithExecutionStrategy(builder, new ParallelExecutionStrategy());\r\n        var sinkHandle = builder.AddSink<ConsoleSink<string>, string>("sink");\r\n\r\n        builder.Connect(sourceHandle, transformHandle);\r\n        builder.Connect(transformHandle, sinkHandle);\r\n\r\n        builder.SetNodeExecutionOption(transformHandle.Id, new ParallelOptions\r\n        {\r\n            MaxDegreeOfParallelism = 8,      // Higher degree of parallelism\r\n            MaxQueueLength = 50,             // Larger input buffer\r\n            QueuePolicy = BoundedQueuePolicy.Block,\r\n            PreserveOrdering = false         // Disable ordering for maximum throughput\r\n        });\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"In this example, items are processed as soon as they complete, without waiting for slower items. This approach:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Increases throughput"}),": Items are emitted immediately upon completion"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reduces memory usage"}),": No need to buffer items to maintain order"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Improves latency"}),": Faster items don't wait for slower ones"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Results in unordered output"}),": The output sequence may not match the input sequence"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"when-to-use-non-ordered-execution",children:"When to Use Non-Ordered Execution"}),"\n",(0,t.jsxs)(n.p,{children:["Consider ",(0,t.jsx)(n.code,{children:"PreserveOrdering = false"})," when:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Downstream processing is order-agnostic"}),": Your operations don't depend on input sequence"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Performance is critical"}),": Maximizing throughput is more important than order"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Processing times are unpredictable"}),": When some items take significantly longer than others"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"You're aggregating data"}),": When collecting statistics or metrics where order doesn't matter"]}),"\n"]}),"\n",(0,t.jsxs)(n.h3,{id:"3-resilientexecutionstrategy",children:["3. ",(0,t.jsx)(n.code,{children:"ResilientExecutionStrategy"})]}),"\n",(0,t.jsx)(n.mermaid,{value:"graph TD\r\n    A[Input Stream] --\x3e B[Resilient Wrapper]\r\n    B --\x3e C[Inner Execution Strategy]\r\n    C --\x3e D[Node Processing]\r\n    D --\x3e E{Success?}\r\n    E --\x3e|Yes| F[Output]\r\n    E --\x3e|No| G[Error Handler]\r\n    G --\x3e H{Retry?}\r\n    H --\x3e|Yes| C\r\n    H --\x3e|No| I[Circuit Breaker]\r\n    I --\x3e J{Circuit Open?}\r\n    J --\x3e|No| C\r\n    J --\x3e|Yes| K[Fail Fast]"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Figure: Resilient execution provides error handling, retries, and circuit breaker functionality."})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"ResilientExecutionStrategy"})," wraps another execution strategy (e.g., ",(0,t.jsx)(n.code,{children:"SequentialExecutionStrategy"})," or ",(0,t.jsx)(n.code,{children:"ParallelExecutionStrategy"}),") to provide robust error handling capabilities. It integrates with NPipeline's ",(0,t.jsx)(n.a,{href:"error-handling",children:"error handling mechanisms"})," to implement:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Node Restart"}),": Automatically re-executes a node if its underlying stream fails."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Circuit Breaker"}),": Prevents repeated failures by temporarily stopping execution if a failure threshold is met."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Retry Logic"}),": Retries individual item processing within a node."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Materialization"}),": Buffers input items to allow for efficient restarts without re-reading from the original source."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This strategy is part of core ",(0,t.jsx)(n.code,{children:"NPipeline"})," library."]}),"\n",(0,t.jsx)(n.h4,{id:"materialization-behavior",children:"Materialization Behavior"}),"\n",(0,t.jsxs)(n.p,{children:["When using ",(0,t.jsx)(n.code,{children:"ResilientExecutionStrategy"}),", input items are materialized (buffered) to enable node restarts. This behavior is controlled by the ",(0,t.jsx)(n.code,{children:"MaxMaterializedItems"})," parameter in ",(0,t.jsx)(n.code,{children:"PipelineRetryOptions"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.strong,{children:["When ",(0,t.jsx)(n.code,{children:"MaxMaterializedItems"})," is null"]})," (default): Unbounded materialization - all items are buffered"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.strong,{children:["When ",(0,t.jsx)(n.code,{children:"MaxMaterializedItems"})," has a value"]}),": Limited materialization - only the specified number of items are buffered, after which new items replace oldest ones"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Materialization ensures that if a node fails and needs to restart, the pipeline can replay items from the buffer instead of re-reading from the original source, which might not support replay."}),"\n",(0,t.jsx)(n.h4,{id:"example-resilient-parallel-execution",children:"Example: Resilient Parallel Execution"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using NPipeline;\r\nusing NPipeline.ErrorHandling;\r\nusing NPipeline.Execution.Strategies;\r\nusing NPipeline.Extensions.Parallelism;\r\nusing NPipeline.Extensions.Testing;\r\nusing NPipeline.Pipeline;\r\n\r\n// A transform that sometimes fails\r\npublic class FlakyTransform : TransformNode<int, string>\r\n{\r\n    private int _failCount = 0;\r\n\r\n    public override Task<string> ExecuteAsync(int item, PipelineContext context, CancellationToken cancellationToken)\r\n    {\r\n        if (item % 3 == 0 && _failCount < 2) // Fail for multiples of 3, up to 2 times\r\n        {\r\n            _failCount++;\r\n            throw new InvalidOperationException($"Simulated failure for item {item}");\r\n        }\r\n        return Task.FromResult($"Processed:{item} (Attempt: {_failCount + 1})");\r\n    }\r\n}\r\n\r\n// Pipeline definition with parameterless constructor\r\npublic sealed class ResilientPipelineDefinition : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var sourceHandle = builder.AddSource<InMemorySourceNode<int>, int>("source");\r\n        var transformHandle = builder.AddTransform<FlakyTransform, int, string>("flakyProcessor");\r\n        var sinkHandle = builder.AddSink<ConsoleSink<string>, string>("sink");\r\n\r\n        builder.Connect(sourceHandle, transformHandle);\r\n        builder.Connect(transformHandle, sinkHandle);\r\n    }\r\n}\r\n\r\npublic static class Program\r\n{\r\n    public static async Task Main(string[] args)\r\n    {\r\n        var runner = new PipelineRunner();\r\n\r\n        // Configure retry options with materialization limit\r\n        var retryOptions = new PipelineRetryOptions(\r\n            MaxItemRetries: 3,\r\n            MaxNodeRestartAttempts: 2,\r\n            MaxSequentialNodeAttempts: 5,\r\n            MaxMaterializedItems: 1000 // Limit materialization to 1000 items\r\n        );\r\n\r\n        var context = PipelineContext.WithRetry(retryOptions);\r\n        context.AddPipelineErrorHandler<DefaultPipelineErrorHandler>();\r\n\r\n        await runner.RunAsync<ResilientPipelineDefinition>(context);\r\n    }\r\n}\r\n\r\npublic sealed class ResilientPipelineDefinitionWithConfiguration : IPipelineDefinition\r\n{\r\n    public void Define(PipelineBuilder builder, PipelineContext context)\r\n    {\r\n        var sourceHandle = builder.AddSource<InMemorySourceNode<int>, int>("source");\r\n        var transformHandle = builder\r\n            .AddTransform<FlakyTransform, int, string>("flakyProcessor")\r\n            .WithExecutionStrategy(builder,\r\n                new ResilientExecutionStrategy(new ParallelExecutionStrategy(maxDegreeOfParallelism: 2)));\r\n        var sinkHandle = builder.AddSink<ConsoleSink<string>, string>("sink");\r\n\r\n        builder.Connect(sourceHandle, transformHandle);\r\n        builder.Connect(transformHandle, sinkHandle);\r\n    }\r\n}\r\n\r\n        await runner.RunAsync<ResilientPipelineDefinition>(context);\r\n    }\r\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["In this example, the ",(0,t.jsx)(n.code,{children:"flakyProcessor"})," node will attempt to process items in parallel. If an item fails, the ",(0,t.jsx)(n.code,{children:"ResilientExecutionStrategy"})," will consult the pipeline's error handler to decide if it should retry processing that item or even restart the entire node's stream. The circuit breaker (if configured in ",(0,t.jsx)(n.code,{children:"PipelineRetryOptions"}),") would prevent excessive retries after too many consecutive failures."]}),"\n",(0,t.jsxs)(n.h2,{id:"bulb-comprehensive-documentation",children:["\ud83d\udca1"," Comprehensive Documentation"]}),"\n",(0,t.jsxs)(n.p,{children:["For detailed information about resilience patterns, materialization requirements, and dependency chains, see the ",(0,t.jsx)(n.a,{href:"/docs/core-concepts/resilience/",children:"Resilience section"})," which covers fault-tolerant execution strategies, buffering for replay functionality, critical prerequisite relationships, and configuration guidance for building robust pipelines."]}),"\n",(0,t.jsxs)(n.h2,{id:"information_source-see-also",children:["\u2139\ufe0f"," See Also"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/core-concepts/resilience/",children:"Resilience Overview"})}),": Comprehensive guide to building fault-tolerant pipelines"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/core-concepts/resilience/resilient-execution-strategy",children:"Resilient Execution Strategy"})}),": In-depth coverage of the ResilientExecutionStrategy"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/core-concepts/resilience/materialization-and-buffering",children:"Materialization and Buffering"})}),": Understanding buffer requirements for resilience"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/core-concepts/resilience/dependency-chains",children:"Dependency Chains"})}),": Critical prerequisite relationships for resilience features"]}),"\n"]}),"\n",(0,t.jsxs)(n.h2,{id:"arrow_right-next-steps",children:["\u27a1\ufe0f"," Next Steps"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/core-concepts/pipeline-execution/error-handling",children:"Error Handling"})}),": Dive deeper into how NPipeline handles errors, retries, and dead-letter queues."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/core-concepts/pipeline-execution",children:"Execution Context and State"})}),": Learn how state can be persisted and recovered across pipeline runs."]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>l});var i=r(6540);const t={},s=i.createContext(t);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);