<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-architecture/optimization-principles" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Optimization Principles - How NPipeline Achieves High Performance | NPipeline</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="robots" content="noindex, nofollow"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://npipeline.dev/docs/architecture/optimization-principles"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Optimization Principles - How NPipeline Achieves High Performance | NPipeline"><meta data-rh="true" name="description" content="Deep dive into architectural and design decisions that enable NPipeline&#x27;s exceptional performance characteristics."><meta data-rh="true" property="og:description" content="Deep dive into architectural and design decisions that enable NPipeline&#x27;s exceptional performance characteristics."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://npipeline.dev/docs/architecture/optimization-principles"><link data-rh="true" rel="alternate" href="https://npipeline.dev/docs/architecture/optimization-principles" hreflang="en"><link data-rh="true" rel="alternate" href="https://npipeline.dev/docs/architecture/optimization-principles" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Architecture","item":"https://npipeline.dev/docs/architecture/"},{"@type":"ListItem","position":2,"name":"Optimization Principles - How NPipeline Achieves High Performance","item":"https://npipeline.dev/docs/architecture/optimization-principles"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="NPipeline RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="NPipeline Atom Feed"><link rel="stylesheet" href="/assets/css/styles.4bb8ba71.css">
<script src="/assets/js/runtime~main.0144db7b.js" defer="defer"></script>
<script src="/assets/js/main.f8b38daa.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="NPipeline logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="NPipeline logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">NPipeline</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/">Docs</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/npipeline/npipeline" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/"><span title="Welcome to NPipeline" class="linkLabel_WmDU">Welcome to NPipeline</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/category/getting-started"><span title="Getting Started" class="categoryLinkLabel_W154">Getting Started</span></a><button aria-label="Expand sidebar category &#x27;Getting Started&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/core-concepts"><span title="Core Concepts" class="categoryLinkLabel_W154">Core Concepts</span></a><button aria-label="Expand sidebar category &#x27;Core Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/docs/architecture/"><span title="Architecture" class="categoryLinkLabel_W154">Architecture</span></a><button aria-label="Collapse sidebar category &#x27;Architecture&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/architectural-foundations"><span title="Architectural Foundations" class="linkLabel_WmDU">Architectural Foundations</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/component-architecture"><span title="Component Architecture" class="linkLabel_WmDU">Component Architecture</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/execution-flow"><span title="Execution Flow" class="linkLabel_WmDU">Execution Flow</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/data-flow"><span title="Data Flow Details" class="linkLabel_WmDU">Data Flow Details</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/dependency-injection"><span title="Dependency Injection Integration" class="linkLabel_WmDU">Dependency Injection Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/node-instantiation"><span title="Node Instantiation" class="linkLabel_WmDU">Node Instantiation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/error-handling-architecture"><span title="Error Handling Architecture" class="linkLabel_WmDU">Error Handling Architecture</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/cancellation-model"><span title="Cancellation Model" class="linkLabel_WmDU">Cancellation Model</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/performance-characteristics"><span title="Performance Characteristics" class="linkLabel_WmDU">Performance Characteristics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/retry-delay-architecture"><span title="Retry Delay Strategies Architecture" class="linkLabel_WmDU">Retry Delay Strategies Architecture</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/extension-points"><span title="Extension Points" class="linkLabel_WmDU">Extension Points</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/design-principles"><span title="Design Principles" class="linkLabel_WmDU">Design Principles</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/architecture/optimization-principles"><span title="Optimization Principles - How NPipeline Achieves High Performance" class="linkLabel_WmDU">Optimization Principles - How NPipeline Achieves High Performance</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/architecture/execution-plan-caching"><span title="Execution Plan Caching" class="linkLabel_WmDU">Execution Plan Caching</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/extensions"><span title="Extensions" class="categoryLinkLabel_W154">Extensions</span></a><button aria-label="Expand sidebar category &#x27;Extensions&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/connectors"><span title="Connectors" class="categoryLinkLabel_W154">Connectors</span></a><button aria-label="Expand sidebar category &#x27;Connectors&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/advanced-topics"><span title="Advanced Topics" class="categoryLinkLabel_W154">Advanced Topics</span></a><button aria-label="Expand sidebar category &#x27;Advanced Topics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/analyzers/"><span title="Build-Time Analyzers" class="categoryLinkLabel_W154">Build-Time Analyzers</span></a><button aria-label="Expand sidebar category &#x27;Build-Time Analyzers&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/samples/"><span title="Samples" class="categoryLinkLabel_W154">Samples</span></a><button aria-label="Expand sidebar category &#x27;Samples&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/category/reference"><span title="Reference" class="categoryLinkLabel_W154">Reference</span></a><button aria-label="Expand sidebar category &#x27;Reference&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/architecture/"><span>Architecture</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Optimization Principles - How NPipeline Achieves High Performance</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Optimization Principles - How NPipeline Achieves High Performance</h1></header><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="optimization-principles-how-npipeline-achieves-high-performance">Optimization Principles: How NPipeline Achieves High Performance<a href="#optimization-principles-how-npipeline-achieves-high-performance" class="hash-link" aria-label="Direct link to Optimization Principles: How NPipeline Achieves High Performance" title="Direct link to Optimization Principles: How NPipeline Achieves High Performance" translate="no">​</a></h2>
<p><strong>This page explains WHY NPipeline is fast.</strong> For HOW TO optimize your specific pipelines, see <a class="" href="/docs/advanced-topics/">Advanced Topics</a> and <a class="" href="/docs/advanced-topics/performance-hygiene">Performance Hygiene</a>.</p>
<p>Before understanding optimization principles, you should be familiar with:</p>
<ul>
<li class=""><a class="" href="/docs/core-concepts">Core Concepts Overview</a> - Basic NPipeline concepts and terminology</li>
<li class=""><a class="" href="/docs/architecture/">Architecture Overview</a> - Understanding NPipeline&#x27;s internal architecture</li>
<li class=""><a class="" href="/docs/core-concepts/pipeline-execution/execution-strategies">Execution Strategies</a> - How nodes execute data</li>
</ul>
<p>NPipeline&#x27;s performance advantages don&#x27;t come by accident. They&#x27;re result of deliberate architectural decisions made at framework level. This document explains <strong>why</strong> behind NPipeline&#x27;s design and how these choices combine to deliver measurable performance benefits.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-performance-challenge">The Performance Challenge<a href="#the-performance-challenge" class="hash-link" aria-label="Direct link to The Performance Challenge" title="Direct link to The Performance Challenge" translate="no">​</a></h2>
<p>Data processing frameworks face inherent tradeoffs:</p>
<ul>
<li class=""><strong>Flexibility</strong> (supporting diverse use cases) vs. <strong>Optimization</strong> (pre-computing for specific scenarios)</li>
<li class=""><strong>Developer Experience</strong> (intuitive APIs, reduced boilerplate) vs. <strong>Performance</strong> (minimal overhead, zero-cost abstractions)</li>
<li class=""><strong>Safety</strong> (preventing errors) vs. <strong>Speed</strong> (avoiding runtime checks)</li>
</ul>
<p>Most frameworks compromise by making reasonable defaults but allowing flexibility. NPipeline takes a different approach: optimize for most common, highest-impact scenarios while maintaining flexibility for others.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="core-optimization-principles">Core Optimization Principles<a href="#core-optimization-principles" class="hash-link" aria-label="Direct link to Core Optimization Principles" title="Direct link to Core Optimization Principles" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-plan-based-execution-model">1. Plan-Based Execution Model<a href="#1-plan-based-execution-model" class="hash-link" aria-label="Direct link to 1. Plan-Based Execution Model" title="Direct link to 1. Plan-Based Execution Model" translate="no">​</a></h3>
<p><strong>The Principle:</strong> Pre-compute everything that doesn&#x27;t change per-item.</p>
<p><strong>Traditional Approach:</strong></p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// Interpreted: evaluate routing/execution strategy for every item</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">foreach (var item in items)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    var strategy = DetermineStrategy(item);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    var result = ExecuteStrategy(strategy, item);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p><strong>NPipeline Approach:</strong></p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// Compiled: determine execution plan once, execute same plan for all items</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">var executionPlan = CompileExecutionPlan(pipeline);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">foreach (var item in items)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    executionPlan.Execute(item);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p><strong>Why This Matters:</strong></p>
<ul>
<li class="">Eliminating per-item branching reduces CPU cache misses</li>
<li class="">Predictable instruction patterns improve branch prediction</li>
<li class="">The CPU pipeline can optimize hot path more effectively</li>
<li class="">In high-throughput scenarios: thousands of decisions per second become zero decisions</li>
</ul>
<p><strong>Impact:</strong> Measurable CPU efficiency improvement, especially on modern CPUs with deep pipelines.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-zero-reflection-during-steady-state">2. Zero Reflection During Steady State<a href="#2-zero-reflection-during-steady-state" class="hash-link" aria-label="Direct link to 2. Zero Reflection During Steady State" title="Direct link to 2. Zero Reflection During Steady State" translate="no">​</a></h3>
<p><strong>The Principle:</strong> Pay reflection cost upfront, then never again.</p>
<p><strong>Reflection Overhead:</strong></p>
<ul>
<li class="">Runtime type introspection (method resolution, property access)</li>
<li class="">Dynamic method invocation via delegates</li>
<li class="">Argument marshalling and unmarshalling</li>
<li class="">GC pressure from temporary objects created during reflection</li>
</ul>
<p><strong>Traditional Approach:</strong></p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// Per-item reflection: look up methods, invoke dynamically</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">foreach (var item in items)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    var method = GetMethod(item.GetType());  // ← Reflection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    method.Invoke(transform, new[] { item }); // ← Dynamic dispatch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p><strong>NPipeline Approach:</strong></p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// Compile-time: pre-compiled delegates to actual methods</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">var compiledDelegate = CompileDelegate&lt;T&gt;(method);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">foreach (var item in items)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    compiledDelegate(item);  // ← Direct, compiled dispatch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p><strong>Why This Matters:</strong></p>
<ul>
<li class="">Reflection is expensive: 100-1000x slower than direct method calls</li>
<li class="">Pre-compiled delegates are statically typed, JIT-optimizable</li>
<li class="">Reflection GC pressure is eliminated during steady state</li>
<li class="">The JIT compiler can inline delegate calls</li>
</ul>
<p><strong>Impact:</strong> Particularly noticeable in scenarios with millions of items, where per-item reflection overhead becomes dominant cost.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-icountable-optimization-for-memory-efficiency">3. ICountable Optimization for Memory Efficiency<a href="#3-icountable-optimization-for-memory-efficiency" class="hash-link" aria-label="Direct link to 3. ICountable Optimization for Memory Efficiency" title="Direct link to 3. ICountable Optimization for Memory Efficiency" translate="no">​</a></h3>
<p><strong>The Principle:</strong> Know the size of your data upfront to make smart allocation decisions.</p>
<p><strong>The Problem:</strong></p>
<ul>
<li class=""><code>IEnumerable&lt;T&gt;</code> has no size information</li>
<li class="">Buffers must be over-allocated or reallocated (expensive)</li>
<li class="">Collections often allocate larger capacity than needed (wasting memory)</li>
</ul>
<p><strong>NPipeline&#x27;s Solution - ICountable:</strong></p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">public interface ICountable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    long Count { get; }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>Pipes and collections implementing <code>ICountable</code> expose their size, enabling:</p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// Allocate exactly the right buffer size, no overshooting</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if (input is ICountable countable)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    var buffer = new T[countable.Count];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // Fill buffer with no reallocation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // Fall back to dynamic resizing for unknown sizes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p><strong>Why This Matters:</strong></p>
<ul>
<li class="">Right-sized buffers = reduced memory waste</li>
<li class="">Fewer reallocations = reduced allocation pressure</li>
<li class="">Predictable memory usage = easier capacity planning</li>
<li class="">Smaller GC working set = better cache locality</li>
</ul>
<p><strong>Impact:</strong> Especially important for pipelines with large intermediate collections (batching, aggregation).</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-streaming-first-design-with-lazy-evaluation">4. Streaming-First Design with Lazy Evaluation<a href="#4-streaming-first-design-with-lazy-evaluation" class="hash-link" aria-label="Direct link to 4. Streaming-First Design with Lazy Evaluation" title="Direct link to 4. Streaming-First Design with Lazy Evaluation" translate="no">​</a></h3>
<p><strong>The Principle:</strong> Process data incrementally, never buffer unnecessarily.</p>
<p><strong>Traditional Batch Processing Approach:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Load entire dataset → Filter → Transform → Load output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Memory usage = entire dataset in memory at once</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Large GC pauses when data is collected</span><br></span></code></pre></div></div>
<p><strong>NPipeline Streaming Approach:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Item 1 → Filter → Transform → Output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Item 2 → Filter → Transform → Output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Item 3 → Filter → Transform → Output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Memory usage = only current item + accumulated state</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Tiny, predictable GC pauses</span><br></span></code></pre></div></div>
<p><strong>Implementation:</strong></p>
<ul>
<li class=""><code>IAsyncEnumerable&lt;T&gt;</code> for lazy evaluation</li>
<li class="">Pull-based data flow (demand-driven)</li>
<li class="">State is only accumulated when explicitly required (aggregation, joins)</li>
</ul>
<p><strong>Why This Matters:</strong></p>
<ul>
<li class="">Memory usage scales with state complexity, not data volume</li>
<li class="">GC pause times are predictable and minimal</li>
<li class="">Latency for processing first item is low (no waiting for batch assembly)</li>
<li class="">Natural backpressure: slow consumers slow down producers</li>
</ul>
<p><strong>Impact:</strong> Enables processing of datasets far larger than available memory, with minimal latency impact.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-allocation-reduction-and-valuetask-optimization">5. Allocation Reduction and ValueTask Optimization<a href="#5-allocation-reduction-and-valuetask-optimization" class="hash-link" aria-label="Direct link to 5. Allocation Reduction and ValueTask Optimization" title="Direct link to 5. Allocation Reduction and ValueTask Optimization" translate="no">​</a></h3>
<p><strong>The Principle:</strong> Eliminate unnecessary heap allocations in hot paths.</p>
<p><strong>The Problem - Traditional Async Framework:</strong></p>
<p>In a pipeline processing 1M items/sec with 90% cache hits: <strong>900,000 Task allocations per second</strong></p>
<p><strong>NPipeline Approach - ValueTask:</strong></p>
<p><code>ValueTask&lt;T&gt;</code> is a struct-based alternative to <code>Task&lt;T&gt;</code> that:</p>
<ul>
<li class=""><strong>Allocates on stack</strong> (not heap) when result is available synchronously</li>
<li class=""><strong>Zero allocations</strong> for common case in cache-hit or synchronous scenarios</li>
<li class=""><strong>Seamlessly transitions</strong> to true async work when needed</li>
</ul>
<p><strong>Why This Matters:</strong></p>
<ul>
<li class=""><code>ValueTask&lt;T&gt;</code> is a struct (stack-allocated)</li>
<li class="">For synchronous results: zero heap allocations</li>
<li class="">For asynchronous results: seamlessly transitions to <code>Task&lt;T&gt;</code></li>
<li class="">No performance penalty for async fallback path</li>
</ul>
<p><strong>Measured Impact:</strong></p>
<ul>
<li class=""><strong>Up to 90% reduction in GC pressure</strong> in high-cache-hit scenarios</li>
<li class="">Smoother throughput: fewer GC pauses</li>
<li class="">More predictable latency: less &quot;garbage spikes&quot;</li>
</ul>
<p><strong>Common Scenarios:</strong></p>
<ul>
<li class="">Data validation (usually synchronous)</li>
<li class="">Filtering (usually synchronous)</li>
<li class="">Cached enrichment (high synchronous fast path rate)</li>
<li class="">These represent everyday pipeline tasks, not edge cases</li>
</ul>
<p>For complete implementation guidance, including critical constraints and real-world examples, see <a class="" href="/docs/advanced-topics/synchronous-fast-paths"><strong>Synchronous Fast Paths and ValueTask Optimization</strong></a>—the dedicated deep-dive guide that covers the complete implementation pattern and dangerous constraints you must understand.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-cached-context-access-per-item-optimization">3. Cached Context Access (Per-Item Optimization)<a href="#3-cached-context-access-per-item-optimization" class="hash-link" aria-label="Direct link to 3. Cached Context Access (Per-Item Optimization)" title="Direct link to 3. Cached Context Access (Per-Item Optimization)" translate="no">​</a></h3>
<p><strong>The Principle:</strong> Cache frequently-accessed execution context to eliminate per-item dictionary lookups.</p>
<p><strong>The Problem - Context Access Overhead:</strong></p>
<p>During high-throughput node execution (1M+ items/sec), accessing execution context properties multiple times per item adds up:</p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// Before optimization: dictionary lookups for every item</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">foreach (var item in items)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    var retryOptions = context.Items.TryGetValue(&quot;retry::nodeId&quot;, ...); // ← Lookup 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    var tracingEnabled = context.Tracer is not NullTracer;              // ← Lookup 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    var loggingEnabled = context.LoggerFactory is not NullFactory;      // ← Lookup 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // ... process item</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>With millions of items, these repeated lookups become a measurable bottleneck (150-250μs overhead per 1K items).</p>
<p><strong>NPipeline Solution - CachedNodeExecutionContext:</strong></p>
<p>Capture execution context state once at node scope, then reuse for all items:</p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// After optimization: capture once, reuse for all items</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">var cached = CachedNodeExecutionContext.Create(context, nodeId);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">foreach (var item in items)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // Use cached values - no dictionary lookups</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (cached.TracingEnabled)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // ... trace</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    var maxRetries = cached.RetryOptions.MaxItemRetries; // ← Already cached</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // ... process item</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p><strong>How It Works:</strong></p>
<p><code>CachedNodeExecutionContext</code> is a readonly struct that captures:</p>
<ul>
<li class=""><strong>NodeId</strong> - Identifier of the executing node</li>
<li class=""><strong>RetryOptions</strong> - Pre-resolved retry configuration (with precedence: node-specific → global → context)</li>
<li class=""><strong>TracingEnabled</strong> - Whether tracing is active (checked once)</li>
<li class=""><strong>LoggingEnabled</strong> - Whether logging is active (checked once)</li>
<li class=""><strong>CancellationToken</strong> - Cancellation token for this execution</li>
</ul>
<p><strong>Why This Matters:</strong></p>
<ul>
<li class=""><strong>Eliminates per-item dictionary lookups</strong> - Direct field access instead of <code>context.Items.TryGetValue()</code></li>
<li class=""><strong>Zero allocation overhead</strong> - Readonly struct is stack-allocated</li>
<li class=""><strong>Transparent to users</strong> - Automatically used by execution strategies</li>
<li class=""><strong>Thread-safe</strong> - Each worker thread has its own cached instance</li>
</ul>
<p><strong>Immutability Guarantee:</strong></p>
<p>The cached context assumes that execution state remains immutable during node execution. NPipeline enforces this automatically:</p>
<ul>
<li class="">In DEBUG builds: <code>PipelineContextImmutabilityGuard</code> validates that context state hasn&#x27;t changed</li>
<li class="">In RELEASE builds: Zero overhead (validation compiled out)</li>
</ul>
<p>If mutations are detected in DEBUG builds, a descriptive exception is thrown:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Context immutability violation detected for node &#x27;myNode&#x27;: </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Retry options were modified during node execution.</span><br></span></code></pre></div></div>
<p><strong>Performance Impact:</strong></p>
<ul>
<li class="">~150-250μs reduction per 1K items in typical pipelines</li>
<li class="">Improvement scales with:<!-- -->
<ul>
<li class="">Number of items (more items = more savings)</li>
<li class="">Item processing cost (overhead is more noticeable with fast transforms)</li>
<li class="">Retry configuration usage (more lookups = more savings)</li>
</ul>
</li>
</ul>
<p><strong>When This Helps Most:</strong></p>
<ul>
<li class="">High-throughput scenarios (100K+ items/sec)</li>
<li class="">Frequent retry option lookups</li>
<li class="">Parallel execution strategies</li>
<li class="">Nodes with low per-item processing cost</li>
</ul>
<p>For best practices on working with cached contexts and avoiding mutations, see <a class="" href="/docs/advanced-topics/performance-hygiene#avoid-context-mutations-during-node-execution">Performance Hygiene: Context Immutability</a>.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="6-graph-based-execution-for-dependency-clarity">6. Graph-Based Execution for Dependency Clarity<a href="#6-graph-based-execution-for-dependency-clarity" class="hash-link" aria-label="Direct link to 6. Graph-Based Execution for Dependency Clarity" title="Direct link to 6. Graph-Based Execution for Dependency Clarity" translate="no">​</a></h3>
<p><strong>The Principle:</strong> Make execution flow explicit and optimizable.</p>
<p><strong>Why a Graph?</strong></p>
<ul>
<li class=""><strong>Clarity:</strong> Visual representation of data dependencies</li>
<li class=""><strong>Optimization:</strong> Can identify parallelizable segments</li>
<li class=""><strong>Composability:</strong> Nodes can be chained, reused, tested independently</li>
<li class=""><strong>Debuggability:</strong> Clear data provenance (lineage)</li>
</ul>
<p><strong>Execution Strategy:</strong></p>
<ul>
<li class="">The graph is traversed once during the &quot;plan compilation&quot; phase</li>
<li class="">Execution strategy (sequential, parallel) is determined from graph structure</li>
<li class="">No per-item graph traversal overhead</li>
</ul>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="7-memory-layout-and-cache-efficiency">7. Memory Layout and Cache Efficiency<a href="#7-memory-layout-and-cache-efficiency" class="hash-link" aria-label="Direct link to 7. Memory Layout and Cache Efficiency" title="Direct link to 7. Memory Layout and Cache Efficiency" translate="no">​</a></h3>
<p><strong>The Principle:</strong> Respect CPU cache behavior.</p>
<p><strong>Key Decisions:</strong></p>
<ul>
<li class=""><strong>Value types for small data:</strong> Structs with &lt; 16 bytes avoid GC overhead</li>
<li class=""><strong>Array-backed collections:</strong> Better cache locality than linked lists</li>
<li class=""><strong>Contiguous buffers:</strong> CPU prefetcher can predict access patterns</li>
<li class=""><strong>Minimize indirection:</strong> Reduce pointer chasing in hot paths</li>
</ul>
<p><strong>Example:</strong></p>
<div class="language-csharp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-csharp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// ✓ GOOD: Value types, contiguous memory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public readonly struct Event</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public long Timestamp { get; }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public int Value { get; }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// LESS OPTIMAL: Reference types, scattered memory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public class Event</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public long Timestamp { get; set; }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public int Value { get; set; }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-these-principles-work-together">How These Principles Work Together<a href="#how-these-principles-work-together" class="hash-link" aria-label="Direct link to How These Principles Work Together" title="Direct link to How These Principles Work Together" translate="no">​</a></h2>
<p>The principles don&#x27;t operate in isolation; they combine synergistically:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Plan-Based Execution</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Eliminates per-item decisions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Enables JIT optimization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Improves CPU cache behavior</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Zero Reflection at Runtime</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Direct method dispatch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Inlinable and optimizable by JIT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Reduces memory allocations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ValueTask Optimization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Eliminates allocations in fast paths</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Reduces GC pressure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Smaller GC working set = better cache locality</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Streaming + Lazy Evaluation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Process incrementally</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Predictable memory usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Minimal GC pauses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ICountable for Right-Sizing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Allocate exactly what&#x27;s needed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Fewer reallocations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Better memory cache behavior</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="6-execution-plan-caching">6. Execution Plan Caching<a href="#6-execution-plan-caching" class="hash-link" aria-label="Direct link to 6. Execution Plan Caching" title="Direct link to 6. Execution Plan Caching" translate="no">​</a></h2>
<p><strong>The Principle:</strong> Pre-compile expression trees once, cache them indefinitely.</p>
<p>NPipeline compiles execution plans (expression trees) when a pipeline first runs. These plans are expensive to build (~300-500μs per pipeline) but can be cached and reused:</p>
<p><strong>What Gets Cached:</strong></p>
<ul>
<li class="">Pre-compiled delegates for transform execution</li>
<li class="">Expression trees for type conversions</li>
<li class="">Execution routing for joins and aggregates</li>
</ul>
<p><strong>Result:</strong></p>
<ul>
<li class=""><strong>First run:</strong> Pay compilation cost (~1.9ms for small pipeline)</li>
<li class=""><strong>Subsequent runs:</strong> Use cached plans (~0.4-0.5ms for small pipeline)</li>
<li class=""><strong>Improvement:</strong> 75% reduction in execution time after warm-up</li>
</ul>
<p><strong>When Caching Applies:</strong></p>
<ul>
<li class="">Same pipeline definition runs multiple times ✓ (typical case)</li>
<li class="">Pipeline definition changes between runs ✗ (automatic cache miss)</li>
<li class="">Preconfigured nodes with state ✗ (caching disabled for safety)</li>
</ul>
<p><strong>Impact:</strong> 250-450μs saved per run for pipelines with caching enabled.</p>
<p>See <a class="" href="/docs/architecture/execution-plan-caching">Execution Plan Caching</a> for detailed architecture.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="combined-impact-of-all-optimizations">Combined Impact of All Optimizations<a href="#combined-impact-of-all-optimizations" class="hash-link" aria-label="Direct link to Combined Impact of All Optimizations" title="Direct link to Combined Impact of All Optimizations" translate="no">​</a></h2>
<p>These six principles work together to create exceptional performance:</p>
<div class="language-plaintext codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-plaintext codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Plan-Based Execution</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Compile once, execute many times</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Zero per-item decision overhead</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Plan Caching amplifies this (75% reduction on warm-up)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Zero Reflection at Runtime</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Direct method dispatch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Inlinable and optimizable by JIT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Reduces memory allocations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ValueTask Optimization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Eliminates allocations in fast paths</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Reduces GC pressure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Smaller GC working set = better cache locality</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Streaming + Lazy Evaluation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Process incrementally</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Predictable memory usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Minimal GC pauses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ICountable for Right-Sizing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓ Allocate exactly what&#x27;s needed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├→ Fewer reallocations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └→ Better memory cache behavior</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="measurable-results">Measurable Results<a href="#measurable-results" class="hash-link" aria-label="Direct link to Measurable Results" title="Direct link to Measurable Results" translate="no">​</a></h2>
<p>The combination of these principles produces observable performance characteristics:</p>
<table><thead><tr><th>Metric</th><th>Typical Benefit</th></tr></thead><tbody><tr><td><strong>GC Pause Duration</strong></td><td>50-80% reduction vs. naive async approach</td></tr><tr><td><strong>Memory Allocations</strong></td><td>Up to 90% fewer in cache-hit scenarios</td></tr><tr><td><strong>Throughput (items/sec)</strong></td><td>2-5x improvement vs. interpreted frameworks</td></tr><tr><td><strong>Latency (p99)</strong></td><td>More predictable, fewer spikes</td></tr><tr><td><strong>CPU Efficiency</strong></td><td>Better branch prediction, cache locality</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="trade-offs-and-when-these-optimizations-matter">Trade-offs and When These Optimizations Matter<a href="#trade-offs-and-when-these-optimizations-matter" class="hash-link" aria-label="Direct link to Trade-offs and When These Optimizations Matter" title="Direct link to Trade-offs and When These Optimizations Matter" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="when-optimization-matters-most">When Optimization Matters Most<a href="#when-optimization-matters-most" class="hash-link" aria-label="Direct link to When Optimization Matters Most" title="Direct link to When Optimization Matters Most" translate="no">​</a></h3>
<p>These optimizations provide most benefit in:</p>
<ul>
<li class=""><strong>High-throughput scenarios:</strong> Millions of items per second</li>
<li class=""><strong>Multi-tenant systems:</strong> GC pauses directly impact other tenants</li>
<li class=""><strong>Real-time processing:</strong> Latency spikes from GC pauses are unacceptable</li>
<li class=""><strong>Long-running processes:</strong> Accumulated allocation pressure matters</li>
<li class=""><strong>Latency-sensitive workloads:</strong> Predictable performance critical</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="when-optimization-matters-less">When Optimization Matters Less<a href="#when-optimization-matters-less" class="hash-link" aria-label="Direct link to When Optimization Matters Less" title="Direct link to When Optimization Matters Less" translate="no">​</a></h3>
<p>These optimizations have minimal impact if:</p>
<ul>
<li class=""><strong>Throughput is low:</strong> (&lt; 1000 items/sec) - bottleneck is elsewhere</li>
<li class=""><strong>Items are large:</strong> (&gt; 100KB) - allocation cost is tiny vs. processing cost</li>
<li class=""><strong>Processing is CPU-bound:</strong> GC pressure is secondary concern</li>
<li class=""><strong>Latency spikes are acceptable:</strong> SLAs allow for GC pauses</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="see-also">See Also<a href="#see-also" class="hash-link" aria-label="Direct link to See Also" title="Direct link to See Also" translate="no">​</a></h2>
<ul>
<li class=""><a class="" href="/docs/architecture/execution-plan-caching">Execution Plan Caching</a> - How plan caching eliminates compilation overhead</li>
<li class=""><a class="" href="/docs/advanced-topics/performance-hygiene">Performance Hygiene</a> - Best practices for writing performant NPipeline code</li>
<li class=""><a class="" href="/docs/advanced-topics/synchronous-fast-paths">Synchronous Fast Paths</a> - Master ValueTask patterns in your transform nodes</li>
<li class=""><a class="" href="/docs/architecture/component-architecture">Component Architecture</a> - Understand how these principles are implemented in codebase</li>
<li class=""><a class="" href="/docs/architecture/execution-flow">Execution Flow</a> - How optimization principles affect data flow</li>
<li class=""><a class="" href="/docs/architecture/performance-characteristics">Performance Characteristics</a> - Measurable performance implications</li>
<li class=""><a class="" href="/docs/architecture/architectural-foundations">Architecture: Architectural Foundations</a> - Fundamental architectural building blocks</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">​</a></h2>
<ul>
<li class=""><strong><a class="" href="/docs/architecture/execution-plan-caching">Execution Plan Caching</a>:</strong> Deep dive into how compiled plans are cached</li>
<li class=""><strong><a class="" href="/docs/advanced-topics/performance-hygiene">Performance Hygiene</a>:</strong> Best practices for writing performant NPipeline code</li>
<li class=""><strong><a class="" href="/docs/advanced-topics/synchronous-fast-paths">Synchronous Fast Paths</a>:</strong> Master ValueTask patterns in your transform nodes</li>
<li class=""><strong><a class="" href="/docs/architecture/component-architecture">Component Architecture</a>:</strong> Understand how these principles are implemented in codebase</li>
<li class=""><strong><a class="" href="/docs/architecture/performance-characteristics">Performance Characteristics</a>:</strong> Understanding performance implications of different approaches</li>
</ul></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/architecture/design-principles"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Design Principles</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/architecture/execution-plan-caching"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Execution Plan Caching</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#optimization-principles-how-npipeline-achieves-high-performance" class="table-of-contents__link toc-highlight">Optimization Principles: How NPipeline Achieves High Performance</a></li><li><a href="#the-performance-challenge" class="table-of-contents__link toc-highlight">The Performance Challenge</a></li><li><a href="#core-optimization-principles" class="table-of-contents__link toc-highlight">Core Optimization Principles</a><ul><li><a href="#1-plan-based-execution-model" class="table-of-contents__link toc-highlight">1. Plan-Based Execution Model</a></li><li><a href="#2-zero-reflection-during-steady-state" class="table-of-contents__link toc-highlight">2. Zero Reflection During Steady State</a></li><li><a href="#3-icountable-optimization-for-memory-efficiency" class="table-of-contents__link toc-highlight">3. ICountable Optimization for Memory Efficiency</a></li><li><a href="#4-streaming-first-design-with-lazy-evaluation" class="table-of-contents__link toc-highlight">4. Streaming-First Design with Lazy Evaluation</a></li><li><a href="#5-allocation-reduction-and-valuetask-optimization" class="table-of-contents__link toc-highlight">5. Allocation Reduction and ValueTask Optimization</a></li><li><a href="#3-cached-context-access-per-item-optimization" class="table-of-contents__link toc-highlight">3. Cached Context Access (Per-Item Optimization)</a></li><li><a href="#6-graph-based-execution-for-dependency-clarity" class="table-of-contents__link toc-highlight">6. Graph-Based Execution for Dependency Clarity</a></li><li><a href="#7-memory-layout-and-cache-efficiency" class="table-of-contents__link toc-highlight">7. Memory Layout and Cache Efficiency</a></li></ul></li><li><a href="#how-these-principles-work-together" class="table-of-contents__link toc-highlight">How These Principles Work Together</a></li><li><a href="#6-execution-plan-caching" class="table-of-contents__link toc-highlight">6. Execution Plan Caching</a></li><li><a href="#combined-impact-of-all-optimizations" class="table-of-contents__link toc-highlight">Combined Impact of All Optimizations</a></li><li><a href="#measurable-results" class="table-of-contents__link toc-highlight">Measurable Results</a></li><li><a href="#trade-offs-and-when-these-optimizations-matter" class="table-of-contents__link toc-highlight">Trade-offs and When These Optimizations Matter</a><ul><li><a href="#when-optimization-matters-most" class="table-of-contents__link toc-highlight">When Optimization Matters Most</a></li><li><a href="#when-optimization-matters-less" class="table-of-contents__link toc-highlight">When Optimization Matters Less</a></li></ul></li><li><a href="#see-also" class="table-of-contents__link toc-highlight">See Also</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Documentation</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/getting-started/why-npipeline">Why NPipeline?</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/getting-started/installation">Installation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/getting-started/quick-start">Quick Start</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/core-concepts">Core Concepts</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/npipeline/npipeline" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">&nbsp;</div></div></div></footer></div>
</body>
</html>